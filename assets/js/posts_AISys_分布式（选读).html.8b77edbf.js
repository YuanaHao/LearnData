"use strict";(self.webpackChunklearn_data=self.webpackChunklearn_data||[]).push([[4629],{8789:(s,a)=>{a.A=(s,a)=>{const n=s.__vccOpts||s;for(const[s,t]of a)n[s]=t;return n}},1439:(s,a,n)=>{n.r(a),n.d(a,{comp:()=>z,data:()=>M});var t=n(5252);const l=n.p+"assets/img/SP1.8eba1a48.png",e=n.p+"assets/img/SP2.9b422665.png",p=n.p+"assets/img/SP3.26579ce4.png",m=n.p+"assets/img/SP4.e5a533d7.png",i=n.p+"assets/img/SP5.c0aed9f0.png",r=n.p+"assets/img/SP6.2241dbc1.png",c=n.p+"assets/img/SP7.753fd7f8.png",o=n.p+"assets/img/SP8.13a5f81c.png",h=n.p+"assets/img/SP9.c333f93f.png",g=n.p+"assets/img/SP10.778f5988.png",k=n.p+"assets/img/SP11.4b73955c.png",d=n.p+"assets/img/SP12.40fb722f.png",L=n.p+"assets/img/SP13.1482917c.png",u=n.p+"assets/img/SP14.4efcc57a.png",v=n.p+"assets/img/SP15.fe92f6aa.png",y=n.p+"assets/img/SP16.63dbadda.png",b=n.p+"assets/img/SP17.25ade6b7.png",w=n.p+"assets/img/SP18.d87235ca.png",x=n.p+"assets/img/SP19.3a640b1c.png",f={},z=(0,n(8789).A)(f,[["render",function(s,a){return(0,t.uX)(),(0,t.CE)("div",null,a[0]||(a[0]=[(0,t.Fv)('<h2 id="序列并行" tabindex="-1"><a class="header-anchor" href="#序列并行"><span>序列并行</span></a></h2><h3 id="megatron" tabindex="-1"><a class="header-anchor" href="#megatron"><span>Megatron</span></a></h3><p>Reducing Activation Recomputation in Large Transformer Models</p><p><code>https://arxiv.org/pdf/2205.05198</code></p><h4 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract"><span>Abstract</span></a></h4><p>在大模型训练过程中显存占用过大往往成为瓶颈，一般会通过<code>重计算</code>的方式降低显存占用，但会带来额外的计算代价。本文提出<code>sequece parallel(序列并行,简称SP)</code>和<code>selective activation recomputation</code>两种方法，可以结合TP有效减少不必要的计算量。</p><p>下图中绿色部分表示不同参数级别模型中需要用于保存activation需要的显存大小，蓝色部分表示不同参数级别模型中需要用于保存<code>parameter</code>和<code>optimizer state</code>需要的显存大小。红色线表示baseline(A100的显存)80G。</p><p>通过对比可以发现,原本单A100跑不了的模型,经过SP优化后可以在单A100上运行了,这就给我们加大数据量和多机并行提供了极大的便利</p><p><img src="'+l+'" alt="SP效果示例"></p><h4 id="activation-memory" tabindex="-1"><a class="header-anchor" href="#activation-memory"><span>Activation Memory</span></a></h4><p>本文以Transformer结构为例估算<code>Activation Memory</code>，Activation指FWD和BWD梯度计算中创建的所有<code>tensor</code>。不包含模型参数大小和优化器中状态大小，但是包含dropout用到的<code>mask tensor</code>。</p><p><img src="'+e+'" alt="Activation"></p><p>本文推导与假设中用到了以下几个参量:<br><img src="'+p+'" alt="parameter"></p><p>本文假设h极大(实际上一般也确实极大), 认为2sb远小于sbh, 即只考虑中间过程的Memory(shb), 忽略输入输出的Memory</p><p>对于Attention模块,这一部分依赖于softmax实现:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex"> Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p><p>具体实现图例见下:</p><p><img src="'+m+'" alt="Attention"></p><p>对于<code>Attention</code>块来说，输入的元素个数为<code>sbh</code>个，每个元素以<code>半精度</code>(2 bytes)来进行存储的话，对应输入的元素大小为<code>2sbh bytes</code></p><p><code>Attention</code>块中包含一个<code>self-attention</code>、一个<code>linear(线性映射层)</code>和<code>attention dropout</code>层。对于<code>linear</code>需要保存输入的<code>Activation</code>大小为<code>2sbh</code>, 对于<code>attention dropout</code>层需要<code>mask</code>的大小为<code>sbh</code>(对于一个元素的mask只用1个bytes)，对于<code>self-attention</code>块的<code>Activation Memory</code>的计算有以下几块：</p><ul><li>Query(Q),Key(K),Value(V) <code>matrix mul</code>：input共享，元素个数为sbh个，总大小是 <code>2sbh bytes</code>。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span>矩阵相乘：需要分别创建保存<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>的矩阵，每个矩阵元素总大小为<code>2sbh bytes</code>, 总共大小为<code>4sbh bytes</code></li></ul><p>原始Self-Attention例子(此处X切分仅作示意,实际上是按行切分的):</p><p><img src="'+i+'" alt="TP"></p><p><img src="'+r+'" alt="Softmax"></p><ul><li><p>dropout的mask层矩阵的大小与softmax的输出一样，元素个数都是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding="application/x-tex">as^{2}b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span></span>个，但mask单个元素的大小只用<code>1 bytes</code>即可，总的大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding="application/x-tex">as^{2}b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span></span> bytes</p></li><li><p>softmax的输出也会用于反向的计算，需要缓存下来，对应大小 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding="application/x-tex">as^{2}b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span></span> bytes</p></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>矩阵的大小之前没有统计，和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>矩阵一样，大小也是<code>2sbh bytes</code></p></li></ul><blockquote><p>Attention 模块总的大小为 11sbh + 5<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding="application/x-tex">as^{2}b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span></span> bytes。</p></blockquote><p><code>MLP的Activation大小计算</code>：MLP中有两层线性layer，分别存储输入矩阵大小为<code>2sbh bytes</code>和<code>8sbh bytes</code>；GeLU的反向也需要对输入进行缓存，大小为<code>8sbh bytes</code>; dropout层需要<code>sbh bytes</code>; 总大小为<code>19sbh</code>。</p><p><code>LayerNorm的Activation大小计算</code>：每个LayerNorm层的输入需要<code>2sbh</code>大小，有两个LayerNorm层，总大小为<code>4sbh bytes</code>.</p><p>一层transformer的memory总的大小为:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>=</mo><mi>s</mi><mi>b</mi><mi>h</mi><mrow><mo fence="true">(</mo><mn>34</mn><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mi>s</mi></mrow><mi>h</mi></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex"> ActivationMemoryPerLayer=sbh\\left(34+5\\frac{as}h\\right) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.03588em;">ory</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">yer</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.836em;vertical-align:-0.686em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">bh</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord">34</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">5</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span></p><h4 id="tensor-parallel" tabindex="-1"><a class="header-anchor" href="#tensor-parallel"><span>Tensor Parallel</span></a></h4><p>在TP并行中只在Attention和MLP两个地方进行了并行计算，对于两块的输入并没有并行操作。</p><p>图中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>f</mi><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\\overline{f}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0889em;vertical-align:-0.1944em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span><span style="top:-3.8144em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>互为共轭(conjugate)，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>在前向时不做操作，反向时执行all-reduce;<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>f</mi><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\\overline{f}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0889em;vertical-align:-0.1944em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span><span style="top:-3.8144em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>在前向时执行all-reduce, 反向时不做操作。</p><p><img src="'+c+'" alt="TP"></p><p>考虑TP并行(并行度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span>)，并行部分有MLP的Linear部分(18sbh bytes)和Attention的QKV部分(6sbh bytes)， <code>ActivationMemoryPerLayer</code>的值降为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>=</mo><mi>s</mi><mi>b</mi><mi>h</mi><mrow><mo fence="true">(</mo><mn>10</mn><mo>+</mo><mfrac><mn>24</mn><mi>t</mi></mfrac><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mi>s</mi></mrow><mrow><mi>h</mi><mi>t</mi></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex"> ActivationMemoryPerLayer=sbh\\left(10+\\frac{24}t+5\\frac{as}{ht}\\right) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.03588em;">ory</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">yer</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">bh</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord">10</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">24</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">5</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p><h4 id="sequence-parallel" tabindex="-1"><a class="header-anchor" href="#sequence-parallel"><span>Sequence Parallel</span></a></h4><p>在Tensor模型并行基础上提出了<code>Sequence Parallel</code>，对于非TP并行的部分在sequence维度都是相互独立的，所以可以在sequence维度上进行拆分(即sequence parallel)。</p><p>拆分后如下图，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>f</mi><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\\overline{f}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0889em;vertical-align:-0.1944em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span><span style="top:-3.8144em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>替换为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\\overline{g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.825em;vertical-align:-0.1944em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6306em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3.5506em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>​在前向是reduce-scatter, 反向是all-gather通信。</p><p><img src="'+o+'" alt="SP"></p><p>以MLP为例，详细说明拆分步骤:</p><p>MLP层由两个Linear层组成，对应的计算公式如下, 其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>的大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>×</mo><mi>b</mi><mo>×</mo><mi>h</mi></mrow><annotation encoding="application/x-tex">s × b × h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span>;<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>是Linear的权重weight矩阵，大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>×</mo><mn>4</mn><mi>h</mi></mrow><annotation encoding="application/x-tex">h × 4h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">4</span><span class="mord mathnormal">h</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>h</mi><mo>×</mo><mi>h</mi></mrow><annotation encoding="application/x-tex">4h×h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span></p><p>论文做如下符号说明:</p>',43),(0,t.Lk)("p",{class:"katex-block"},[(0,t.Lk)("span",{class:"katex-display"},[(0,t.Lk)("span",{class:"katex"},[(0,t.Lk)("span",{class:"katex-mathml"},[(0,t.Lk)("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[(0,t.Lk)("semantics",null,[(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mi",null,"Y")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mtext",null,"LayerNorm"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("mi",null,"X"),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mi",null,"Z")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mtext",null,"GeLU"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("mi",null,"A"),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mi",null,"W")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mi",null,"Z"),(0,t.Lk)("mi",null,"B"),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mi",null,"V")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mtext",null,"Dropout"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},",")])])])])]),(0,t.Lk)("annotation",{encoding:"application/x-tex"}," \\begin{aligned}Y&=\\text{LayerNorm}(X),\\\\Z&=\\text{GeLU}(YA),\\\\W&=ZB,\\\\V&=\\text{Dropout}(W),\\end{aligned} ")])])]),(0,t.Lk)("span",{class:"katex-html","aria-hidden":"true"},[(0,t.Lk)("span",{class:"base"},[(0,t.Lk)("span",{class:"strut",style:{height:"6em","vertical-align":"-2.75em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"3.25em"}},[(0,t.Lk)("span",{style:{top:"-5.41em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y")])]),(0,t.Lk)("span",{style:{top:"-3.91em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z")])]),(0,t.Lk)("span",{style:{top:"-2.41em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W")])]),(0,t.Lk)("span",{style:{top:"-0.91em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"2.75em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"col-align-l"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"3.25em"}},[(0,t.Lk)("span",{style:{top:"-5.41em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"},"LayerNorm")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"-3.91em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"},"GeLU")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"mord mathnormal"},"A"),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"-2.41em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"ZB"),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"-0.91em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"},"Dropout")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},",")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"2.75em"}},[(0,t.Lk)("span")])])])])])])])])])])],-1),(0,t.Fv)('<p><img src="'+h+'" alt="SP细节"></p><ul><li>对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>按sequence维度切分， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo fence="true">[</mo><msubsup><mi>X</mi><mn>1</mn><mi>s</mi></msubsup><mo separator="true">,</mo><msubsup><mi>X</mi><mn>2</mn><mi>s</mi></msubsup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">X = \\left[ X^s_1, X^s_2 \\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span>，LayerNorm的结果<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mrow><mo fence="true">[</mo><msubsup><mi>Y</mi><mn>1</mn><mi>s</mi></msubsup><mo separator="true">,</mo><msubsup><mi>Y</mi><mn>2</mn><mi>s</mi></msubsup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">Y = \\left[ Y^s_1, Y^s_2 \\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span>；</li><li>考虑GeLU非线性，进行all-gather，计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>Y</mi><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z = GeLU(YA)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>；</li><li>对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>进行列切分的tensor并行，得到结果<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><msubsup><mi>A</mi><mn>1</mn><mi>c</mi></msubsup></mrow><annotation encoding="application/x-tex">YA^c_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9314em;vertical-align:-0.2481em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span>​和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><msubsup><mi>A</mi><mn>2</mn><mi>c</mi></msubsup></mrow><annotation encoding="application/x-tex">YA^c_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9314em;vertical-align:-0.2481em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span></li><li>对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>进行行切分的tensor并行，得到结果<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Z</mi><mn>1</mn><mi>h</mi></msubsup><msubsup><mi>B</mi><mn>1</mn><mi>r</mi></msubsup></mrow><annotation encoding="application/x-tex">Z^h_1 B^r_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0972em;vertical-align:-0.2481em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4519em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Z</mi><mn>2</mn><mi>h</mi></msubsup><msubsup><mi>B</mi><mn>2</mn><mi>r</mi></msubsup></mrow><annotation encoding="application/x-tex">Z^h_2 B^r_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0972em;vertical-align:-0.2481em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4519em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4519em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span></li><li>得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">W_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">W_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>后进行reduce-scatter</li></ul><p>具体过程见下:</p>',3),(0,t.Lk)("p",{class:"katex-block"},[(0,t.Lk)("span",{class:"katex-display"},[(0,t.Lk)("span",{class:"katex"},[(0,t.Lk)("span",{class:"katex-mathml"},[(0,t.Lk)("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[(0,t.Lk)("semantics",null,[(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},"]")])])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mtext",null,"LayerNorm"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"X"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"X"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},"]"),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},",")])])])])])])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mtext",null,"Y")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mi",null,"g"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Z"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"h")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Z"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"h")]),(0,t.Lk)("mo",{stretchy:"false"},"]")])])])])])])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("mtext",null,"GeLU"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"A"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"c")]),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("mtext",null," GeLU"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("mi",null,"Y"),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"A"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"c")]),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{stretchy:"false"},"]"),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"1")])])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Z"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"h")]),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"B"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"r")]),(0,t.Lk)("mtext",null," and "),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"2")]),(0,t.Lk)("mo",null,"="),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"Z"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"h")]),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"B"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"r")]),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},"]")])])])])])])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mover",{accent:"true"},[(0,t.Lk)("mi",null,"g"),(0,t.Lk)("mo",null,"ˉ")]),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"1")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"2")]),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},",")])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right",columnspacing:""},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"V"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"V"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},"]")])])])])])])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mo",{stretchy:"false"},"["),(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",{mathvariant:"normal"},"D"),(0,t.Lk)("mi",{mathvariant:"normal"},"r"),(0,t.Lk)("mi",{mathvariant:"normal"},"o"),(0,t.Lk)("mi",{mathvariant:"normal"},"p"),(0,t.Lk)("mi",{mathvariant:"normal"},"o"),(0,t.Lk)("mi",{mathvariant:"normal"},"u"),(0,t.Lk)("mi",{mathvariant:"normal"},"t")]),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"1"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("mtext",null," Dropout"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("msubsup",null,[(0,t.Lk)("mi",null,"W"),(0,t.Lk)("mn",null,"2"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mo",{stretchy:"false"},")"),(0,t.Lk)("mo",{stretchy:"false"},"]"),(0,t.Lk)("mi",{mathvariant:"normal"},".")])])])])]),(0,t.Lk)("annotation",{encoding:"application/x-tex"}," \\begin{aligned} [Y_1^s,Y_2^s]& \\begin{aligned}&=\\text{LayerNorm}([X_1^s,X_2^s]),\\end{aligned} \\\\ \\text{Y}& =g(Y_1^s,Y_2^s), \\\\ \\begin{aligned}[Z_1^h,Z_2^h]\\end{aligned}& =[\\text{GeLU}(YA_1^c),\\text{ GeLU}(YA_2^c)], \\\\ W_{1}& =Z_1^hB_1^r\\text{ and }W_2=Z_2^hB_2^r, \\\\ \\begin{aligned}[W_1^s,W_2^s]\\end{aligned}& =\\bar{g}(W_1,W_2), \\\\ \\begin{aligned}[V_1^s,V_2^s]\\end{aligned}& =[\\mathrm{Dropout}(W_1^s),\\text{ Dropout}(W_2^s)]. \\end{aligned}")])])]),(0,t.Lk)("span",{class:"katex-html","aria-hidden":"true"},[(0,t.Lk)("span",{class:"base"},[(0,t.Lk)("span",{class:"strut",style:{height:"10.3182em","vertical-align":"-4.9091em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"5.4091em"}},[(0,t.Lk)("span",{style:{top:"-7.4387em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen"},"["),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.2222em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.2222em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},"]")])]),(0,t.Lk)("span",{style:{top:"-5.7987em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"},"Y")])])]),(0,t.Lk)("span",{style:{top:"-4.1091em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.0296em"}},[(0,t.Lk)("span",{style:{top:"-3.1304em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen"},"["),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.8991em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0715em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"h")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.8991em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0715em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"h")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},"]")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.5296em"}},[(0,t.Lk)("span")])])])])])])])]),(0,t.Lk)("span",{style:{top:"-2.3804em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.3011em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.15em"}},[(0,t.Lk)("span")])])])])])])]),(0,t.Lk)("span",{style:{top:"-0.7204em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1em"}},[(0,t.Lk)("span",{style:{top:"-3.16em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen"},"["),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},"]")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.5em"}},[(0,t.Lk)("span")])])])])])])])]),(0,t.Lk)("span",{style:{top:"1.0796em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1em"}},[(0,t.Lk)("span",{style:{top:"-3.16em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen"},"["),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.2222em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.2222em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},"]")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.5em"}},[(0,t.Lk)("span")])])])])])])])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"4.9091em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"col-align-l"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"5.4091em"}},[(0,t.Lk)("span",{style:{top:"-7.4387em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1em"}},[(0,t.Lk)("span",{style:{top:"-3em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.84em"}}),(0,t.Lk)("span",{class:"mord"})])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.5em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"col-align-l"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1em"}},[(0,t.Lk)("span",{style:{top:"-3.16em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"},"LayerNorm")]),(0,t.Lk)("span",{class:"mopen"},"(["),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0785em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0785em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},"])"),(0,t.Lk)("span",{class:"mpunct"},",")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.5em"}},[(0,t.Lk)("span")])])])])])])])]),(0,t.Lk)("span",{style:{top:"-5.7987em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.2222em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.2222em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"-4.1091em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mopen"},"["),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"},"GeLU")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"A"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"c")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"}," GeLU")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"A"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"c")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")]"),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"-2.3804em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.8991em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0715em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"h")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0502em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"}," and ")]),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.3011em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.15em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.8991em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0715em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"h")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.0502em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"-0.7204em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord accent"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.5678em"}},[(0,t.Lk)("span",{style:{top:"-3em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g")]),(0,t.Lk)("span",{style:{top:"-3em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"accent-body",style:{left:"-0.2222em"}},[(0,t.Lk)("span",{class:"mord"},"ˉ")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.1944em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.3011em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.15em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.3011em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.15em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},",")])]),(0,t.Lk)("span",{style:{top:"1.0796em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.0296em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mopen"},"["),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathrm"},"Dropout")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"1")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")"),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord text"},[(0,t.Lk)("span",{class:"mord"}," Dropout")]),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.7144em"}},[(0,t.Lk)("span",{style:{top:"-2.453em","margin-left":"-0.1389em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},"2")])]),(0,t.Lk)("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.247em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")]"),(0,t.Lk)("span",{class:"mord"},".")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"4.9091em"}},[(0,t.Lk)("span")])])])])])])])])])])],-1),(0,t.Fv)("<p>TP在一次前向和后向总共有4次的<code>all-reduce</code>操作，在SP一次前向和后向总共有4次<code>all-gather</code>和4次<code>reduce-scatter</code>操作。<br><code>ring all-reduce</code> 执行过程中有两步，先是一个<code>reduce-scatter</code>然后一个<code>all-gather</code>，SP没有引入更多的通信代价。</p>",1),(0,t.Lk)("p",{class:"katex-block"},[(0,t.Lk)("span",{class:"katex-display"},[(0,t.Lk)("span",{class:"katex"},[(0,t.Lk)("span",{class:"katex-mathml"},[(0,t.Lk)("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[(0,t.Lk)("semantics",null,[(0,t.Lk)("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"A"),(0,t.Lk)("mi",null,"c"),(0,t.Lk)("mi",null,"t"),(0,t.Lk)("mi",null,"i"),(0,t.Lk)("mi",null,"v"),(0,t.Lk)("mi",null,"a"),(0,t.Lk)("mi",null,"t"),(0,t.Lk)("mi",null,"i"),(0,t.Lk)("mi",null,"o"),(0,t.Lk)("mi",null,"n"),(0,t.Lk)("mi",null,"M"),(0,t.Lk)("mi",null,"e"),(0,t.Lk)("mi",null,"m"),(0,t.Lk)("mi",null,"o"),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mi",null,"y"),(0,t.Lk)("mi",null,"P"),(0,t.Lk)("mi",null,"e"),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mi",null,"L"),(0,t.Lk)("mi",null,"a"),(0,t.Lk)("mi",null,"y"),(0,t.Lk)("mi",null,"e"),(0,t.Lk)("mi",null,"r")])])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mi",null,"s"),(0,t.Lk)("mi",null,"b"),(0,t.Lk)("mi",null,"h"),(0,t.Lk)("mrow",null,[(0,t.Lk)("mo",{fence:"true"},"("),(0,t.Lk)("mfrac",null,[(0,t.Lk)("mn",null,"10"),(0,t.Lk)("mi",null,"t")]),(0,t.Lk)("mo",null,"+"),(0,t.Lk)("mfrac",null,[(0,t.Lk)("mn",null,"24"),(0,t.Lk)("mi",null,"t")]),(0,t.Lk)("mo",null,"+"),(0,t.Lk)("mn",null,"5"),(0,t.Lk)("mfrac",null,[(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"a"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"h"),(0,t.Lk)("mi",null,"t")])]),(0,t.Lk)("mo",{fence:"true"},")")])])])])]),(0,t.Lk)("mtr",null,[(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow")])]),(0,t.Lk)("mtd",null,[(0,t.Lk)("mstyle",{scriptlevel:"0",displaystyle:"true"},[(0,t.Lk)("mrow",null,[(0,t.Lk)("mrow"),(0,t.Lk)("mo",null,"="),(0,t.Lk)("mfrac",null,[(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"s"),(0,t.Lk)("mi",null,"b"),(0,t.Lk)("mi",null,"h")]),(0,t.Lk)("mi",null,"t")]),(0,t.Lk)("mrow",null,[(0,t.Lk)("mo",{fence:"true"},"("),(0,t.Lk)("mn",null,"34"),(0,t.Lk)("mo",null,"+"),(0,t.Lk)("mn",null,"5"),(0,t.Lk)("mfrac",null,[(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"a"),(0,t.Lk)("mi",null,"s")]),(0,t.Lk)("mi",null,"h")]),(0,t.Lk)("mo",{fence:"true"},")")])])])])])]),(0,t.Lk)("annotation",{encoding:"application/x-tex"}," \\begin{aligned} ActivationMemoryPerLayer& =sbh\\left(\\frac{10}t+\\frac{24}t+5\\frac{as}{ht}\\right) \\\\ &=\\frac{sbh}t\\left(34+5\\frac{as}h\\right) \\end{aligned}")])])]),(0,t.Lk)("span",{class:"katex-html","aria-hidden":"true"},[(0,t.Lk)("span",{class:"base"},[(0,t.Lk)("span",{class:"strut",style:{height:"5.0575em","vertical-align":"-2.2787em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mtable"},[(0,t.Lk)("span",{class:"col-align-r"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"2.7787em"}},[(0,t.Lk)("span",{style:{top:"-4.7787em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.45em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"A"),(0,t.Lk)("span",{class:"mord mathnormal"},"c"),(0,t.Lk)("span",{class:"mord mathnormal"},"t"),(0,t.Lk)("span",{class:"mord mathnormal"},"i"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),(0,t.Lk)("span",{class:"mord mathnormal"},"a"),(0,t.Lk)("span",{class:"mord mathnormal"},"t"),(0,t.Lk)("span",{class:"mord mathnormal"},"i"),(0,t.Lk)("span",{class:"mord mathnormal"},"o"),(0,t.Lk)("span",{class:"mord mathnormal"},"n"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"M"),(0,t.Lk)("span",{class:"mord mathnormal"},"e"),(0,t.Lk)("span",{class:"mord mathnormal"},"m"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"ory"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"er"),(0,t.Lk)("span",{class:"mord mathnormal"},"L"),(0,t.Lk)("span",{class:"mord mathnormal"},"a"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"yer")])]),(0,t.Lk)("span",{style:{top:"-2.1573em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.45em"}}),(0,t.Lk)("span",{class:"mord"})])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"2.2787em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"col-align-l"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"2.7787em"}},[(0,t.Lk)("span",{style:{top:"-4.7787em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.45em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord mathnormal"},"s"),(0,t.Lk)("span",{class:"mord mathnormal"},"bh"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"minner"},[(0,t.Lk)("span",{class:"mopen delimcenter",style:{top:"0em"}},[(0,t.Lk)("span",{class:"delimsizing size3"},"(")]),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen nulldelimiter"}),(0,t.Lk)("span",{class:"mfrac"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.3214em"}},[(0,t.Lk)("span",{style:{top:"-2.314em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"t")])]),(0,t.Lk)("span",{style:{top:"-3.23em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),(0,t.Lk)("span",{style:{top:"-3.677em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"},"10")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.686em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"mclose nulldelimiter"})]),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mbin"},"+"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen nulldelimiter"}),(0,t.Lk)("span",{class:"mfrac"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.3214em"}},[(0,t.Lk)("span",{style:{top:"-2.314em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"t")])]),(0,t.Lk)("span",{style:{top:"-3.23em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),(0,t.Lk)("span",{style:{top:"-3.677em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"},"24")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.686em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"mclose nulldelimiter"})]),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mbin"},"+"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mord"},"5"),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen nulldelimiter"}),(0,t.Lk)("span",{class:"mfrac"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.1076em"}},[(0,t.Lk)("span",{style:{top:"-2.314em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"h"),(0,t.Lk)("span",{class:"mord mathnormal"},"t")])]),(0,t.Lk)("span",{style:{top:"-3.23em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),(0,t.Lk)("span",{style:{top:"-3.677em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"a"),(0,t.Lk)("span",{class:"mord mathnormal"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.686em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"mclose nulldelimiter"})]),(0,t.Lk)("span",{class:"mclose delimcenter",style:{top:"0em"}},[(0,t.Lk)("span",{class:"delimsizing size3"},")")])])])]),(0,t.Lk)("span",{style:{top:"-2.1573em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3.45em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord"}),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mrel"},"="),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen nulldelimiter"}),(0,t.Lk)("span",{class:"mfrac"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.3714em"}},[(0,t.Lk)("span",{style:{top:"-2.314em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"t")])]),(0,t.Lk)("span",{style:{top:"-3.23em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),(0,t.Lk)("span",{style:{top:"-3.677em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"s"),(0,t.Lk)("span",{class:"mord mathnormal"},"bh")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.686em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"mclose nulldelimiter"})]),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"minner"},[(0,t.Lk)("span",{class:"mopen delimcenter",style:{top:"0em"}},[(0,t.Lk)("span",{class:"delimsizing size2"},"(")]),(0,t.Lk)("span",{class:"mord"},"34"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mbin"},"+"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mord"},"5"),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mopen nulldelimiter"}),(0,t.Lk)("span",{class:"mfrac"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.1076em"}},[(0,t.Lk)("span",{style:{top:"-2.314em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"h")])]),(0,t.Lk)("span",{style:{top:"-3.23em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),(0,t.Lk)("span",{style:{top:"-3.677em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"a"),(0,t.Lk)("span",{class:"mord mathnormal"},"s")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.686em"}},[(0,t.Lk)("span")])])])]),(0,t.Lk)("span",{class:"mclose nulldelimiter"})]),(0,t.Lk)("span",{class:"mclose delimcenter",style:{top:"0em"}},[(0,t.Lk)("span",{class:"delimsizing size2"},")")])])])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"2.2787em"}},[(0,t.Lk)("span")])])])])])])])])])])],-1),(0,t.Fv)('<h3 id="deepspeed-ulysses" tabindex="-1"><a class="header-anchor" href="#deepspeed-ulysses"><span>DeepSpeed-Ulysses</span></a></h3><p><code>DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models</code><br><code>https://arxiv.org/pdf/2309.14509</code></p><blockquote><p>DeepSpeed在知乎也有官号, 这里仅作简述, 官号本身讲的也非常不错, 链接在这儿:https://zhuanlan.zhihu.com/p/652206513</p></blockquote><h4 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h4><ul><li>长序列在LLM应用中非常重要, 长上下文的保存有助于LLM推理, 需求大token和长Sequence的输入</li><li>现有的DP TP PP不能解决序列维度的扩展问题</li><li>现有的序列并行方法依托内存通讯, 不够高效</li></ul><p>DeepSpeed-Ulysses将各个样本在<code>序列维度</code>上分割给参与的GPU。在attention计算之前，它对已分割的查询(Q)、键(K)和值(V)执行<code>all-to-all</code>通信操作，以使每个GPU接收完整的序列，但仅用于注意力头的<code>非重叠子集</code>。<br> 这使得参与的GPU可以并行计算不同的注意力头。最后，DeepSpeed-Ulysses还使用另一个<code>all-to-all</code>来在注意力头上收集结果，同时重新在序列维度上进行分区。</p><h4 id="deepspeed-ulysses的核心设计" tabindex="-1"><a class="header-anchor" href="#deepspeed-ulysses的核心设计"><span>DeepSpeed-Ulysses的核心设计</span></a></h4><p><img src="'+g+'" alt="Transformer设计"></p><p><img src="'+k+'" alt="Ulysses设计"></p><p>与已知的Transformer架构一样，设计由<code>N个输入序列</code>在<code>P个可用设备</code>上分区组成。每个本地N/P分区都被投影到查询（Q）、键（K）和值（V）嵌入中。接下来，(QKV) 嵌入通过参与计算设备之间的高度优化的全对全集合（all-to-all collectives）进行全局的 QKV 收集。在全对全集合后，每个头的注意力计算形式为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mtext> </mtext><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mtext> </mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex"> Output~context=Softmax~(\\frac{QK^T}{\\sqrt{d}})V </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace nobreak"> </span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mspace nobreak"> </span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.1778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">d</span></span></span><span style="top:-2.8922em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p><p>注意力计算后，另一个全对全集合将注意力计算的输出上下文张量转换为序列(N/P)并行，用于Transformer模型层的剩余模块中的后续操作。</p><h3 id="sequence-parallelism" tabindex="-1"><a class="header-anchor" href="#sequence-parallelism"><span>Sequence Parallelism</span></a></h3><p><code>Sequence Parallelism: Long Sequence Training from System Perspective</code><br><code>https://arxiv.org/pdf/2105.13120</code></p><h4 id="论文背景" tabindex="-1"><a class="header-anchor" href="#论文背景"><span>论文背景</span></a></h4><p>和Ulysses一样, 这个SP也是目的也是解决输入序列规模问题, 而不是像Megtron-LM一样解决计算过程中的内存占用问题.</p><p>文章将自己的SP流程和PP TP模型做了比较:<br><img src="'+d+'" alt="SP模型示意"></p><h4 id="主要工作" tabindex="-1"><a class="header-anchor" href="#主要工作"><span>主要工作</span></a></h4><p>本文认为SP最主要的问题是跨设备如何计算<code>sub-sequences</code>的<code>attention scores</code>问题，为了解决该问题，本文设计出<code>Ring Self-Attention</code>来解决此问题.</p><blockquote><p>感觉想法来源于Ring-AllReduce, 而且只优化了自注意力部分</p></blockquote><p><img src="'+L+'" alt="RSA做法"></p><blockquote><p>RSA感觉就是将输入序列进行切分, 通过将序列整体切分成小的chunk, 使得每一个chunk都尽可能大, 用commnication换取序列长度</p></blockquote><p><img src="'+u+'" alt="RSA过程示例图"></p><h3 id="ring-attention" tabindex="-1"><a class="header-anchor" href="#ring-attention"><span>Ring-Attention</span></a></h3><p><code>Ring Attention with Blockwise Transformers for Near-Infinite Context</code><br><code>https://arxiv.org/pdf/2310.01889</code></p><h4 id="背景" tabindex="-1"><a class="header-anchor" href="#背景"><span>背景</span></a></h4><p>老生常谈的transformer长序列要求，不做赘述。</p><h4 id="ring-attention-1" tabindex="-1"><a class="header-anchor" href="#ring-attention-1"><span>Ring Attention</span></a></h4><p>本文提出以<code>分块方式</code>执行Self-Attention和FWD计算，多机分布序列维度，从而实现并发计算和通信.<br> 由于该方法将环中主机设备之间的<code>Key Value Block</code>通信与compute重叠，因此将其命名：<code>环注意(Ring Attention)</code></p><p>具体实现：</p><p><img src="'+v+'" alt="RA示意图"></p><p>该方法在主机设备之间构建Self-Attention的外循环，每个主机设备具有一个<code>query block</code>，并通过<code>Key Value Block</code>遍历主机<code>Ring</code>，以<code>逐块</code>的方式进行注意力和前馈网络计算。<br> 当计算Self-Attention时，每个主机将<code>Key Value Block</code>发送到下一个主机，同时从前一个主机接收<code>Key Value Block</code>。</p><p><img src="'+y+'" alt="RA流程图"></p><p>对于内循环，每个设备计算其各自的Self-Attention和FWD。在内循环期间，每个设备将用于compute的<code>Key Value Block</code>的副本发送到Ring中的下一个设备，同时从前一个设备接收<code>Key Value Block</code>。<br> 由于<code>块计算比块传输需要更长的时间</code>，与标准Transformer相比，此过程不会增加开销。</p><blockquote><p>这种Ring Attention方式可以突破序列长度限制（对于单卡内存需求来说，而非模型整体来说），因为我们在Attention之前矩阵乘就已经切分了Squence，让每一个卡分批成环去跑一小批token</p><p>这种方式理论上并不影响训练结果，因为最小训练单位还是一个token（对Squence做切分时的原则）</p><p>天才般的想法！（我觉得）好吧也需要堆卡出奇迹</p></blockquote><blockquote><p>那么代价呢？ 文章的训练测试规模比较小，能否在大规模训练时取得想象中的线性效果，还是未知数 文章只对Attention和FWD操作做了优化，基础操作还有进一步优化的空间，可以考虑采用4D并行。</p></blockquote><h3 id="distflashattn" tabindex="-1"><a class="header-anchor" href="#distflashattn"><span>DISTFLASHATTN</span></a></h3><p><code>https://arxiv.org/pdf/2310.03294</code></p><h4 id="背景-1" tabindex="-1"><a class="header-anchor" href="#背景-1"><span>背景</span></a></h4><p>部分SP方法，如Ring Attention缺少高效的Attention实现。（前文提及的<code>基础操作还有进一步优化的空间</code>）</p><h4 id="论文方法" tabindex="-1"><a class="header-anchor" href="#论文方法"><span>论文方法</span></a></h4><p>文章针对三个challenge提出了三个解决方法，解决了高校Attention实现、分布式应用等问题。</p><h5 id="token-level-workload-imbalance" tabindex="-1"><a class="header-anchor" href="#token-level-workload-imbalance"><span>token-level workload imbalance</span></a></h5><p>这主要是由于causal mask引起的attention计算问题，如果简单分块计算约会有1/2的计算资源浪费。<br> 因为一般causal mask就是会用矩阵以对角线为界mask数据, 按照ring拓扑结构进行计算也会有约一半的CPU处于等待状态。</p><p>针对这个问题，论文中提出<code>Token-level workload balancing</code>的调度算法，通过给空闲的worker来fetch部分key-value数据，计算后再传递回去。</p><p><img src="'+b+'" alt="CHA1"></p><h5 id="prohibitive-communication-overhead" tabindex="-1"><a class="header-anchor" href="#prohibitive-communication-overhead"><span>Prohibitive communication overhead</span></a></h5>',47),(0,t.Lk)("p",null,[(0,t.eW)("需要通信汇总不同worker上的attention结果，本文提出通过计算"),(0,t.Lk)("span",{class:"katex"},[(0,t.Lk)("span",{class:"katex-mathml"},[(0,t.Lk)("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[(0,t.Lk)("semantics",null,[(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"a"),(0,t.Lk)("mi",null,"t"),(0,t.Lk)("mi",null,"t"),(0,t.Lk)("mi",null,"n"),(0,t.Lk)("mo",{stretchy:"false"},"("),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"q"),(0,t.Lk)("mi",null,"p")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"k"),(0,t.Lk)("mi",null,"r")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"v"),(0,t.Lk)("mi",null,"r")]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"s"),(0,t.Lk)("mi",null,"p")]),(0,t.Lk)("mo",{stretchy:"false"},")")]),(0,t.Lk)("annotation",{encoding:"application/x-tex"},"attn(q_p,k_r,v_r,s_p)")])])]),(0,t.Lk)("span",{class:"katex-html","aria-hidden":"true"},[(0,t.Lk)("span",{class:"base"},[(0,t.Lk)("span",{class:"strut",style:{height:"1.0361em","vertical-align":"-0.2861em"}}),(0,t.Lk)("span",{class:"mord mathnormal"},"a"),(0,t.Lk)("span",{class:"mord mathnormal"},"tt"),(0,t.Lk)("span",{class:"mord mathnormal"},"n"),(0,t.Lk)("span",{class:"mopen"},"("),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.1514em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"p")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.2861em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.1514em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.0315em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.15em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.1514em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.15em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct"},","),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mord mathnormal"},"s"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.1514em"}},[(0,t.Lk)("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.7em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight"},"p")])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.2861em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mclose"},")")])])]),(0,t.eW)(" prefetch张量来完成通信"),(0,t.Lk)("span",{class:"katex"},[(0,t.Lk)("span",{class:"katex-mathml"},[(0,t.Lk)("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[(0,t.Lk)("semantics",null,[(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"w"),(0,t.Lk)("mi",null,"o"),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mi",null,"k"),(0,t.Lk)("mi",null,"e"),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mspace",{width:"1em"}),(0,t.Lk)("mi",null,"p"),(0,t.Lk)("mi",null,[(0,t.Lk)("mover",null,[(0,t.Lk)("mo",null,[(0,t.Lk)("mi",{mathvariant:"normal"},"⟵"),(0,t.Lk)("mo",null,"⁡")]),(0,t.Lk)("mrow",null,[(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"k"),(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mo",null,"+"),(0,t.Lk)("mn",null,"1")])]),(0,t.Lk)("mo",{separator:"true"},","),(0,t.Lk)("msub",null,[(0,t.Lk)("mi",null,"v"),(0,t.Lk)("mrow",null,[(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mo",null,"+"),(0,t.Lk)("mn",null,"1")])])])])]),(0,t.Lk)("mi",null,"w"),(0,t.Lk)("mi",null,"o"),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mi",null,"k"),(0,t.Lk)("mi",null,"e"),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mspace",{width:"1em"}),(0,t.Lk)("mi",null,"r"),(0,t.Lk)("mo",null,"+"),(0,t.Lk)("mn",null,"1")]),(0,t.Lk)("annotation",{encoding:"application/x-tex"},"worker\\quad p\\overset{k_{r+1},v_{r+1}}{\\operatorname*{\\longleftarrow}}worker\\quad r+1")])])]),(0,t.Lk)("span",{class:"katex-html","aria-hidden":"true"},[(0,t.Lk)("span",{class:"base"},[(0,t.Lk)("span",{class:"strut",style:{height:"1.5443em","vertical-align":"-0.1944em"}}),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"er"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"1em"}}),(0,t.Lk)("span",{class:"mord mathnormal"},"p"),(0,t.Lk)("span",{class:"mord"},[(0,t.Lk)("span",{class:"mop op-limits"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"1.3499em"}},[(0,t.Lk)("span",{style:{top:"-3em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",null,[(0,t.Lk)("span",{class:"mop"},[(0,t.Lk)("span",{class:"mop"},[(0,t.Lk)("span",{class:"mord mathrm"},"⟵")])])])]),(0,t.Lk)("span",{style:{top:"-3.7638em","margin-left":"0em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"3em"}}),(0,t.Lk)("span",{class:"sizing reset-size6 size3 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},[(0,t.Lk)("span",{class:"mord mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.3173em"}},[(0,t.Lk)("span",{style:{top:"-2.357em","margin-left":"-0.0315em","margin-right":"0.0714em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.5em"}}),(0,t.Lk)("span",{class:"sizing reset-size3 size1 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r"),(0,t.Lk)("span",{class:"mbin mtight"},"+"),(0,t.Lk)("span",{class:"mord mtight"},"1")])])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.2025em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mpunct mtight"},","),(0,t.Lk)("span",{class:"mord mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"v"),(0,t.Lk)("span",{class:"msupsub"},[(0,t.Lk)("span",{class:"vlist-t vlist-t2"},[(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.3173em"}},[(0,t.Lk)("span",{style:{top:"-2.357em","margin-left":"-0.0359em","margin-right":"0.0714em"}},[(0,t.Lk)("span",{class:"pstrut",style:{height:"2.5em"}}),(0,t.Lk)("span",{class:"sizing reset-size3 size1 mtight"},[(0,t.Lk)("span",{class:"mord mtight"},[(0,t.Lk)("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r"),(0,t.Lk)("span",{class:"mbin mtight"},"+"),(0,t.Lk)("span",{class:"mord mtight"},"1")])])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.2025em"}},[(0,t.Lk)("span")])])])])])])])])]),(0,t.Lk)("span",{class:"vlist-s"},"​")]),(0,t.Lk)("span",{class:"vlist-r"},[(0,t.Lk)("span",{class:"vlist",style:{height:"0.011em"}},[(0,t.Lk)("span")])])])])]),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"er"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"1em"}}),(0,t.Lk)("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),(0,t.Lk)("span",{class:"mbin"},"+"),(0,t.Lk)("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),(0,t.Lk)("span",{class:"base"},[(0,t.Lk)("span",{class:"strut",style:{height:"0.6444em"}}),(0,t.Lk)("span",{class:"mord"},"1")])])]),(0,t.eW)("的覆盖，实现依赖于P2P的通信模式。")],-1),(0,t.Fv)('<p><img src="'+w+'" alt="CHA2"></p><h4 id="loadbalanced-scheduling-with-communication-and-computation-overlap" tabindex="-1"><a class="header-anchor" href="#loadbalanced-scheduling-with-communication-and-computation-overlap"><span>Loadbalanced scheduling with communication and computation overlap</span></a></h4><p>huggingface中采用的Recomputation的检查点放置不合理，导致相对高的还原计算代价。<br> 下面是两种重计算策略的对比：<br><img src="'+x+'" alt="CHA3"></p><p>DFA相较HF每一个<code>FlashAttention</code>+<code>FFN</code>约能够减少一个FA的计算量。<br><code>FlashAttention</code>部分的梯度更新为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi>Q</mi><mi>V</mi></mrow><annotation encoding="application/x-tex">K Q V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">Q</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>三个矩阵，可以通过FA的输出结果完成更新，因此保存FA的结果便可计算三者的矩阵。</p><h3 id="典型并行方式时序图" tabindex="-1"><a class="header-anchor" href="#典型并行方式时序图"><span>典型并行方式时序图</span></a></h3><h4 id="tp" tabindex="-1"><a class="header-anchor" href="#tp"><span>TP</span></a></h4><div class="language-sequencediagram line-numbers-mode" data-highlighter="shiki" data-ext="sequencediagram" data-title="sequencediagram" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span></span></span>\n<span class="line"><span>    %% 定义参与者</span></span>\n<span class="line"><span>    participant CPU as 主机 CPU</span></span>\n<span class="line"><span>    participant P0 as GPU 0</span></span>\n<span class="line"><span>    participant P1 as GPU 1</span></span>\n<span class="line"><span>    participant P2 as GPU 2</span></span>\n<span class="line"><span>    participant P3 as GPU 3</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 初始化阶段</span></span>\n<span class="line"><span>    note over CPU,P3: 初始化阶段</span></span>\n<span class="line"><span>    rect rgba(235, 235, 235, 0.5)</span></span>\n<span class="line"><span>        CPU-&gt;&gt;P0: 加载并分割模型参数</span></span>\n<span class="line"><span>        CPU-&gt;&gt;P1: 加载并分割模型参数</span></span>\n<span class="line"><span>        CPU-&gt;&gt;P2: 加载并分割模型参数</span></span>\n<span class="line"><span>        CPU-&gt;&gt;P3: 加载并分割模型参数</span></span>\n<span class="line"><span>        P0-&gt;&gt;P0: 初始化本地张量部分</span></span>\n<span class="line"><span>        P1-&gt;&gt;P1: 初始化本地张量部分</span></span>\n<span class="line"><span>        P2-&gt;&gt;P2: 初始化本地张量部分</span></span>\n<span class="line"><span>        P3-&gt;&gt;P3: 初始化本地张量部分</span></span>\n<span class="line"><span>    end</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 前向传播阶段</span></span>\n<span class="line"><span>    note over CPU,P3: 前向传播阶段</span></span>\n<span class="line"><span>    rect rgba(215, 235, 255, 0.5)</span></span>\n<span class="line"><span>        P0-&gt;&gt;P1: 发送激活值 (All-Gather)</span></span>\n<span class="line"><span>        P1-&gt;&gt;P2: 发送激活值 (All-Gather)</span></span>\n<span class="line"><span>        P2-&gt;&gt;P3: 发送激活值 (All-Gather)</span></span>\n<span class="line"><span>        P3-&gt;&gt;P0: 发送激活值 (All-Gather)</span></span>\n<span class="line"><span>        par</span></span>\n<span class="line"><span>            P0-&gt;&gt;P0: 计算本地张量部分</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P1-&gt;&gt;P1: 计算本地张量部分</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P2-&gt;&gt;P2: 计算本地张量部分</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P3-&gt;&gt;P3: 计算本地张量部分</span></span>\n<span class="line"><span>        end</span></span>\n<span class="line"><span>        P0-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class="line"><span>        P1-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class="line"><span>        P2-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class="line"><span>        P3-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class="line"><span>    end</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 反向传播阶段</span></span>\n<span class="line"><span>    note over CPU,P3: 反向传播阶段</span></span>\n<span class="line"><span>    rect rgba(235, 215, 235, 0.5)</span></span>\n<span class="line"><span>        P0-&gt;&gt;P1: 发送梯度 (All-Reduce)</span></span>\n<span class="line"><span>        P1-&gt;&gt;P2: 发送梯度 (All-Reduce)</span></span>\n<span class="line"><span>        P2-&gt;&gt;P3: 发送梯度 (All-Reduce)</span></span>\n<span class="line"><span>        P3-&gt;&gt;P0: 发送梯度 (All-Reduce)</span></span>\n<span class="line"><span>        par</span></span>\n<span class="line"><span>            P0-&gt;&gt;P0: 计算本地梯度</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P1-&gt;&gt;P1: 计算本地梯度</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P2-&gt;&gt;P2: 计算本地梯度</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P3-&gt;&gt;P3: 计算本地梯度</span></span>\n<span class="line"><span>        end</span></span>\n<span class="line"><span>        P0-&gt;&gt;CPU: 存储梯度</span></span>\n<span class="line"><span>        P1-&gt;&gt;CPU: 存储梯度</span></span>\n<span class="line"><span>        P2-&gt;&gt;CPU: 存储梯度</span></span>\n<span class="line"><span>        P3-&gt;&gt;CPU: 存储梯度</span></span>\n<span class="line"><span>    end</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 参数更新阶段</span></span>\n<span class="line"><span>    note over CPU,P3: 参数更新阶段</span></span>\n<span class="line"><span>    rect rgba(215, 255, 215, 0.5)</span></span>\n<span class="line"><span>        par</span></span>\n<span class="line"><span>            P0-&gt;&gt;P0: 更新本地参数</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P1-&gt;&gt;P1: 更新本地参数</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P2-&gt;&gt;P2: 更新本地参数</span></span>\n<span class="line"><span>            and</span></span>\n<span class="line"><span>            P3-&gt;&gt;P3: 更新本地参数</span></span>\n<span class="line"><span>        end</span></span>\n<span class="line"><span>        P0-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class="line"><span>        P1-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class="line"><span>        P2-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class="line"><span>        P3-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class="line"><span>    end</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="dp" tabindex="-1"><a class="header-anchor" href="#dp"><span>DP</span></a></h4><div class="language-sequencediagram line-numbers-mode" data-highlighter="shiki" data-ext="sequencediagram" data-title="sequencediagram" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span></span></span>\n<span class="line"><span>    participant Server</span></span>\n<span class="line"><span>    participant Worker1</span></span>\n<span class="line"><span>    participant Worker2</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    Server-&gt;&gt;Worker1: 分发第k-1个batch数据</span></span>\n<span class="line"><span>    Server-&gt;&gt;Worker2: 分发第k-1个batch数据</span></span>\n<span class="line"><span>    Worker1-&gt;&gt;Worker1: 第k-1个batch FWD</span></span>\n<span class="line"><span>    Worker2-&gt;&gt;Worker2: 第k-1个batch FWD</span></span>\n<span class="line"><span>    Worker1-&gt;&gt;Worker1: 第k-1个batch BWD</span></span>\n<span class="line"><span>    Worker2-&gt;&gt;Worker2: 第k-1个batch BWD</span></span>\n<span class="line"><span>    Worker1--&gt;&gt;Server: 返回第k-1个batch梯度</span></span>\n<span class="line"><span>    Worker2--&gt;&gt;Server: 返回第k-1个batch梯度</span></span>\n<span class="line"><span>    Server-&gt;&gt;Server: 第k-1个batch AllReduce操作</span></span>\n<span class="line"><span>    Server-&gt;&gt;Server: 更新第k-1个batch参数</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    Server-&gt;&gt;Worker1: 分发第k个batch数据</span></span>\n<span class="line"><span>    Server-&gt;&gt;Worker2: 分发第k个batch数据</span></span>\n<span class="line"><span>    Worker1-&gt;&gt;Worker1: 第k个batch FWD</span></span>\n<span class="line"><span>    Worker2-&gt;&gt;Worker2: 第k个batch FWD</span></span>\n<span class="line"><span>    Worker1-&gt;&gt;Worker1: 第k个batch BWD</span></span>\n<span class="line"><span>    Worker2-&gt;&gt;Worker2: 第k个batch BWD</span></span>\n<span class="line"><span>    Worker1--&gt;&gt;Server: 返回第k个batch梯度</span></span>\n<span class="line"><span>    Worker2--&gt;&gt;Server: 返回第k个batch梯度</span></span>\n<span class="line"><span>    Server-&gt;&gt;Server: 第k个batch AllReduce操作</span></span>\n<span class="line"><span>    Server-&gt;&gt;Server: 更新第k个batch参数</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    Server-&gt;&gt;Worker1: 分发第k+1个batch数据</span></span>\n<span class="line"><span>    Server-&gt;&gt;Worker2: 分发第k+1个batch数据</span></span>\n<span class="line"><span>    Worker1-&gt;&gt;Worker1: 第k+1个batch FWD</span></span>\n<span class="line"><span>    Worker2-&gt;&gt;Worker2: 第k+1个batch FWD</span></span>\n<span class="line"><span>    Worker1-&gt;&gt;Worker1: 第k+1个batch BWD</span></span>\n<span class="line"><span>    Worker2-&gt;&gt;Worker2: 第k+1个batch BWD</span></span>\n<span class="line"><span>    Worker1--&gt;&gt;Server: 返回第k+1个batch梯度</span></span>\n<span class="line"><span>    Worker2--&gt;&gt;Server: 返回第k+1个batch梯度</span></span>\n<span class="line"><span>    Server-&gt;&gt;Server: 第k+1个batch AllReduce操作</span></span>\n<span class="line"><span>    Server-&gt;&gt;Server: 更新第k+1个batch参数</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="pp" tabindex="-1"><a class="header-anchor" href="#pp"><span>PP</span></a></h4><div class="language-sequencediagram line-numbers-mode" data-highlighter="shiki" data-ext="sequencediagram" data-title="sequencediagram" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span></span></span>\n<span class="line"><span>    participant Client</span></span>\n<span class="line"><span>    participant Splitter</span></span>\n<span class="line"><span>    participant Stage1</span></span>\n<span class="line"><span>    participant Stage2</span></span>\n<span class="line"><span>    participant Stage3</span></span>\n<span class="line"><span>    participant Aggregator</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    Client-&gt;&gt;Splitter: 分割为微批次</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 微批次1 前向传播</span></span>\n<span class="line"><span>    Splitter-&gt;&gt;Stage1: 微批次1 FWD</span></span>\n<span class="line"><span>    activate Stage1</span></span>\n<span class="line"><span>    Stage1-&gt;&gt;Stage2: 微批次1 FWD</span></span>\n<span class="line"><span>    activate Stage2</span></span>\n<span class="line"><span>    Stage2-&gt;&gt;Stage3: 微批次1 FWD</span></span>\n<span class="line"><span>    activate Stage3</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 微批次2 前向传播（稍后开始）</span></span>\n<span class="line"><span>    Splitter-&gt;&gt;Stage1: 微批次2 FWD</span></span>\n<span class="line"><span>    Stage1-&gt;&gt;Stage2: 微批次2 FWD</span></span>\n<span class="line"><span>    Stage2-&gt;&gt;Stage3: 微批次2 FWD</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 微批次1 反向传播</span></span>\n<span class="line"><span>    Stage3--&gt;&gt;Stage2: 微批次1 BWD</span></span>\n<span class="line"><span>    deactivate Stage3</span></span>\n<span class="line"><span>    Stage2--&gt;&gt;Stage1: 微批次1 BWD</span></span>\n<span class="line"><span>    deactivate Stage2</span></span>\n<span class="line"><span>    Stage1-&gt;&gt;Aggregator: 微批次1 梯度</span></span>\n<span class="line"><span>    deactivate Stage1</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 微批次3 前向传播（再次稍后开始）</span></span>\n<span class="line"><span>    Splitter-&gt;&gt;Stage1: 微批次3 FWD</span></span>\n<span class="line"><span>    activate Stage1</span></span>\n<span class="line"><span>    Stage1-&gt;&gt;Stage2: 微批次3 FWD</span></span>\n<span class="line"><span>    activate Stage2</span></span>\n<span class="line"><span>    Stage2-&gt;&gt;Stage3: 微批次3 FWD</span></span>\n<span class="line"><span>    activate Stage3</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 微批次2 反向传播</span></span>\n<span class="line"><span>    Stage3--&gt;&gt;Stage2: 微批次2 BWD</span></span>\n<span class="line"><span>    Stage2--&gt;&gt;Stage1: 微批次2 BWD</span></span>\n<span class="line"><span>    Stage1-&gt;&gt;Aggregator: 微批次2 梯度</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    %% 微批次3 反向传播</span></span>\n<span class="line"><span>    Stage3--&gt;&gt;Stage2: 微批次3 BWD</span></span>\n<span class="line"><span>    deactivate Stage3</span></span>\n<span class="line"><span>    Stage2--&gt;&gt;Stage1: 微批次3 BWD</span></span>\n<span class="line"><span>    deactivate Stage2</span></span>\n<span class="line"><span>    Stage1-&gt;&gt;Aggregator: 微批次3 梯度</span></span>\n<span class="line"><span>    deactivate Stage1</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>    Aggregator--&gt;&gt;Client: 汇总训练结果</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>',11)]))}]]),M=JSON.parse('{"path":"/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%88%E9%80%89%E8%AF%BB).html","title":"AISys_分布式开发（选读）","lang":"zh-CN","frontmatter":{"title":"AISys_分布式开发（选读）","date":"2024-10-28T00:00:00.000Z","category":["SOSD"],"tag":["分布式系统","AISys","并行运算"],"sticky":true,"star":true,"order":-1.3,"description":"序列并行 Megatron Reducing Activation Recomputation in Large Transformer Models https://arxiv.org/pdf/2205.05198 Abstract 在大模型训练过程中显存占用过大往往成为瓶颈，一般会通过重计算的方式降低显存占用，但会带来额外的计算代价。本文提出seq...","head":[["meta",{"property":"og:url","content":"https://newzone.top/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%88%E9%80%89%E8%AF%BB).html"}],["meta",{"property":"og:site_name","content":"CS_Blog"}],["meta",{"property":"og:title","content":"AISys_分布式开发（选读）"}],["meta",{"property":"og:description","content":"序列并行 Megatron Reducing Activation Recomputation in Large Transformer Models https://arxiv.org/pdf/2205.05198 Abstract 在大模型训练过程中显存占用过大往往成为瓶颈，一般会通过重计算的方式降低显存占用，但会带来额外的计算代价。本文提出seq..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-11-28T10:26:35.000Z"}],["meta",{"property":"article:tag","content":"分布式系统"}],["meta",{"property":"article:tag","content":"AISys"}],["meta",{"property":"article:tag","content":"并行运算"}],["meta",{"property":"article:published_time","content":"2024-10-28T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-11-28T10:26:35.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AISys_分布式开发（选读）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-10-28T00:00:00.000Z\\",\\"dateModified\\":\\"2024-11-28T10:26:35.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"序列并行","slug":"序列并行","link":"#序列并行","children":[{"level":3,"title":"Megatron","slug":"megatron","link":"#megatron","children":[]},{"level":3,"title":"DeepSpeed-Ulysses","slug":"deepspeed-ulysses","link":"#deepspeed-ulysses","children":[]},{"level":3,"title":"Sequence Parallelism","slug":"sequence-parallelism","link":"#sequence-parallelism","children":[]},{"level":3,"title":"Ring-Attention","slug":"ring-attention","link":"#ring-attention","children":[]},{"level":3,"title":"DISTFLASHATTN","slug":"distflashattn","link":"#distflashattn","children":[]},{"level":3,"title":"典型并行方式时序图","slug":"典型并行方式时序图","link":"#典型并行方式时序图","children":[]}]}],"git":{"createdTime":1732702791000,"updatedTime":1732789595000,"contributors":[{"name":"YuanaHao","email":"youthandqueen@qq.com","commits":2},{"name":"youth00000000","email":"youthandqueen@qq.com","commits":1}]},"readingTime":{"minutes":14.01,"words":4204},"filePathRelative":"_posts/AISys_分布式（选读).md","localizedDate":"2024年10月28日","excerpt":"<h2>序列并行</h2>\\n<h3>Megatron</h3>\\n<p>Reducing Activation Recomputation in Large Transformer Models</p>\\n<p><code>https://arxiv.org/pdf/2205.05198</code></p>\\n<h4>Abstract</h4>\\n<p>在大模型训练过程中显存占用过大往往成为瓶颈，一般会通过<code>重计算</code>的方式降低显存占用，但会带来额外的计算代价。本文提出<code>sequece parallel(序列并行,简称SP)</code>和<code>selective activation recomputation</code>两种方法，可以结合TP有效减少不必要的计算量。</p>","autoDesc":true}')}}]);