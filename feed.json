{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "CS_Blog",
  "home_page_url": "https://newzone.top/",
  "feed_url": "https://newzone.top/feed.json",
  "description": "算法学习, 计算机公开课博客分享平台。",
  "favicon": "https://newzone.top/favicon.ico",
  "items": [
    {
      "title": "AISys_分布式开发",
      "url": "https://newzone.top/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F.html",
      "id": "https://newzone.top/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F.html",
      "summary": "为什么AI需要分布式系统 什么是分布式系统 分布式系统顾名思义，就是将单一计算机节点要做的任务分布在多个计算机节点上完成的，各个节点之间通过网络进行通讯的计算机系统。 这种系统的好处是显而易见的，我们可以把一台机器的Task进行切分，可能大幅度提升计算效率；我们可以把一台机器存不下的任务放到多个结点里面，拓展数据规模。 但同时也可能引入更多的问题，多台...",
      "content_html": "<h2>为什么AI需要分布式系统</h2>\n<h3>什么是分布式系统</h3>\n<p>分布式系统顾名思义，就是将单一计算机节点要做的任务<code>分布</code>在多个计算机节点上完成的，各个节点之间通过网络进行通讯的计算机系统。</p>\n<p>这种系统的好处是显而易见的，我们可以把一台机器的Task进行切分，可能大幅度<code>提升计算效率</code>；我们可以把一台机器存不下的任务放到多个结点里面，<code>拓展数据规模</code>。</p>\n<p>但同时也可能引入更多的问题，多台机器之间通讯耗费的时间会不会比原先计算的时间更长？切分后的任务如何再将结果重新合在一起？这些都问题都有进一步研究的价值。</p>\n<h3>为什么AI训练需要分布式系统</h3>\n<p>在训练AI时，无论在CV方向还是NLP等其他方向，无论使用哪一种模型，总是绕不开<code>训练集</code>和<code>测试集</code>这两部分，我们总要拿出一部分数据用来预训练模型，另一部分用来测试模型效果。</p>\n<p><code>数据集越大，训练效果越好</code>，这基本上是在不考虑机器性能上限的情况下，我们针对AI训练达成的一种共识，所以在训练AI时我们希望能使用尽可能大的数据集，使用尽可能多的参数，来对尽可能多的标签进行刻画。但可惜一台机器的性能总是有限的。</p>\n<p>这个时候就不得不引入<code>分布式系统</code>来改善这种局面了，如果我们一台机器、一张GPU/TPU没办法高效完成我们的运算，那我们可以分到多张卡上面；如果我们一台机器存储不开我们的数据集，那我们可以分到多台设备上，或者考虑让CPU也存储一部分模型数据。这就是AI使用分布式系统想要解决的问题。</p>\n<h2>分布式系统如何发挥作用</h2>\n<h3>数据分布式的一些基本想法</h3>\n<p>如果我们希望分布式系统在AI训练中发挥他的力量，我们要怎么做呢？大家都对ML有一些基本的认识了，无论哪一种模型，在训练过程中总会有数据（输入、输出），模型（参数、激活函数）等等需要保存的东西。</p>\n<p>现在假定我们要做一个训练任务，我们有我们自己的很大的<code>数据集</code>，我希望能把这个数据<code>很快的训练完</code>，那我们就可以考虑把数据<code>切分</code>成好几份，然后给<code>不同的GPU</code>去算每一个单独的部分，这种每个一份数据切分成多份，给不同的GPU做计算的方式，但每一个GPU均做<code>保留完整的模型</code>做计算，被我们称作<code>数据并行（Data Patallel，简称DP）</code>。</p>\n<p>既然可能有很大的<code>数据集</code>需要切分，那自然也可能有很大的<code>模型</code>进行切分，让每一个GPU仅保留<code>几个隐藏层的模型</code>（参数、激活函数），这样可以训练更大的模型，提升训练精度，这种按层切分模型，不切分数据的方式，被称作<code>模型并行（Model Patallel，简称MP）</code>。</p>\n<p>这种按层切分的方式固然可以增加可容纳的模型的大小，但是仅让一个卡存模型的几层在计算某些必须要用到之前的数据的模型时可能不尽如人意，通讯成本会比较高昂。</p>\n<p>为了解决层切分的弊端，我们可以考虑将计算过程中的算子/计算矩阵进行切分，让每一张卡只保留必须的参数和算子，产生部分输出，这样就可以将每一部分计算矩阵进行并发处理，我们将这种方式称作<code>张量并行/算子并行（Tensor Patallel，简称TP）</code>，谷歌专门为TP开发了TPU进行并发适配，TP也是应用较广的基本并发方式。</p>\n<p>既然我们有了对数据切分的方法，有了对模型算子切分的方法，那我们也可以考虑进行结合，既切分优化器状态，又切分模型的参数、梯度，这种并行方式被称作<code>完全分片数据并行（Fully Sharded Data Parallel，简称FSDP）</code>。</p>\n<p>前面所提及的方法，是在利用切分层内数据/优化器状态/模型绕过MP方法按层切分时可能带来的通讯瓶颈，但是也可以利用类似CPU指令流水线执行的方式，进行数据计算，切分模型让不同GPU延后计算开始时间，从而保证通讯无boundary，这种方式被称作<code>流水线并行（Pipe Parallel，简称PP）</code>。</p>\n<p>在探讨了DP、PP、TP基本并行方式后，我们可以考虑将三种并行方式进行综合，考虑一些综合利用并行方式的策略，这种并行考量被称为<code>3D并行</code>。</p>\n<p>事实上对于采用哪种并行模式，要用多少张卡进行并行，并行中使用的参数如何调整，是一件非常复杂的事情，我们期望有可以<code>自动为我们选定并行方法的策略</code>，这种策略被称作<code>自动并行</code>。</p>\n<h2>数据并行（DP）</h2>\n<h3>典型数据并行的流程</h3>\n<p></p>\n<p></p>\n<ul>\n<li>分配n块计算GPU（图中0-2）;1块梯度收集GPU</li>\n<li>每块GPU均拷贝一份完整的模型</li>\n<li>把一份Data（也可以是一个batch）切分成若干份给不同的GPU</li>\n<li>每一块GPU完成Forward和Backward后，计算出本地的梯度</li>\n<li>把本地梯度push到梯度收集GPU，梯度收集GPU聚合梯度</li>\n<li>计算GPU从聚合GPU中pull完整梯度，更新模型参数，保证各个计算GPU模型同步</li>\n</ul>\n<blockquote>\n<p>聚合再下发梯度操作被称为<code>AllReduce</code></p>\n</blockquote>\n<h3>Horovod</h3>\n<blockquote>\n<p>Horovod: fast and easy distributed deep learning in TensorFlow</p>\n</blockquote>\n<p><code>https://arxiv.org/abs/1802.05799</code> <code>https://github.com/uber/horovod</code></p>\n<p>传统的DP在带来使用大数据集可能的同时，又同时增加了额外的通讯开销，本文还指出DP代码重构成本较大。</p>\n<p>本文通过在不同数量卡上训练结果进行说明：<br>\n</p>\n<p>可以明显看到GPU数量增多时，TensorFlow框架下的通讯开销越大，在128卡时甚至已经超过训练开销。</p>\n<p>为了解决传统DP计算节点和聚合节点比例不好确定导致的通讯成本/计算成本过大的问题，本文指出了ring-allreduce的方式。</p>\n<h4>Ring-AllReduce</h4>\n<p>假设有4块GPU，每块GPU上的数据也对应被切成4份。AllReduce就是要让每块GPU上的数据都变成箭头右边汇总的样子。</p>\n<p></p>\n<p>Ring-AllReduce将这个过程分为<code>Reduce-Scatter</code>和<code>All-Gather</code>。</p>\n<h5>Reduce-Scatter</h5>\n<p>定义网络拓扑关系，使得每个GPU只和其<code>相邻的两块GPU通讯</code>。每次发送对应位置的数据进行累加。每一次累加更新都形成一个拓扑环。</p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p>3次更新之后，每块GPU上都有一块数据拥有了对应位置完整的聚合（图中红色）。此时，Reduce-Scatter阶段结束。进入All-Gather阶段。目标是把红色块的数据广播到其余GPU对应的位置上。</p>\n<h5>All-Gather</h5>\n<p>相邻GPU对应位置进行通讯，对应位置数据不再做相加，而是直接替换</p>\n<p></p>\n<h4>Horovod工作</h4>\n<ul>\n<li>将百度的 TensorFlow ring-allreduce 算法的实现转化为一个独立的 Python 包，命名为 Horovod</li>\n<li>使用 NCCL 库实现了 TensorFlow ring-allreduce，并优化了性能</li>\n<li>添加了对单机多卡的支持</li>\n<li>改进了 API，添加 broadcast 操作，仅需 4 步即可使用 Horovod</li>\n</ul>\n<h4>使用方法</h4>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>import tensorflow as tf</span></span>\n<span class=\"line\"><span>import horovod.tensorflow as hvd</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># 初始化 Horovod</span></span>\n<span class=\"line\"><span>hvd.init()</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># 固定 GPU 以处理本地 rank（每个进程一个 GPU）</span></span>\n<span class=\"line\"><span>config = tf.ConfigProto()</span></span>\n<span class=\"line\"><span>config.gpu_options.visible_device_list = str(hvd.local_rank())</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># 构建模型...</span></span>\n<span class=\"line\"><span>loss = ...</span></span>\n<span class=\"line\"><span>opt = tf.train.AdagradOptimizer(0.01)</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># 添加 Horovod 分布式优化器</span></span>\n<span class=\"line\"><span>opt = hvd.DistributedOptimizer(opt)</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># 添加hook，在初始化期间将变量从 rank 0 广播到所有其他进程</span></span>\n<span class=\"line\"><span>hooks = [hvd.BroadcastGlobalVariablesHook(0)]</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># 创建训练操作</span></span>\n<span class=\"line\"><span>train_op = opt.minimize(loss)</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span># MonitoredTrainingSession 负责会话初始化、从检查点恢复、保存到检查点以及在完成或发生错误时关闭</span></span>\n<span class=\"line\"><span>with tf.train.MonitoredTrainingSession(checkpoint_dir=\"/tmp/train_logs\",</span></span>\n<span class=\"line\"><span>                                       config=config,</span></span>\n<span class=\"line\"><span>                                       hooks=hooks) as mon_sess:</span></span>\n<span class=\"line\"><span>    while not mon_sess.should_stop():</span></span>\n<span class=\"line\"><span>        # 执行同步训练</span></span>\n<span class=\"line\"><span>        mon_sess.run(train_op)</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3>PyTorch DDP</h3>\n<blockquote>\n<p>PyTorch Distributed: Experiences on Accelerating Data Parallel Training</p>\n</blockquote>\n<p><code>https://arxiv.org/abs/2006.15704</code> <code>https://github.com/pytorch/pytorch/</code></p>\n<h4>Python前端API</h4>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span> 1 import torch</span></span>\n<span class=\"line\"><span> 2 import torch.nn as nn</span></span>\n<span class=\"line\"><span> 3 import torch.nn.parallel as par</span></span>\n<span class=\"line\"><span> 4 import torch.optim as optim</span></span>\n<span class=\"line\"><span> 5</span></span>\n<span class=\"line\"><span> 6 # initialize torch.distributed properly</span></span>\n<span class=\"line\"><span> 7 # with init_process_group</span></span>\n<span class=\"line\"><span> 8</span></span>\n<span class=\"line\"><span> 9 # setup model and optimizer</span></span>\n<span class=\"line\"><span> 10 net = nn.Linear(10, 10)</span></span>\n<span class=\"line\"><span> 11 net = par.DistributedDataParallel(net)</span></span>\n<span class=\"line\"><span> 12 opt = optim.SGD(net.parameters(), lr=0.01)</span></span>\n<span class=\"line\"><span> 13</span></span>\n<span class=\"line\"><span> 14 # run forward pass</span></span>\n<span class=\"line\"><span> 15 inp = torch.randn(20, 10)</span></span>\n<span class=\"line\"><span> 16 exp = torch.randn(20, 10)</span></span>\n<span class=\"line\"><span> 17 out = net(inp)</span></span>\n<span class=\"line\"><span> 18</span></span>\n<span class=\"line\"><span> 19 # run backward pass</span></span>\n<span class=\"line\"><span> 20 nn.MSELoss()(out, exp).backward()</span></span>\n<span class=\"line\"><span> 21</span></span>\n<span class=\"line\"><span> 22 # update parameters</span></span>\n<span class=\"line\"><span> 23 opt.step()</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>PyTorch在设计API时做到了仅调用第11行代码中的DistributedDataParallel部分，就可以实现从本机训练到分布式训练的部署。</p>\n<h4>梯度同步算法</h4>\n<p>论文中所提到的DP背景本篇blog前文均有提及，不再赘述。</p>\n<h5>传统做法</h5>\n<ul>\n<li>batch较小时，通讯效率低</li>\n<li>计算与聚合之间存在间隔，很难做到即时通讯。</li>\n</ul>\n<h5>改进做法</h5>\n<p>PyTorch使用<code>Gradient Bucketing</code>，在小batch时，选择收集到一定量的梯度，再做聚合和同步。</p>\n<p>PyTorch使用<code>hook</code>机制，在反向传播计算完成后，调用自定义函数，当在同一个bucket中的梯度的hook都被调用后，就调用AllReduce对该bucket进行通信。</p>\n<p>这种方式有两个问题需要注意：</p>\n<p>（1）由于每个机器（进程）是独立计算的，因此不同机器之间处理的bucket的顺序将会不一致，这会导致梯度同步结果出现错误。因此，我们需要保证不同机器处理bucket的顺序一致。</p>\n<blockquote>\n<p>使用参数的反序作为梯度放入bucket的顺序。依据是，后向传播的顺序与梯度更新的顺序大致可认为是相同的。</p>\n</blockquote>\n<p>（2）不同迭代中，使用的参数可能不相同，使得某些参数的梯度不需要用到。</p>\n<blockquote>\n<p>前向传播结束后从输出开始遍历计算图，记录哪些参数参与计算，哪些参数没有参与计算，对于没有参与计算的参数，则直接标记为ready。</p>\n</blockquote>\n<h5>集合通讯库</h5>\n<p>PyTorch DDP支持三种通讯库：<code>NCCL</code>，<code>Gloo</code>和<code>MPI</code>。DDP支持用户使用统一的API ProcessGroup来调用不同的集合通讯库。</p>\n<ul>\n<li><code>NCCL doc</code>:<code>https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/api.html</code></li>\n<li><code>Gloo doc</code>:<code>https://docs.solo.io/gateway/latest</code></li>\n<li><code>MPI doc</code>:<code>https://www.open-mpi.org/doc/</code></li>\n</ul>\n<h2>FSDP并行</h2>\n<h3>ZeRO</h3>\n<blockquote>\n<p>ZeRO: memory optimizations toward Training trillion parameter Models</p>\n</blockquote>\n<p><code>https://github.com/microsoft/DeepSpeed</code> <code>https://arxiv.org/abs/1910.02054</code></p>\n<h4>Abstract</h4>\n<p>深度学习模型在训练万亿级别参数时存在根本性限制，现有DP（数据并行）、MP（模型并行）方法无法满足日益增长的参数量需求，ZeRO（零冗余优化器）消除了数据和模型并行训练中的内存冗余，同时保持了低通信量和高计算粒度（计算与通信比率的定量或定性度量），使我们能够根据设备数量按比例扩展模型大小，同时保持高效率，实现超线性优化。</p>\n<h4>Extended Introduction</h4>\n<p>巨量参数可以大幅提升NLP处理能力，但参数量的上升在传统的单机GPU、TPU运算中无以为继，简单增加机器数量也用处不大。</p>\n<p>现有的PP（流水线并行）、MP都在通信和计算效率之间权衡，但重点是计算规模和速度。</p>\n<p>现有系统在模型训练中内存消耗的全部范围，并将其分为两部分:</p>\n<p>1）对于大型模型，【大部分内存】被模型状态占用，包括优化器状态、梯度和参数（不得不保存的模型内容）。</p>\n<p>2）剩余内存被激活、临时缓冲区和不可用的碎片内存所消耗，本文将其统称为残差状态（residual states）。</p>\n<h4>Where Did All the Memory Go</h4>\n<p>在模型计算的过程中，只有很少一部分被过程中产生的冗余量使用了（residual states），大部分内存都被用于模型本身数据的存储和运算（model states），ZeRO使用不同的方式优化这两种内存使用。</p>\n<h4>Model States: Optimizer States, Gradients and Parameters</h4>\n<p>论文以Adam优化器为例说明了模型造成的内存浪费是一件难以接受的事情，Adam本身对每一个参数都需要保留momentum和variance两个参数进行数据更新。</p>\n<p>看上去这是仅仅由1变2的内存保留变化，但是由于NVIDIA对于fp16精度计算的高优化度，要服务于计算速度内存变化就会发生膨胀。</p>\n<p>一般来说，在计算时，参数、输入、输出，均采用fp16半精度运算，但是考虑在更新权重的时候，可能在模型训练过程中梯度不大等原因，如果还是使用半精度进行运算，可能并不会产生权重累计，导致模型训练失效，所以此时应采用fp32的全精度计算，这又是一个仅在计算时才能用到的额外copy。</p>\n<blockquote>\n<p>FP32:1位符号位，8位指数位，23位尾数位<br>\nFP16:1位符号位，5位指数位，10位尾数位<br>\nBF16:1位符号位，8位指数位，7位尾数位</p>\n</blockquote>\n<p>假设有Ψ个参数，那就有4Ψ个byte（fp16）存储模型的参数和输入，同时又有12Ψ个byte（fp32）存储momentum和variance（Adam），也就是单计算仅需4Ψ，但是在更新参数进行新的计算时，需要额外的12Ψ，本文将其记作2Ψ+2Ψ+KΨ，其中K取决于模型。</p>\n<h4>Residual Memory Consumption</h4>\n<h5>Temporary buﬀers</h5>\n<p>是指通讯过程中、计算过程中产生的一些临时数据.</p>\n<h5>Memory Fragmentation</h5>\n<p>是指碎片化内存，用pytorch等使用虚拟内存分配方式的库时，可能内存池的维护并不能做到完全利用，论文假设有30%内存其实根本无法使用。</p>\n<h4>ZeRO: Insights and Overview</h4>\n<p>这一部分主要介绍作者使用ZeRO的一些想法。</p>\n<h5>Insights and Overview: ZeRO-DP</h5>\n<p>a）数据并行比模型并行更好，效率更高，因为通讯更少，计算粒度更精细</p>\n<p>b）数据并行内存使用并不高效，因为每一个分发计算都需要完全copy所有数据</p>\n<p>c）两种并行都需要存储模型状态变量，单就这一块部分内存而言，两者使用均不高效。</p>\n<p>我们可以考虑在某一个GPU中存储和更新参数，而在其他GPU需要使用其进行计算时，再进行通讯获取参数，从而降低内存占用。</p>\n<h4>Insights and Overview: ZeRO-R</h4>\n<h5>Reducing Activation Memory</h5>\n<p>a）MP占据模型内存，但是需要时常更新</p>\n<p>b）大模型即使的带宽小的情况下，也可以考虑每个GPU都各自保存和重算部分数据</p>\n<p>ZeRO考虑可以使用将模型内存切分成多分，分开重算，多次通讯的方式收集数据，减少内存使用。</p>\n<h5>Managing Temporary buﬀers</h5>\n<p>对于临时缓存采用开一段固定大小内存的方式进行反复存储。</p>\n<h5>Managing fragmented Memory.</h5>\n<p>内存碎片通过对不同寿命的内存进行整理，减少内存释放和分配的时间</p>\n<h4>Deep Dive into ZeRO-DP</h4>\n<h5>ZeRO1</h5>\n<p>对优化器本身存储的fp32数据进行切分，使每个GPU仅留1/N份数据。</p>\n<h5>ZeRO2</h5>\n<p>对数据并行中存储的fp16梯度进行切分，使每个GPU仅留1/N份数据。</p>\n<h5>ZeRO3</h5>\n<p>对数据并行中存储的fp16参数进行切分，使每个GPU仅留1/N份数据，使用时通讯获取完整参数。</p>\n<p>ZeRO1/2依托allreduce算法实现，NVIDIA本身支持这种优化并不会有通讯增加，但是ZeRO3需要对参数进行切分和更新，每次都会有Ψ 的额外通讯开销，但是事实上可以考虑在不同隐藏层中实现异步更新参数 ，使得参数额外开销尽可能减少。</p>\n<h4>Deep Dive into ZeRO-R</h4>\n<h5>Partitioned Activation Checkpointing</h5>\n<p>采用Megatron的模型并行方式，每个GPU保存1/N参数，对切分后部分输入分开运算，使用reduce-scatter更新各个参数状态，与ZeRO-DP的区别是，计算参数时，每个GPU都没有保存或通讯获取完整的参数，而是对输出进行通讯和更新。</p>\n<h5>Constant Size Buﬀers</h5>\n<p>使用固定大小buffer指定数据的单批发送量，保证带宽不浪费。</p>\n<h5>Memory Defragmentation</h5>\n<p>将数据池分为两部分，一部分存储大批量的计算数据，另一部分动态存储临时数据。</p>\n<h3>ZeRO-Offload</h3>\n<blockquote>\n<p>ZeRO-Offload：Democratizing Billion-Scale Model Training</p>\n</blockquote>\n<p><code>https://arxiv.org/pdf/2101.06840</code>  <code>https://arxiv.org/pdf/2101.06840</code></p>\n<h4>背景</h4>\n<p>GPU内存占用是一件非常昂贵的事情，在过去训练中人们往往忽略了CPU的计算潜力，高估了GPU的存储性能。</p>\n<p>ZeRO-Offload 优化：尽量减少数据在 GPU 与 CPU 之间的移动，并减少 CPU 计算时间，同时最大限度地节省 GPU 上的内存。</p>\n<h4>Efficiency</h4>\n<p>论文提出了一种名为Efficiency的offload策略，通过分析确定了CPU和GPU设备之间的最佳计算和数据划分策略，以在三个关键方面达到最优化：</p>\n<ul>\n<li>在CPU上的计算量比GPU少多个数量级，防止CPU性能瓶颈；</li>\n<li>最小化CPU和GPU之间的通信量，防止通信瓶颈；</li>\n<li>在实现最小通信量的同时，可证明地最大化节约GPU内存。</li>\n</ul>\n<p>offload 优化器计算要求CPU进行O(M)次计算，而GPU需进行O(MB)次计算，其中M和B分别为模型规模和 batch size 。在大多数情况下， batch size 较大，CPU计算量并不是瓶颈，但对于小 batch size，CPU计算量可能成为瓶颈。为了解决这个问题，采取了两种优化措施：</p>\n<ul>\n<li>高效的CPU优化器，其速度比现有技术快6倍；</li>\n<li>延迟一步的参数更新，允许将CPU优化器步骤与GPU计算重叠，同时确保准确性。这两种措施共同保证了ZeRO-Offload在小 batch size 下也能保持效率。</li>\n</ul>\n<h4>Unique Optimal Offload Strategy</h4>\n<p>为了确定最佳的下载策略，ZeRO-Offload将深度学习训练建模为数据流图，将该图分割为CPU和GPU设备之间的部分。</p>\n<p>训练的计算复杂度通常为O(MB)，其中M为模型大小，B为有效batch size。为避免CPU计算成为瓶颈，只有那些计算复杂度低于O(MB)的计算才能转移到CPU上</p>\n<p>FWD 和 BWD 的计算复杂度都是O(MB)，必须在GPU上进行，而其余的计算，如范数计算、权重更新等，其复杂度为O(M)，可以转移到CPU上</p>\n<p></p>\n<p>还需要最小化 CPU 与 GPU 的通信带宽，如图中所示，最小通信量为 BWD后 GPU 发送到 CPU 的 2M 梯度与 CPU 发送到 GPU 的 2M 参数，只有将 fp32 模型状态（momentum 32、variance 32和p32），Param Update 和 float2half 计算放置在一起，为一个 CPU 上的 Update Super Node，才能达成最小通信量策略</p>\n<h4>ZeRO-Offload Schedule</h4>\n<h5>单卡策略</h5>\n<p>ZeRO-Offload将数据进行分区，将fp16参数存储在GPU上，fp16梯度和所有优化器状态存储在CPU上。</p>\n<p>在训练过程中，首先通过 FWD 计算损失。由于fp16参数已经位于GPU上，因此这部分计算不需要与CPU进行通信。</p>\n<p>在 BWD 过程中，不同参数的梯度在后向调度的不同位置计算。ZeRO-Offload可以立即将这些梯度逐个或切分传输到 CPU 内存中。</p>\n<p>因此，在将梯度传输到CPU内存之前，只需要在GPU内存中临时保存少量的梯度。此外，每个梯度传输可以与反向计算重叠，消除大部分通信成本。</p>\n<p>在 BWD 之后，ZeRO-Offload在CPU上直接更新fp32参数和剩余的优化器状态，并将更新后的 fp32 参数从 CPU 内存复制到 GPU 内存中的fp16参数中。</p>\n<blockquote>\n<p>下图GPU与CPU二次通信应该是从CPU到GPU</p>\n</blockquote>\n<p></p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>for_parallel rank in range(world_size):</span></span>\n<span class=\"line\"><span>  # 初始化每个进程的层</span></span>\n<span class=\"line\"><span>  initialize_layers()</span></span>\n<span class=\"line\"><span>  for batch in dataset:</span></span>\n<span class=\"line\"><span>    # 前向传播</span></span>\n<span class=\"line\"><span>    x = forward(batch)</span></span>\n<span class=\"line\"><span>    # 计算损失并反向传播</span></span>\n<span class=\"line\"><span>    compute_loss(x, batch).backward()</span></span>\n<span class=\"line\"><span>    # 反向传播梯度</span></span>\n<span class=\"line\"><span>    backward(x.grad)</span></span>\n<span class=\"line\"><span>    # 更新参数</span></span>\n<span class=\"line\"><span>    step()</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>def _is_owner(i):</span></span>\n<span class=\"line\"><span>  # 判断当前进程是否拥有第 i 层</span></span>\n<span class=\"line\"><span>  return True if rank owns i else False</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>def initialize_layers():</span></span>\n<span class=\"line\"><span>  for i in range(num_layers):</span></span>\n<span class=\"line\"><span>    l = layers[i]</span></span>\n<span class=\"line\"><span>    # 在 GPU 上分配半精度参数</span></span>\n<span class=\"line\"><span>    allocate_on_gpu l.param_fp16</span></span>\n<span class=\"line\"><span>    if _is_owner(i):</span></span>\n<span class=\"line\"><span>      # 在 CPU 上分配全精度参数、优化器状态和梯度</span></span>\n<span class=\"line\"><span>      allocate_on_cpu l.param_fp32</span></span>\n<span class=\"line\"><span>      allocate_on_cpu l.optim_states_fp32</span></span>\n<span class=\"line\"><span>      allocate_on_cpu l.param_grad</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>def forward(x):</span></span>\n<span class=\"line\"><span>  # 前向传播逻辑</span></span>\n<span class=\"line\"><span>  for i in range(num_layers):</span></span>\n<span class=\"line\"><span>    x = layers[i].forward(x)</span></span>\n<span class=\"line\"><span>  return x</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>def backward(dx):</span></span>\n<span class=\"line\"><span>  # 反向传播逻辑</span></span>\n<span class=\"line\"><span>  for i in range(num_layers, 0, -1):</span></span>\n<span class=\"line\"><span>    dx = layers[i].backward(dx)</span></span>\n<span class=\"line\"><span>    # 将梯度减少到拥有该层的进程</span></span>\n<span class=\"line\"><span>    reduce(layers[i].grad, dest_rank = _owner_rank(i))</span></span>\n<span class=\"line\"><span>    if _is_owner(i):</span></span>\n<span class=\"line\"><span>      # 将梯度复制到 CPU</span></span>\n<span class=\"line\"><span>      l.cpu_grad.copy(l.grad)</span></span>\n<span class=\"line\"><span>    else:</span></span>\n<span class=\"line\"><span>      pass</span></span>\n<span class=\"line\"><span>    # 删除 GPU 上的梯度</span></span>\n<span class=\"line\"><span>    del layers[i].grad</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>def step():</span></span>\n<span class=\"line\"><span>  # 参数更新逻辑</span></span>\n<span class=\"line\"><span>  for i in range(num_layers):</span></span>\n<span class=\"line\"><span>    l = layers[i]</span></span>\n<span class=\"line\"><span>    if _is_owner(i):</span></span>\n<span class=\"line\"><span>      # 在 CPU 上更新参数</span></span>\n<span class=\"line\"><span>      update_in_cpu(l.optim_states_fp32,</span></span>\n<span class=\"line\"><span>                    l.cpu_grad,</span></span>\n<span class=\"line\"><span>                    l.param_fp32)</span></span>\n<span class=\"line\"><span>      # 将更新后的参数复制回 GPU</span></span>\n<span class=\"line\"><span>      l.param_fp16.copy(l.param_fp32)</span></span>\n<span class=\"line\"><span>    # 广播更新后的参数</span></span>\n<span class=\"line\"><span>    BROADCAST(l.param_fp16, src = _owner_rank(i))</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h5>多卡策略</h5>\n<p>ZeRO-Offload 将梯度和优化器状态在不同的 GPU 之间进行 partition，并且每个 GPU 将自己的 part offload 到 CPU 内存中，存储持续整个训练过程</p>\n<p>BWD 过程中，在 GPU 上 reduce-scatter 计算梯度并平均，每个 GPU 仅将属于其 part 的平均梯度 offload 到 CPU 内存中</p>\n<p>一旦梯度在 CPU 上可用，优化器状态 part 对应的每个 DP 进程直接在 CPU 上并行更新对应的参数 part</p>\n<p>更新完成后，参数 part 发送到 GPU，在 GPU 上对参数进行类似 ZeRO-2 的 all-gather 操作</p>\n<p></p>\n<h2>流水线并行</h2>\n<h3>GPipe</h3>\n<blockquote>\n<p>GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</p>\n</blockquote>\n<p><code>https://arxiv.org/abs/1811.06965</code></p>\n<h4>Gpipe Abstract</h4>\n<p>增大模型规模可以提升模型效果，但是单卡/单机GPU内存有限，必须引入分布式系统</p>\n<p>GPipe使用模型并行（MP）方案，将模型切分成一连串stage，每个stage放在独立的设备（GPU/TPU）上，实现对超大规模模型的支持</p>\n<p>利用Pipeline（PP）的方案，提高了模型并行模式下的设备利用率</p>\n<p>最终GPipe通过更大规模的模型和更大的batch_size，在图像和NLP的模型上都得到更好的模型效果。</p>\n<h4>Design</h4>\n<h5>Naive Model Parallelism</h5>\n<p>论文中提到的MP就是传统的MP方案，不是Magatron-LM提出的新MP方案（事实上是TP），对数据按层切分，而非对所有输入、输出、参数都按块切分。</p>\n<p></p>\n<p>模型有 12 层（layer），可以切为 4 份（4个cell），每份 3 层。然后每份放到一块 GPU 上</p>\n<p>第 k 个 cell 的模型参数，就放在第 k 块 GPU 上。</p>\n<p>Fk和 Bk 分别表示第 k 个 cell 的 forward 和 backward 计算</p>\n<p></p>\n<p>单批量以这种顺序进行计算，Fk和 Bk 分别表示第 k 个批次的forward和backward运算（注意与上张图不同），每一种颜色代表一块 GPU，每一列代表一个时间段</p>\n<p>问题是：每块 GPU 都会有大量的空闲时间</p>\n<h5>Pipeline Parallelism 1 - Split into micro-batches</h5>\n<p>单batch（mini-batch）切成更小的micro-batch，然后流水线并行（类似CPU指令执行）</p>\n<p></p>\n<blockquote>\n<p>为什么不流水线并行batch，而是切分后再流水线并行？\n多batch可以提速，但占用空间会多很多<br>\n多batch训练时，可能会导致梯度更新不稳定，结果收敛不明显</p>\n</blockquote>\n<h5>Pipeline Parallelism 2 - re-materialization</h5>\n<p>GPU 只保留最开始的输入，中间结果全部丢掉；计算梯度时，再重新计算这些中间结果。</p>\n<p>减少计算时内存占用，但要增加计算时长。</p>\n<h2>张量并行（TP）</h2>\n<h3>Megatron-LM</h3>\n<blockquote>\n<p>Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</p>\n</blockquote>\n<p><code>https://arxiv.org/abs/1909.08053</code> <code>https://github.com/NVIDIA/Megatron-LM</code></p>\n<h4>Model Parallel Transformers</h4>\n<ul>\n<li>在MLP中最常用的操作是MM + GELU，即输入与参数矩阵相乘 和 激活函数</li>\n<li>一种方法是沿着其行(row)将weight矩阵A分割，并沿着其列(columns)输入X分割，来实现tensor-model-parallel，从下图中我们可以看出，在该方法下，需要通过同步来保障语义对等。</li>\n</ul>\n<p></p>\n<ul>\n<li>另一种方法是沿着它的列(columns)分割A，这种方法的好处是保障了各自在独立计算时的语义对等，不需要进行额外通讯</li>\n</ul>\n<p></p>\n<p>不过由于我们使用的A是同一个，在反向传播时要保证在保存不同切分W的GPU中均及时更新A，在PyTorch中可以通过下面的代码简单实现：</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>class f(torch.autograd.Function):</span></span>\n<span class=\"line\"><span> def forward(ctx, x):</span></span>\n<span class=\"line\"><span>  return x</span></span>\n<span class=\"line\"><span> def backward(ctx, gradient):</span></span>\n<span class=\"line\"><span>  all_reduce(gradient)</span></span>\n<span class=\"line\"><span>  return gradient</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><ul>\n<li>通过结合上述两种方法，可以在transformer中实现简单并发，针对MLP、SA两个环节做了如下优化，实现MLP的整体的tensor-model-parallel且语义和原始MLP对等：</li>\n</ul>\n<p></p>\n<ul>\n<li>在优化 embedding 层时，PyTorch 将 embedding 操作视为对输入进行索引操作，即在权重矩阵上执行 index_select 操作。实际上，这个操作等价于先对输入进行 one-hot 编码，然后与权重矩阵进行矩阵乘法（mm）操作。可以将 embedding 层视为线性层来处理，并使用模型并行操作来优化。</li>\n</ul>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>class VocabParallelEmbedding():</span></span>\n<span class=\"line\"><span>    def __init__(self, num_embeddings, embedding_dim, init_method=init.xavier_normal_):</span></span>\n<span class=\"line\"><span>        super(VocabParallelEmbedding, self).__init__()</span></span>\n<span class=\"line\"><span>        ...</span></span>\n<span class=\"line\"><span>        # 通过获取当前 tensor_model_parallel 的 rank 来确定当前卡要 embedding 的 category id，初始化权重</span></span>\n<span class=\"line\"><span>        self.vocab_start_index, self.vocab_end_index = VocabUtility.vocab_range_from_global_vocab_size(</span></span>\n<span class=\"line\"><span>            self.num_embeddings, get_tensor_model_parallel_rank(),</span></span>\n<span class=\"line\"><span>            self.tensor_model_parallel_size)</span></span>\n<span class=\"line\"><span>        self.num_embeddings_per_partition = self.vocab_end_index - self.vocab_start_index</span></span>\n<span class=\"line\"><span>        self.weight = Parameter(torch.empty(</span></span>\n<span class=\"line\"><span>            self.num_embeddings_per_partition, self.embedding_dim,</span></span>\n<span class=\"line\"><span>            dtype=args.params_dtype))</span></span>\n<span class=\"line\"><span>        ...</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    def forward(self, input_):</span></span>\n<span class=\"line\"><span>        if self.tensor_model_parallel_size &gt; 1:</span></span>\n<span class=\"line\"><span>            # 把当前卡上不要的 category idx mask 掉</span></span>\n<span class=\"line\"><span>            input_mask = (input_ &lt; self.vocab_start_index) | \\</span></span>\n<span class=\"line\"><span>                         (input_ &gt;= self.vocab_end_index)</span></span>\n<span class=\"line\"><span>            # Mask 掉的输入</span></span>\n<span class=\"line\"><span>            masked_input = input_.clone() - self.vocab_start_index</span></span>\n<span class=\"line\"><span>            masked_input[input_mask] = 0</span></span>\n<span class=\"line\"><span>        else:</span></span>\n<span class=\"line\"><span>            masked_input = input_</span></span>\n<span class=\"line\"><span>        # 获取嵌入向量</span></span>\n<span class=\"line\"><span>        output_parallel = F.embedding(masked_input, self.weight,</span></span>\n<span class=\"line\"><span>                                      self.padding_idx, self.max_norm,</span></span>\n<span class=\"line\"><span>                                      self.norm_type, self.scale_grad_by_freq,</span></span>\n<span class=\"line\"><span>                                      self.sparse)</span></span>\n<span class=\"line\"><span>        # 把 mask 掉的 category idx 对应的嵌入向量处理成 0</span></span>\n<span class=\"line\"><span>        if self.tensor_model_parallel_size &gt; 1:</span></span>\n<span class=\"line\"><span>            output_parallel[input_mask, :] = 0.0</span></span>\n<span class=\"line\"><span>        # 在所有模型并行 GPU 上进行 reduce 操作</span></span>\n<span class=\"line\"><span>        output = reduce_from_tensor_model_parallel_region(output_parallel)</span></span>\n<span class=\"line\"><span>        return output</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2>3D并行</h2>\n<blockquote>\n<p>Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</p>\n</blockquote>\n<p><code>https://arxiv.org/pdf/2104.04473</code> <code>https://github.com/NVIDIA/Megatron-LM</code></p>\n<h3>贡献</h3>\n<p>如何合理的使用上面的多种并行技术一直是一个困难的命题，本文中研究人员提出了一种名为PTD-P的策略，在一个大规模的GPU集群上达到超过50%的效能。</p>\n<p>本文探讨了以下几种因素对效率的影响：</p>\n<ul>\n<li>不同的并行策略：通常张量并行只适用于一个multi-GPU服务器内部，而流水线并行则几乎只用于更大的模型（多机集群）</li>\n<li>流水线并行中的schedule：对通信、pipeline bubble的大小、内存都有重要的影响</li>\n<li>参数的选取（如microbatch的大小）：对于内存使用和kernel计算效率、pipeline bubble大小也有影响</li>\n</ul>\n<h3>数据并行</h3>\n<p>问题：</p>\n<ul>\n<li>batch过小，会导致单块GPU利用率降低，而通信成本大大增长</li>\n<li>理论上GPU数量等于batch size，这也限制了可以使用的卡的规模</li>\n</ul>\n<h3>考虑流水线并行</h3>\n<p>流水线并行技术将一个模型（Transformer）中的不同层发放到多块GPU上，将原本一个batch的数据分解为多个更小的micro batch，通过编排forward pass和backward pass可以来获取不同的性能。<br>\n为了确保optimizer semantics（也就是端到端的计算能够正确的完成），不同GPU之间需要进行定期同步</p>\n",
      "date_published": "2024-10-28T00:00:00.000Z",
      "date_modified": "2024-11-06T11:20:05.000Z",
      "authors": [],
      "tags": [
        "SOSD"
      ]
    },
    {
      "title": "AISys_分布式开发（选读）",
      "url": "https://newzone.top/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%88%E9%80%89%E8%AF%BB).html",
      "id": "https://newzone.top/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%88%E9%80%89%E8%AF%BB).html",
      "summary": "序列并行 Megatron Reducing Activation Recomputation in Large Transformer Models https://arxiv.org/pdf/2205.05198 Abstract 在大模型训练过程中显存占用过大往往成为瓶颈，一般会通过重计算的方式降低显存占用，但会带来额外的计算代价。本文提出seq...",
      "content_html": "<h2>序列并行</h2>\n<h3>Megatron</h3>\n<p>Reducing Activation Recomputation in Large Transformer Models</p>\n<p><code>https://arxiv.org/pdf/2205.05198</code></p>\n<h4>Abstract</h4>\n<p>在大模型训练过程中显存占用过大往往成为瓶颈，一般会通过<code>重计算</code>的方式降低显存占用，但会带来额外的计算代价。本文提出<code>sequece parallel(序列并行,简称SP)</code>和<code>selective activation recomputation</code>两种方法，可以结合TP有效减少不必要的计算量。</p>\n<p>下图中绿色部分表示不同参数级别模型中需要用于保存activation需要的显存大小，蓝色部分表示不同参数级别模型中需要用于保存<code>parameter</code>和<code>optimizer state</code>需要的显存大小。红色线表示baseline(A100的显存)80G。</p>\n<p>通过对比可以发现,原本单A100跑不了的模型,经过SP优化后可以在单A100上运行了,这就给我们加大数据量和多机并行提供了极大的便利</p>\n<p></p>\n<h4>Activation Memory</h4>\n<p>本文以Transformer结构为例估算<code>Activation Memory</code>，Activation指FWD和BWD梯度计算中创建的所有<code>tensor</code>。不包含模型参数大小和优化器中状态大小，但是包含dropout用到的<code>mask tensor</code>。</p>\n<p></p>\n<p>本文推导与假设中用到了以下几个参量:<br>\n</p>\n<p>本文假设h极大(实际上一般也确实极大), 认为2sb远小于sbh, 即只考虑中间过程的Memory(shb), 忽略输入输出的Memory</p>\n<p>对于Attention模块,这一部分依赖于softmax实现:</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy=\"false\">)</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">\nAttention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">tt</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.4483em;vertical-align:-0.93em;\"></span><span class=\"mord mathnormal\">so</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183em;\"><span style=\"top:-2.2528em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8572em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8172em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1828em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<p>具体实现图例见下:</p>\n<p></p>\n<p>对于<code>Attention</code>块来说，输入的元素个数为<code>sbh</code>个，每个元素以<code>半精度</code>(2 bytes)来进行存储的话，对应输入的元素大小为<code>2sbh bytes</code></p>\n<p><code>Attention</code>块中包含一个<code>self-attention</code>、一个<code>linear(线性映射层)</code>和<code>attention dropout</code>层。对于<code>linear</code>需要保存输入的<code>Activation</code>大小为<code>2sbh</code>, 对于<code>attention dropout</code>层需要<code>mask</code>的大小为<code>sbh</code>(对于一个元素的mask只用1个bytes)，对于<code>self-attention</code>块的<code>Activation Memory</code>的计算有以下几块：</p>\n<ul>\n<li>Query(Q),Key(K),Value(V) <code>matrix mul</code>：input共享，元素个数为sbh个，总大小是 <code>2sbh bytes</code>。</li>\n<li><span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">QK^{T}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0358em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span>矩阵相乘：需要分别创建保存<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>的矩阵，每个矩阵元素总大小为<code>2sbh bytes</code>, 总共大小为<code>4sbh bytes</code></li>\n</ul>\n<p>原始Self-Attention例子(此处X切分仅作示意,实际上是按行切分的):</p>\n<p></p>\n<p></p>\n<ul>\n<li>\n<p>dropout的mask层矩阵的大小与softmax的输出一样，元素个数都是<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">as^{2}b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">b</span></span></span></span>个，但mask单个元素的大小只用<code>1 bytes</code>即可，总的大小为 <span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">as^{2}b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">b</span></span></span></span> bytes</p>\n</li>\n<li>\n<p>softmax的输出也会用于反向的计算，需要缓存下来，对应大小 <span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">as^{2}b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">b</span></span></span></span> bytes</p>\n</li>\n<li>\n<p><span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>矩阵的大小之前没有统计，和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span>、<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>矩阵一样，大小也是<code>2sbh bytes</code></p>\n</li>\n</ul>\n<blockquote>\n<p>Attention 模块总的大小为 11sbh + 5<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><msup><mi>s</mi><mn>2</mn></msup><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">as^{2}b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">b</span></span></span></span> bytes。</p>\n</blockquote>\n<p><code>MLP的Activation大小计算</code>：MLP中有两层线性layer，分别存储输入矩阵大小为<code>2sbh bytes</code>和<code>8sbh bytes</code>；GeLU的反向也需要对输入进行缓存，大小为<code>8sbh bytes</code>; dropout层需要<code>sbh bytes</code>; 总大小为<code>19sbh</code>。</p>\n<p><code>LayerNorm的Activation大小计算</code>：每个LayerNorm层的输入需要<code>2sbh</code>大小，有两个LayerNorm层，总大小为<code>4sbh bytes</code>.</p>\n<p>一层transformer的memory总的大小为:</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>=</mo><mi>s</mi><mi>b</mi><mi>h</mi><mrow><mo fence=\"true\">(</mo><mn>34</mn><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mi>s</mi></mrow><mi>h</mi></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\nActivationMemoryPerLayer=sbh\\left(34+5\\frac{as}h\\right) \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">yer</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.836em;vertical-align:-0.686em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">bh</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\">34</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\">5</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span></p>\n<h4>Tensor Parallel</h4>\n<p>在TP并行中只在Attention和MLP两个地方进行了并行计算，对于两块的输入并没有并行操作。</p>\n<p>图中<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"true\">‾</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\overline{f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0889em;vertical-align:-0.1944em;\"></span><span class=\"mord overline\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span><span style=\"top:-3.8144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span></span></span></span>互为共轭(conjugate)，<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span>在前向时不做操作，反向时执行all-reduce;<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"true\">‾</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\overline{f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0889em;vertical-align:-0.1944em;\"></span><span class=\"mord overline\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span><span style=\"top:-3.8144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span></span></span></span>在前向时执行all-reduce, 反向时不做操作。</p>\n<p></p>\n<p>考虑TP并行(并行度为<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span>)，并行部分有MLP的Linear部分(18sbh bytes)和Attention的QKV部分(6sbh bytes)， <code>ActivationMemoryPerLayer</code>的值降为：</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>=</mo><mi>s</mi><mi>b</mi><mi>h</mi><mrow><mo fence=\"true\">(</mo><mn>10</mn><mo>+</mo><mfrac><mn>24</mn><mi>t</mi></mfrac><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mi>s</mi></mrow><mrow><mi>h</mi><mi>t</mi></mrow></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\nActivationMemoryPerLayer=sbh\\left(10+\\frac{24}t+5\\frac{as}{ht}\\right)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">yer</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.4em;vertical-align:-0.95em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">bh</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\">10</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">24</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\">5</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span></span></span></span></span></p>\n<h4>Sequence Parallel</h4>\n<p>在Tensor模型并行基础上提出了<code>Sequence Parallel</code>，对于非TP并行的部分在sequence维度都是相互独立的，所以可以在sequence维度上进行拆分(即sequence parallel)。</p>\n<p>拆分后如下图，<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"true\">‾</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\overline{f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0889em;vertical-align:-0.1944em;\"></span><span class=\"mord overline\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8944em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span><span style=\"top:-3.8144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span></span></span></span>替换为<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi></mrow><annotation encoding=\"application/x-tex\">g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>g</mi><mo stretchy=\"true\">‾</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\overline{g}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.825em;vertical-align:-0.1944em;\"></span><span class=\"mord overline\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6306em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span><span style=\"top:-3.5506em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span></span></span></span>​在前向是reduce-scatter, 反向是all-gather通信。</p>\n<p></p>\n<p>以MLP为例，详细说明拆分步骤:</p>\n<p>MLP层由两个Linear层组成，对应的计算公式如下, 其中<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>的大小为<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mo>×</mo><mi>b</mi><mo>×</mo><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">s × b × h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span>;<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span>是Linear的权重weight矩阵，大小为<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo>×</mo><mn>4</mn><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h × 4h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord\">4</span><span class=\"mord mathnormal\">h</span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4</mn><mi>h</mi><mo>×</mo><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">4h×h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord\">4</span><span class=\"mord mathnormal\">h</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></p>\n<p>论文做如下符号说明:</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mi>Y</mi></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mtext>LayerNorm</mtext><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mi>Z</mi></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mtext>GeLU</mtext><mo stretchy=\"false\">(</mo><mi>Y</mi><mi>A</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mi>W</mi></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>Z</mi><mi>B</mi><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mi>V</mi></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mtext>Dropout</mtext><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\n\\begin{aligned}Y&amp;=\\text{LayerNorm}(X),\\\\Z&amp;=\\text{GeLU}(YA),\\\\W&amp;=ZB,\\\\V&amp;=\\text{Dropout}(W),\\end{aligned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:6em;vertical-align:-2.75em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.25em;\"><span style=\"top:-5.41em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span><span style=\"top:-3.91em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span></span></span><span style=\"top:-2.41em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span></span></span><span style=\"top:-0.91em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.25em;\"><span style=\"top:-5.41em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord text\"><span class=\"mord\">LayerNorm</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span></span></span><span style=\"top:-3.91em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord text\"><span class=\"mord\">GeLU</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord mathnormal\">A</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span></span></span><span style=\"top:-2.41em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">ZB</span><span class=\"mpunct\">,</span></span></span><span style=\"top:-0.91em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord text\"><span class=\"mord\">Dropout</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p></p>\n<ul>\n<li>对<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>按sequence维度切分， <span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo fence=\"true\">[</mo><msubsup><mi>X</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>X</mi><mn>2</mn><mi>s</mi></msubsup><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X = \\left[ X^s_1, X^s_2 \\right]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:-0.0785em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:-0.0785em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">]</span></span></span></span></span>，LayerNorm的结果<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi><mo>=</mo><mrow><mo fence=\"true\">[</mo><msubsup><mi>Y</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>Y</mi><mn>2</mn><mi>s</mi></msubsup><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y = \\left[ Y^s_1, Y^s_2 \\right]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">]</span></span></span></span></span>；</li>\n<li>考虑GeLU非线性，进行all-gather，计算<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Z = GeLU(YA)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">G</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">LU</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord mathnormal\">A</span><span class=\"mclose\">)</span></span></span></span>；</li>\n<li>对<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span>进行列切分的tensor并行，得到结果<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi><msubsup><mi>A</mi><mn>1</mn><mi>c</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">YA^c_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9314em;vertical-align:-0.2481em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">c</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span></span></span></span>​和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi><msubsup><mi>A</mi><mn>2</mn><mi>c</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">YA^c_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9314em;vertical-align:-0.2481em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">c</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>对<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span>进行行切分的tensor并行，得到结果<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>Z</mi><mn>1</mn><mi>h</mi></msubsup><msubsup><mi>B</mi><mn>1</mn><mi>r</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">Z^h_1 B^r_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0972em;vertical-align:-0.2481em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-2.4519em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:-0.0502em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>Z</mi><mn>2</mn><mi>h</mi></msubsup><msubsup><mi>B</mi><mn>2</mn><mi>r</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">Z^h_2 B^r_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0972em;vertical-align:-0.2481em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-2.4519em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-2.4519em;margin-left:-0.0502em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2481em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>得到<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">W_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">W_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>后进行reduce-scatter</li>\n</ul>\n<p>具体过程见下:</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>Y</mi><mn>2</mn><mi>s</mi></msubsup><mo stretchy=\"false\">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mtable rowspacing=\"0.25em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mtext>LayerNorm</mtext><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">[</mo><msubsup><mi>X</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>X</mi><mn>2</mn><mi>s</mi></msubsup><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr></mtable></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mtext>Y</mtext></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>g</mi><mo stretchy=\"false\">(</mo><msubsup><mi>Y</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>Y</mi><mn>2</mn><mi>s</mi></msubsup><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Z</mi><mn>1</mn><mi>h</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>Z</mi><mn>2</mn><mi>h</mi></msubsup><mo stretchy=\"false\">]</mo></mrow></mstyle></mtd></mtr></mtable></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mo stretchy=\"false\">[</mo><mtext>GeLU</mtext><mo stretchy=\"false\">(</mo><mi>Y</mi><msubsup><mi>A</mi><mn>1</mn><mi>c</mi></msubsup><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mtext>&nbsp;GeLU</mtext><mo stretchy=\"false\">(</mo><mi>Y</mi><msubsup><mi>A</mi><mn>2</mn><mi>c</mi></msubsup><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><msub><mi>W</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msubsup><mi>Z</mi><mn>1</mn><mi>h</mi></msubsup><msubsup><mi>B</mi><mn>1</mn><mi>r</mi></msubsup><mtext>&nbsp;and&nbsp;</mtext><msub><mi>W</mi><mn>2</mn></msub><mo>=</mo><msubsup><mi>Z</mi><mn>2</mn><mi>h</mi></msubsup><msubsup><mi>B</mi><mn>2</mn><mi>r</mi></msubsup><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>W</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>W</mi><mn>2</mn><mi>s</mi></msubsup><mo stretchy=\"false\">]</mo></mrow></mstyle></mtd></mtr></mtable></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mover accent=\"true\"><mi>g</mi><mo>ˉ</mo></mover><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>W</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>V</mi><mn>1</mn><mi>s</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>V</mi><mn>2</mn><mi>s</mi></msubsup><mo stretchy=\"false\">]</mo></mrow></mstyle></mtd></mtr></mtable></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mo stretchy=\"false\">[</mo><mrow><mi mathvariant=\"normal\">D</mi><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">o</mi><mi mathvariant=\"normal\">p</mi><mi mathvariant=\"normal\">o</mi><mi mathvariant=\"normal\">u</mi><mi mathvariant=\"normal\">t</mi></mrow><mo stretchy=\"false\">(</mo><msubsup><mi>W</mi><mn>1</mn><mi>s</mi></msubsup><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mtext>&nbsp;Dropout</mtext><mo stretchy=\"false\">(</mo><msubsup><mi>W</mi><mn>2</mn><mi>s</mi></msubsup><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\n\\begin{aligned}\n[Y_1^s,Y_2^s]&amp; \\begin{aligned}&amp;=\\text{LayerNorm}([X_1^s,X_2^s]),\\end{aligned} \\\\\n\\text{Y}&amp; =g(Y_1^s,Y_2^s), \\\\\n\\begin{aligned}[Z_1^h,Z_2^h]\\end{aligned}&amp; =[\\text{GeLU}(YA_1^c),\\text{ GeLU}(YA_2^c)], \\\\\nW_{1}&amp; =Z_1^hB_1^r\\text{ and }W_2=Z_2^hB_2^r, \\\\\n\\begin{aligned}[W_1^s,W_2^s]\\end{aligned}&amp; =\\bar{g}(W_1,W_2), \\\\\n\\begin{aligned}[V_1^s,V_2^s]\\end{aligned}&amp; =[\\mathrm{Dropout}(W_1^s),\\text{ Dropout}(W_2^s)]. \n\\end{aligned}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:10.3182em;vertical-align:-4.9091em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:5.4091em;\"><span style=\"top:-7.4387em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span><span style=\"top:-5.7987em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">Y</span></span></span></span><span style=\"top:-4.1091em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0296em;\"><span style=\"top:-3.1304em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991em;\"><span style=\"top:-2.453em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991em;\"><span style=\"top:-2.453em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5296em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.3804em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-0.7204em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1em;\"><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:1.0796em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1em;\"><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:4.9091em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:5.4091em;\"><span style=\"top:-7.4387em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:2.84em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1em;\"><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord text\"><span class=\"mord\">LayerNorm</span></span><span class=\"mopen\">([</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.0785em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.0785em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">])</span><span class=\"mpunct\">,</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-5.7987em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span></span></span><span style=\"top:-4.1091em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mopen\">[</span><span class=\"mord text\"><span class=\"mord\">GeLU</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">c</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord text\"><span class=\"mord\">&nbsp;GeLU</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">c</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)]</span><span class=\"mpunct\">,</span></span></span><span style=\"top:-2.3804em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991em;\"><span style=\"top:-2.453em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.0502em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mord text\"><span class=\"mord\">&nbsp;and&nbsp;</span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991em;\"><span style=\"top:-2.453em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.0502em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span></span></span><span style=\"top:-0.7204em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5678em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.2222em;\"><span class=\"mord\">ˉ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1944em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span></span></span><span style=\"top:1.0796em;\"><span class=\"pstrut\" style=\"height:3.0296em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathrm\">Dropout</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord text\"><span class=\"mord\">&nbsp;Dropout</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)]</span><span class=\"mord\">.</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:4.9091em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>TP在一次前向和后向总共有4次的<code>all-reduce</code>操作，在SP一次前向和后向总共有4次<code>all-gather</code>和4次<code>reduce-scatter</code>操作。<br>\n<code>ring all-reduce</code> 执行过程中有两步，先是一个<code>reduce-scatter</code>然后一个<code>all-gather</code>，SP没有引入更多的通信代价。</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>y</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>s</mi><mi>b</mi><mi>h</mi><mrow><mo fence=\"true\">(</mo><mfrac><mn>10</mn><mi>t</mi></mfrac><mo>+</mo><mfrac><mn>24</mn><mi>t</mi></mfrac><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mi>s</mi></mrow><mrow><mi>h</mi><mi>t</mi></mrow></mfrac><mo fence=\"true\">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>s</mi><mi>b</mi><mi>h</mi></mrow><mi>t</mi></mfrac><mrow><mo fence=\"true\">(</mo><mn>34</mn><mo>+</mo><mn>5</mn><mfrac><mrow><mi>a</mi><mi>s</mi></mrow><mi>h</mi></mfrac><mo fence=\"true\">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\n\\begin{aligned}\nActivationMemoryPerLayer&amp; =sbh\\left(\\frac{10}t+\\frac{24}t+5\\frac{as}{ht}\\right) \\\\\n&amp;=\\frac{sbh}t\\left(34+5\\frac{as}h\\right)\n\\end{aligned}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:5.0575em;vertical-align:-2.2787em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7787em;\"><span style=\"top:-4.7787em;\"><span class=\"pstrut\" style=\"height:3.45em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ory</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">yer</span></span></span><span style=\"top:-2.1573em;\"><span class=\"pstrut\" style=\"height:3.45em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.2787em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7787em;\"><span style=\"top:-4.7787em;\"><span class=\"pstrut\" style=\"height:3.45em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">bh</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">10</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">24</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\">5</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span></span></span><span style=\"top:-2.1573em;\"><span class=\"pstrut\" style=\"height:3.45em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">bh</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\">34</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\">5</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.2787em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<h3>DeepSpeed-Ulysses</h3>\n<p><code>DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models</code><br>\n<code>https://arxiv.org/pdf/2309.14509</code></p>\n<blockquote>\n<p>DeepSpeed在知乎也有官号, 这里仅作简述, 官号本身讲的也非常不错, 链接在这儿:https://zhuanlan.zhihu.com/p/652206513</p>\n</blockquote>\n<h4>简介</h4>\n<ul>\n<li>长序列在LLM应用中非常重要, 长上下文的保存有助于LLM推理, 需求大token和长Sequence的输入</li>\n<li>现有的DP TP PP不能解决序列维度的扩展问题</li>\n<li>现有的序列并行方法依托内存通讯, 不够高效</li>\n</ul>\n<p>DeepSpeed-Ulysses将各个样本在<code>序列维度</code>上分割给参与的GPU。在attention计算之前，它对已分割的查询(Q)、键(K)和值(V)执行<code>all-to-all</code>通信操作，以使每个GPU接收完整的序列，但仅用于注意力头的<code>非重叠子集</code>。<br>\n这使得参与的GPU可以并行计算不同的注意力头。最后，DeepSpeed-Ulysses还使用另一个<code>all-to-all</code>来在注意力头上收集结果，同时重新在序列维度上进行分区。</p>\n<h4>DeepSpeed-Ulysses的核心设计</h4>\n<p></p>\n<p></p>\n<p>与已知的Transformer架构一样，设计由<code>N个输入序列</code>在<code>P个可用设备</code>上分区组成。每个本地N/P分区都被投影到查询（Q）、键（K）和值（V）嵌入中。接下来，(QKV) 嵌入通过参与计算设备之间的高度优化的全对全集合（all-to-all collectives）进行全局的 QKV 收集。在全对全集合后，每个头的注意力计算形式为：</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mtext>&nbsp;</mtext><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo stretchy=\"false\">)</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">\nOutput~context=Softmax~(\\frac{QK^T}{\\sqrt{d}})V\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">tp</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace nobreak\">&nbsp;</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.4483em;vertical-align:-0.93em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mspace nobreak\">&nbsp;</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183em;\"><span style=\"top:-2.1778em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord mathnormal\">d</span></span></span><span style=\"top:-2.8922em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1078em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<p>注意力计算后，另一个全对全集合将注意力计算的输出上下文张量转换为序列(N/P)并行，用于Transformer模型层的剩余模块中的后续操作。</p>\n<h3>Sequence Parallelism</h3>\n<p><code>Sequence Parallelism: Long Sequence Training from System Perspective</code><br>\n<code>https://arxiv.org/pdf/2105.13120</code></p>\n<h4>论文背景</h4>\n<p>和Ulysses一样, 这个SP也是目的也是解决输入序列规模问题, 而不是像Megtron-LM一样解决计算过程中的内存占用问题.</p>\n<p>文章将自己的SP流程和PP TP模型做了比较:<br>\n</p>\n<h4>主要工作</h4>\n<p>本文认为SP最主要的问题是跨设备如何计算<code>sub-sequences</code>的<code>attention scores</code>问题，为了解决该问题，本文设计出<code>Ring Self-Attention</code>来解决此问题.</p>\n<blockquote>\n<p>感觉想法来源于Ring-AllReduce, 而且只优化了自注意力部分</p>\n</blockquote>\n<p></p>\n<blockquote>\n<p>RSA感觉就是将输入序列进行切分, 通过将序列整体切分成小的chunk, 使得每一个chunk都尽可能大, 用commnication换取序列长度</p>\n</blockquote>\n<p></p>\n<h3>Ring-Attention</h3>\n<p><code>Ring Attention with Blockwise Transformers for Near-Infinite Context</code><br>\n<code>https://arxiv.org/pdf/2310.01889</code></p>\n<h4>背景</h4>\n<p>老生常谈的transformer长序列要求，不做赘述。</p>\n<h4>Ring Attention</h4>\n<p>本文提出以<code>分块方式</code>执行Self-Attention和FWD计算，多机分布序列维度，从而实现并发计算和通信.<br>\n由于该方法将环中主机设备之间的<code>Key Value Block</code>通信与compute重叠，因此将其命名：<code>环注意(Ring Attention)</code></p>\n<p>具体实现：</p>\n<p></p>\n<p>该方法在主机设备之间构建Self-Attention的外循环，每个主机设备具有一个<code>query block</code>，并通过<code>Key Value Block</code>遍历主机<code>Ring</code>，以<code>逐块</code>的方式进行注意力和前馈网络计算。<br>\n当计算Self-Attention时，每个主机将<code>Key Value Block</code>发送到下一个主机，同时从前一个主机接收<code>Key Value Block</code>。</p>\n<p></p>\n<p>对于内循环，每个设备计算其各自的Self-Attention和FWD。在内循环期间，每个设备将用于compute的<code>Key Value Block</code>的副本发送到Ring中的下一个设备，同时从前一个设备接收<code>Key Value Block</code>。<br>\n由于<code>块计算比块传输需要更长的时间</code>，与标准Transformer相比，此过程不会增加开销。</p>\n<blockquote>\n<p>这种Ring Attention方式可以突破序列长度限制（对于单卡内存需求来说，而非模型整体来说），因为我们在Attention之前矩阵乘就已经切分了Squence，让每一个卡分批成环去跑一小批token</p>\n<p>这种方式理论上并不影响训练结果，因为最小训练单位还是一个token（对Squence做切分时的原则）</p>\n<p>天才般的想法！（我觉得）好吧也需要堆卡出奇迹</p>\n</blockquote>\n<blockquote>\n<p>那么代价呢？\n文章的训练测试规模比较小，能否在大规模训练时取得想象中的线性效果，还是未知数\n文章只对Attention和FWD操作做了优化，基础操作还有进一步优化的空间，可以考虑采用4D并行。</p>\n</blockquote>\n<h3>DISTFLASHATTN</h3>\n<p><code>https://arxiv.org/pdf/2310.03294</code></p>\n<h4>背景</h4>\n<p>部分SP方法，如Ring Attention缺少高效的Attention实现。（前文提及的<code>基础操作还有进一步优化的空间</code>）</p>\n<h4>论文方法</h4>\n<p>文章针对三个challenge提出了三个解决方法，解决了高校Attention实现、分布式应用等问题。</p>\n<h5>token-level workload imbalance</h5>\n<p>这主要是由于causal mask引起的attention计算问题，如果简单分块计算约会有1/2的计算资源浪费。<br>\n因为一般causal mask就是会用矩阵以对角线为界mask数据, 按照ring拓扑结构进行计算也会有约一半的CPU处于等待状态。</p>\n<p>针对这个问题，论文中提出<code>Token-level workload balancing</code>的调度算法，通过给空闲的worker来fetch部分key-value数据，计算后再传递回去。</p>\n<p></p>\n<h5>Prohibitive communication overhead</h5>\n<p>需要通信汇总不同worker上的attention结果，本文提出通过计算<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><mi>t</mi><mi>t</mi><mi>n</mi><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>p</mi></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>r</mi></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mi>r</mi></msub><mo separator=\"true\">,</mo><msub><mi>s</mi><mi>p</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">attn(q_p,k_r,v_r,s_p)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">tt</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> prefetch张量来完成通信<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mi>e</mi><mi>r</mi><mspace width=\"1em\"></mspace><mi>p</mi><mi><mover><mo><mi mathvariant=\"normal\">⟵</mi><mo>⁡</mo></mo><mrow><msub><mi>k</mi><mrow><mi>r</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mrow><mi>r</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></mover></mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mi>e</mi><mi>r</mi><mspace width=\"1em\"></mspace><mi>r</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">worker\\quad p\\overset{k_{r+1},v_{r+1}}{\\operatorname*{\\longleftarrow}}worker\\quad r+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5443em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">or</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord\"><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3499em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\"><span class=\"mop\"><span class=\"mord mathrm\">⟵</span></span></span></span></span><span style=\"top:-3.7638em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3173em;\"><span style=\"top:-2.357em;margin-left:-0.0315em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2025em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3173em;\"><span style=\"top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2025em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">or</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>的覆盖，实现依赖于P2P的通信模式。</p>\n<p></p>\n<h4>Loadbalanced scheduling with communication and computation overlap</h4>\n<p>huggingface中采用的Recomputation的检查点放置不合理，导致相对高的还原计算代价。<br>\n下面是两种重计算策略的对比：<br>\n</p>\n<p>DFA相较HF每一个<code>FlashAttention</code>+<code>FFN</code>约能够减少一个FA的计算量。<br>\n<code>FlashAttention</code>部分的梯度更新为<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mi>Q</mi><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">K Q V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">Q</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span>三个矩阵，可以通过FA的输出结果完成更新，因此保存FA的结果便可计算三者的矩阵。</p>\n<h3>典型并行方式时序图</h3>\n<h4>TP</h4>\n<div class=\"language-sequencediagram line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"sequencediagram\" data-title=\"sequencediagram\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 定义参与者</span></span>\n<span class=\"line\"><span>    participant CPU as 主机 CPU</span></span>\n<span class=\"line\"><span>    participant P0 as GPU 0</span></span>\n<span class=\"line\"><span>    participant P1 as GPU 1</span></span>\n<span class=\"line\"><span>    participant P2 as GPU 2</span></span>\n<span class=\"line\"><span>    participant P3 as GPU 3</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 初始化阶段</span></span>\n<span class=\"line\"><span>    note over CPU,P3: 初始化阶段</span></span>\n<span class=\"line\"><span>    rect rgba(235, 235, 235, 0.5)</span></span>\n<span class=\"line\"><span>        CPU-&gt;&gt;P0: 加载并分割模型参数</span></span>\n<span class=\"line\"><span>        CPU-&gt;&gt;P1: 加载并分割模型参数</span></span>\n<span class=\"line\"><span>        CPU-&gt;&gt;P2: 加载并分割模型参数</span></span>\n<span class=\"line\"><span>        CPU-&gt;&gt;P3: 加载并分割模型参数</span></span>\n<span class=\"line\"><span>        P0-&gt;&gt;P0: 初始化本地张量部分</span></span>\n<span class=\"line\"><span>        P1-&gt;&gt;P1: 初始化本地张量部分</span></span>\n<span class=\"line\"><span>        P2-&gt;&gt;P2: 初始化本地张量部分</span></span>\n<span class=\"line\"><span>        P3-&gt;&gt;P3: 初始化本地张量部分</span></span>\n<span class=\"line\"><span>    end</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 前向传播阶段</span></span>\n<span class=\"line\"><span>    note over CPU,P3: 前向传播阶段</span></span>\n<span class=\"line\"><span>    rect rgba(215, 235, 255, 0.5)</span></span>\n<span class=\"line\"><span>        P0-&gt;&gt;P1: 发送激活值 (All-Gather)</span></span>\n<span class=\"line\"><span>        P1-&gt;&gt;P2: 发送激活值 (All-Gather)</span></span>\n<span class=\"line\"><span>        P2-&gt;&gt;P3: 发送激活值 (All-Gather)</span></span>\n<span class=\"line\"><span>        P3-&gt;&gt;P0: 发送激活值 (All-Gather)</span></span>\n<span class=\"line\"><span>        par</span></span>\n<span class=\"line\"><span>            P0-&gt;&gt;P0: 计算本地张量部分</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P1-&gt;&gt;P1: 计算本地张量部分</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P2-&gt;&gt;P2: 计算本地张量部分</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P3-&gt;&gt;P3: 计算本地张量部分</span></span>\n<span class=\"line\"><span>        end</span></span>\n<span class=\"line\"><span>        P0-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class=\"line\"><span>        P1-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class=\"line\"><span>        P2-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class=\"line\"><span>        P3-&gt;&gt;CPU: 存储中间结果</span></span>\n<span class=\"line\"><span>    end</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 反向传播阶段</span></span>\n<span class=\"line\"><span>    note over CPU,P3: 反向传播阶段</span></span>\n<span class=\"line\"><span>    rect rgba(235, 215, 235, 0.5)</span></span>\n<span class=\"line\"><span>        P0-&gt;&gt;P1: 发送梯度 (All-Reduce)</span></span>\n<span class=\"line\"><span>        P1-&gt;&gt;P2: 发送梯度 (All-Reduce)</span></span>\n<span class=\"line\"><span>        P2-&gt;&gt;P3: 发送梯度 (All-Reduce)</span></span>\n<span class=\"line\"><span>        P3-&gt;&gt;P0: 发送梯度 (All-Reduce)</span></span>\n<span class=\"line\"><span>        par</span></span>\n<span class=\"line\"><span>            P0-&gt;&gt;P0: 计算本地梯度</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P1-&gt;&gt;P1: 计算本地梯度</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P2-&gt;&gt;P2: 计算本地梯度</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P3-&gt;&gt;P3: 计算本地梯度</span></span>\n<span class=\"line\"><span>        end</span></span>\n<span class=\"line\"><span>        P0-&gt;&gt;CPU: 存储梯度</span></span>\n<span class=\"line\"><span>        P1-&gt;&gt;CPU: 存储梯度</span></span>\n<span class=\"line\"><span>        P2-&gt;&gt;CPU: 存储梯度</span></span>\n<span class=\"line\"><span>        P3-&gt;&gt;CPU: 存储梯度</span></span>\n<span class=\"line\"><span>    end</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 参数更新阶段</span></span>\n<span class=\"line\"><span>    note over CPU,P3: 参数更新阶段</span></span>\n<span class=\"line\"><span>    rect rgba(215, 255, 215, 0.5)</span></span>\n<span class=\"line\"><span>        par</span></span>\n<span class=\"line\"><span>            P0-&gt;&gt;P0: 更新本地参数</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P1-&gt;&gt;P1: 更新本地参数</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P2-&gt;&gt;P2: 更新本地参数</span></span>\n<span class=\"line\"><span>            and</span></span>\n<span class=\"line\"><span>            P3-&gt;&gt;P3: 更新本地参数</span></span>\n<span class=\"line\"><span>        end</span></span>\n<span class=\"line\"><span>        P0-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class=\"line\"><span>        P1-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class=\"line\"><span>        P2-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class=\"line\"><span>        P3-&gt;&gt;CPU: 同步更新后的参数</span></span>\n<span class=\"line\"><span>    end</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h4>DP</h4>\n<div class=\"language-sequencediagram line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"sequencediagram\" data-title=\"sequencediagram\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    participant Server</span></span>\n<span class=\"line\"><span>    participant Worker1</span></span>\n<span class=\"line\"><span>    participant Worker2</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Worker1: 分发第k-1个batch数据</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Worker2: 分发第k-1个batch数据</span></span>\n<span class=\"line\"><span>    Worker1-&gt;&gt;Worker1: 第k-1个batch FWD</span></span>\n<span class=\"line\"><span>    Worker2-&gt;&gt;Worker2: 第k-1个batch FWD</span></span>\n<span class=\"line\"><span>    Worker1-&gt;&gt;Worker1: 第k-1个batch BWD</span></span>\n<span class=\"line\"><span>    Worker2-&gt;&gt;Worker2: 第k-1个batch BWD</span></span>\n<span class=\"line\"><span>    Worker1--&gt;&gt;Server: 返回第k-1个batch梯度</span></span>\n<span class=\"line\"><span>    Worker2--&gt;&gt;Server: 返回第k-1个batch梯度</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Server: 第k-1个batch AllReduce操作</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Server: 更新第k-1个batch参数</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Worker1: 分发第k个batch数据</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Worker2: 分发第k个batch数据</span></span>\n<span class=\"line\"><span>    Worker1-&gt;&gt;Worker1: 第k个batch FWD</span></span>\n<span class=\"line\"><span>    Worker2-&gt;&gt;Worker2: 第k个batch FWD</span></span>\n<span class=\"line\"><span>    Worker1-&gt;&gt;Worker1: 第k个batch BWD</span></span>\n<span class=\"line\"><span>    Worker2-&gt;&gt;Worker2: 第k个batch BWD</span></span>\n<span class=\"line\"><span>    Worker1--&gt;&gt;Server: 返回第k个batch梯度</span></span>\n<span class=\"line\"><span>    Worker2--&gt;&gt;Server: 返回第k个batch梯度</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Server: 第k个batch AllReduce操作</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Server: 更新第k个batch参数</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Worker1: 分发第k+1个batch数据</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Worker2: 分发第k+1个batch数据</span></span>\n<span class=\"line\"><span>    Worker1-&gt;&gt;Worker1: 第k+1个batch FWD</span></span>\n<span class=\"line\"><span>    Worker2-&gt;&gt;Worker2: 第k+1个batch FWD</span></span>\n<span class=\"line\"><span>    Worker1-&gt;&gt;Worker1: 第k+1个batch BWD</span></span>\n<span class=\"line\"><span>    Worker2-&gt;&gt;Worker2: 第k+1个batch BWD</span></span>\n<span class=\"line\"><span>    Worker1--&gt;&gt;Server: 返回第k+1个batch梯度</span></span>\n<span class=\"line\"><span>    Worker2--&gt;&gt;Server: 返回第k+1个batch梯度</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Server: 第k+1个batch AllReduce操作</span></span>\n<span class=\"line\"><span>    Server-&gt;&gt;Server: 更新第k+1个batch参数</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h4>PP</h4>\n<div class=\"language-sequencediagram line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"sequencediagram\" data-title=\"sequencediagram\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    participant Client</span></span>\n<span class=\"line\"><span>    participant Splitter</span></span>\n<span class=\"line\"><span>    participant Stage1</span></span>\n<span class=\"line\"><span>    participant Stage2</span></span>\n<span class=\"line\"><span>    participant Stage3</span></span>\n<span class=\"line\"><span>    participant Aggregator</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    Client-&gt;&gt;Splitter: 分割为微批次</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 微批次1 前向传播</span></span>\n<span class=\"line\"><span>    Splitter-&gt;&gt;Stage1: 微批次1 FWD</span></span>\n<span class=\"line\"><span>    activate Stage1</span></span>\n<span class=\"line\"><span>    Stage1-&gt;&gt;Stage2: 微批次1 FWD</span></span>\n<span class=\"line\"><span>    activate Stage2</span></span>\n<span class=\"line\"><span>    Stage2-&gt;&gt;Stage3: 微批次1 FWD</span></span>\n<span class=\"line\"><span>    activate Stage3</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 微批次2 前向传播（稍后开始）</span></span>\n<span class=\"line\"><span>    Splitter-&gt;&gt;Stage1: 微批次2 FWD</span></span>\n<span class=\"line\"><span>    Stage1-&gt;&gt;Stage2: 微批次2 FWD</span></span>\n<span class=\"line\"><span>    Stage2-&gt;&gt;Stage3: 微批次2 FWD</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 微批次1 反向传播</span></span>\n<span class=\"line\"><span>    Stage3--&gt;&gt;Stage2: 微批次1 BWD</span></span>\n<span class=\"line\"><span>    deactivate Stage3</span></span>\n<span class=\"line\"><span>    Stage2--&gt;&gt;Stage1: 微批次1 BWD</span></span>\n<span class=\"line\"><span>    deactivate Stage2</span></span>\n<span class=\"line\"><span>    Stage1-&gt;&gt;Aggregator: 微批次1 梯度</span></span>\n<span class=\"line\"><span>    deactivate Stage1</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 微批次3 前向传播（再次稍后开始）</span></span>\n<span class=\"line\"><span>    Splitter-&gt;&gt;Stage1: 微批次3 FWD</span></span>\n<span class=\"line\"><span>    activate Stage1</span></span>\n<span class=\"line\"><span>    Stage1-&gt;&gt;Stage2: 微批次3 FWD</span></span>\n<span class=\"line\"><span>    activate Stage2</span></span>\n<span class=\"line\"><span>    Stage2-&gt;&gt;Stage3: 微批次3 FWD</span></span>\n<span class=\"line\"><span>    activate Stage3</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 微批次2 反向传播</span></span>\n<span class=\"line\"><span>    Stage3--&gt;&gt;Stage2: 微批次2 BWD</span></span>\n<span class=\"line\"><span>    Stage2--&gt;&gt;Stage1: 微批次2 BWD</span></span>\n<span class=\"line\"><span>    Stage1-&gt;&gt;Aggregator: 微批次2 梯度</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    %% 微批次3 反向传播</span></span>\n<span class=\"line\"><span>    Stage3--&gt;&gt;Stage2: 微批次3 BWD</span></span>\n<span class=\"line\"><span>    deactivate Stage3</span></span>\n<span class=\"line\"><span>    Stage2--&gt;&gt;Stage1: 微批次3 BWD</span></span>\n<span class=\"line\"><span>    deactivate Stage2</span></span>\n<span class=\"line\"><span>    Stage1-&gt;&gt;Aggregator: 微批次3 梯度</span></span>\n<span class=\"line\"><span>    deactivate Stage1</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>    Aggregator--&gt;&gt;Client: 汇总训练结果</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div>",
      "date_published": "2024-10-28T00:00:00.000Z",
      "date_modified": "2024-11-28T10:26:35.000Z",
      "authors": [],
      "tags": [
        "SOSD"
      ]
    },
    {
      "title": "CS149 Lab Assignment1",
      "url": "https://newzone.top/posts/CS149_asst1.html",
      "id": "https://newzone.top/posts/CS149_asst1.html",
      "summary": "Prog1_mandelbort_threads 环境配置 本人使用OS为Ubuntu 22.04, 还是建议使用Linux系统做Lab, 很多环境配置会方便一些. CS149_Asst1并不需要额外配置运行环境, 下载解压一下编译环境就好啦! 下载包: 解压包: 配置环境路径: 环境配置完成后就可以clone repo到本地来开始lab了: 任务分析...",
      "content_html": "<h2>Prog1_mandelbort_threads</h2>\n<h3>环境配置</h3>\n<p>本人使用OS为<code>Ubuntu 22.04</code>, 还是建议使用Linux系统做Lab, 很多环境配置会方便一些.</p>\n<p>CS149_Asst1并不需要额外配置运行环境, 下载解压一下编译环境就好啦!<br>\n下载包:</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    wget https://github.com/ispc/ispc/releases/download/v1.21.0/ispc-v1.21.0-linux.tar.gz</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div><p>解压包:</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    tar -xvf ispc-v1.21.0-linux.tar.gz</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div><p>配置环境路径:</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    export PATH=$PATH:${HOME}/Downloads/ispc-v1.21.0-linux/bin</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div><p>环境配置完成后就可以clone repo到本地来开始lab了:</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    git clone https://github.com/stanford-cs149/asst1.git</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div></div></div><h3>任务分析</h3>\n<blockquote>\n<p>Pro1的内容主要是为了让学生了解<code>std::thread</code>的并行机制和\"多线程不一定高效率\"的并发事实, 所以难度并不算大~~(这是我的事后诸葛亮)~~, 整体框架已经在源码中基本完成了.完成后可以通过<code>make</code> + <code>./mandelbort --&lt;args&gt;</code>检验正确与否.</p>\n</blockquote>\n<p>task :</p>\n<ul>\n<li>创建<code>线程0</code>和<code>线程1</code>, 分别计算图像的上下两个部分, 即<code>将图像的不同空间交给不同线程</code>计算, 这被称为<code>空间分解(spatial decomposition)</code>.</li>\n<li>扩展代码使其能够使用<code>2, 3, 4, 5, 6, 7, 8</code>个线程, 进行空间分解, 生成加速图, 假设加速是否与线程数线性相关并加以验证.</li>\n<li>在<code>workerThreadStart()</code>的开头和结尾插入计时代码, 验证并解释task2中提出的猜想.</li>\n<li>修改一开始的线程分配方式, 实现将两个图片都拉到<code>8线程时7-8倍加速比</code>的效果, 找到适应任何线程数的泛型分配方式(不需要线程之间进行响应和同步), 报告最后得出的8线程加速比.</li>\n<li>使用<code>16个线程</code>运行改进后代码, 回答性能是否明显高于8线程并解释原因.</li>\n</ul>\n<p>事实上task中给的提示还是比较明显的, 在<code>task1</code>中解释了空间分解的概念, 那么通过对图片本身的<code>上下多份分割</code>,就可以解决这个问题,要注意分割的时候会不会漏行.</p>\n<h3>任务实现</h3>\n<p>我们将一开始就对任务给出多线程的解决方式, 并在后续针对数据结果决定是否要进行优化.</p>\n<p>首先我们可以根据阅读<code>mandelbrotSerial.cpp</code>中的源码, 得到mandelbrotSerial()函数事实上是用来计算<code>Mandelbrot</code>图像的, 可以简单分析一下<code>mandelbrotSerial()</code>函数的各个参数:</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    void mandelbrotSerial(</span></span>\n<span class=\"line\"><span>    float x0, float y0, float x1, float y1, // 复平面左上和右下两个点坐标</span></span>\n<span class=\"line\"><span>    int width, int height,                  // 图像宽度和高度</span></span>\n<span class=\"line\"><span>    int startRow, int numRows,              // 开始行和总计算行数</span></span>\n<span class=\"line\"><span>    int maxIterations,                      // 最大迭代次数</span></span>\n<span class=\"line\"><span>    int output[]);                          // 每个点的迭代次数</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>不难发现只要我们给出<code>startRow</code>, <code>numRows</code>, 其余保持图像默认参数, 就可以完成计算了.<br>\n所以可以给出函数<code>workerThreadStart(WorkerArgs * const args)</code>的代码:</p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    size_t rows = args -&gt; height / args -&gt; numThreads;          // 确定要计算的行数</span></span>\n<span class=\"line\"><span>    if (args -&gt; height % args -&gt; numThreads) {                  // 如果该遇到整除要加一行避免遗漏</span></span>\n<span class=\"line\"><span>        rows++;</span></span>\n<span class=\"line\"><span>    }</span></span>\n<span class=\"line\"><span>    size_t startRow = args -&gt; threadId * rows;                  // 确定开始行</span></span>\n<span class=\"line\"><span>    // 如果已经到最后部分不够切分, 直接处理最后部分</span></span>\n<span class=\"line\"><span>    rows = rows &gt; args -&gt; height - startRow ? args -&gt; height - startRow : rows;</span></span>\n<span class=\"line\"><span>    // 调用mandelbrotSerial</span></span>\n<span class=\"line\"><span>    mandelbrotSerial(args -&gt; x0, args -&gt; y0, args -&gt; x1, args -&gt; y1, args -&gt; width, </span></span>\n<span class=\"line\"><span>                    args -&gt; height, startRow, rows, args -&gt; maxIterations, args -&gt; output);</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div>",
      "date_published": "2024-09-18T00:00:00.000Z",
      "date_modified": "2024-09-18T15:50:38.000Z",
      "authors": [],
      "tags": [
        "CS149_Lab"
      ]
    },
    {
      "title": "阶乘的位数估算--数学在计算机算法研究中的作用",
      "url": "https://newzone.top/posts/factorial_Stirling.html",
      "id": "https://newzone.top/posts/factorial_Stirling.html",
      "summary": "题目引入 算法与数据结构实验题 1.10 单身狗进化 这一天晚上，弯通又做梦了，并且梦到了一个帅气的男孩纸！这个男孩给了弯通一个数字 n。男孩离开前告诉弯通，n!（n 的阶乘）的位数就是距离弯通脱单的天数。矜（ji）持（ke）的弯通想知道自己还有多久能脱单，快写个程序帮助他！ 输入: 输入第一行为一个正整数 n（1<=n<=25000）。 输出: n阶...",
      "content_html": "<h2>题目引入</h2>\n<blockquote>\n<p>算法与数据结构实验题 1.10 单身狗进化\n这一天晚上，弯通又做梦了，并且梦到了一个帅气的男孩纸！这个男孩给了弯通一个数字 n。男孩离开前告诉弯通，n!（n 的阶乘）的位数就是距离弯通脱单的天数。矜（ji）持（ke）的弯通想知道自己还有多久能脱单，快写个程序帮助他！<br>\n输入:<br>\n输入第一行为一个正整数 n（1&lt;=n&lt;=25000）。<br>\n输出:<br>\nn阶乘的位数</p>\n</blockquote>\n<h2>题目分析</h2>\n<p>这道题看上去还挺有意思的<s>很符合大学生的心理状态</s>, 实际上就是要求阶乘的位数<s>倒也没有拐弯抹角</s>.<br>\n但是我们都知道, 要是用<code>递归</code>或者<code>循环</code>写阶乘, 这将是一件极为恐怖的事情.<br>\n在数据存储(空间复杂度)&amp;计算用时(时间复杂度)上的开销, 将成为任何一台机器的噩梦, 更不可能过测试了.<br>\n举个栗子:</p>\n<div class=\"language-用循环计算阶乘 line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"用循环计算阶乘\" data-title=\"用循环计算阶乘\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>    int n;</span></span>\n<span class=\"line\"><span>    long long ans = 1;</span></span>\n<span class=\"line\"><span>    std::cin &gt;&gt; n;</span></span>\n<span class=\"line\"><span>    for (int i = 1; i &lt; MAX; i++)</span></span>\n<span class=\"line\"><span>        ans *= i;</span></span>\n<span class=\"line\"><span>    std::cout &lt;&lt; ans;</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>大家可以简单跑一下这个程序, 然后就会发现, 在<code>n = 27</code>的时候, 就已经溢出了, 完全无法满足题目要求.<br>\n这就是第一种错误的可能, 忘记了估计数据规模, 随便算算就存爆了.</p>\n<p>还有一种可能, 就是采用高精度的算法, 将阶乘结果用表存储, 每个内存存有限位数据, 在乘法时做类似竖式乘法的高精度运算.</p>\n<p>这种方式能不能过这个题我没有试过<s>因为我懒</s>, 但是一般来说高精度阶乘的时间复杂度是<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n^{2})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p>程序代码的复杂度和 <code>n = 25000</code> 所要存储的数据规模, 也会是比较大的开销.</p>\n<p>下文将介绍一种用数学方法巧妙估算阶乘结果规模的方式.</p>\n<h2>斯特林公式</h2>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>n</mi><mo stretchy=\"false\">!</mo><mo>≈</mo><msqrt><mrow><mn>2</mn><mi>π</mi><mi>n</mi></mrow></msqrt><mtext> </mtext><msup><mrow><mo fence=\"true\">(</mo><mfrac><mi>n</mi><mi>e</mi></mfrac><mo fence=\"true\">)</mo></mrow><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\nn!\\approx {\\sqrt {2\\pi n}}\\,\\left({\\frac {n}{e}}\\right)^{n} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">!</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8903em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9561em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">2</span><span class=\"mord mathnormal\">πn</span></span></span><span style=\"top:-2.9161em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.0839em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2043em;\"><span style=\"top:-3.6029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>这个公式以<code>詹姆斯·斯特林</code>的名字命名，虽然<code>亚伯拉罕·棣美弗</code>早于斯特林提出了一个类似的公式，但结果较不精确.<br>\n当n很大的时候，n阶乘的计算量十分大，所以斯特林公式十分好用，而且，即使在n很小的时候，斯特林公式的取值已经十分准确.</p>\n<p>可以通过计算对比来估计一下斯特林公式算出结果, 和阶乘计算结果的误差程度.</p>\n<p></p>\n<p>我们可以看到, 随着n的增大, 斯特林公式估算的误差已经降到了十万分之一以下, 这对估算阶乘的规模来说是完全可以接受的误差.</p>\n<p>通过斯特林公式我们可以简单估算阶乘的位数, 我们知道对于一个n进制数x, 都可以对其取$ [\\log_{n}x] + 1 $来得到这个n进制数的位数, 我们将进一步推导<code>用斯特林公式估算阶乘位数N</code>的公式.</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>N</mi><mo>=</mo><mo stretchy=\"false\">[</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>10</mn></msub><mo stretchy=\"false\">[</mo><msqrt><mrow><mn>2</mn><mi>π</mi><mi>n</mi></mrow></msqrt><mtext> </mtext><msup><mrow><mo fence=\"true\">(</mo><mfrac><mi>n</mi><mi>e</mi></mfrac><mo fence=\"true\">)</mo></mrow><mi>n</mi></msup><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">]</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\nN = [log_{10}[{\\sqrt {2\\pi n}}\\,\\left({\\frac {n}{e}}\\right)^{n}]] + 1 \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8903em;vertical-align:-0.686em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">10</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9561em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">2</span><span class=\"mord mathnormal\">πn</span></span></span><span style=\"top:-2.9161em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.0839em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2043em;\"><span style=\"top:-3.6029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]]</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span></p>\n<p>其中内层中括号标记运算顺序, 外层中括号意为高斯取整(即向下取整).</p>\n<p v-pre=\"\" class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>N</mi><mo>=</mo><mo stretchy=\"false\">[</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>10</mn></msub><mo stretchy=\"false\">(</mo><mn>2</mn><mi>π</mi><mi>n</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>n</mi><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>10</mn></msub><mo stretchy=\"false\">(</mo><mfrac><mi>n</mi><mi>e</mi></mfrac><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\nN = [\\frac{1}{2}log_{10}(2\\pi n) + nlog_{10}(\\frac{n}{e})] + 1 \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0074em;vertical-align:-0.686em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">10</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">2</span><span class=\"mord mathnormal\">πn</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.7936em;vertical-align:-0.686em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">10</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)]</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span></p>\n<p>通过代入n, 即可轻松求得<span v-pre=\"\" class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo stretchy=\"false\">!</mo></mrow><annotation encoding=\"application/x-tex\">n!</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">!</span></span></span></span>的位数, 时间复杂度是梦寐以求的O(1), 即常数时间复杂度.</p>\n<h2>代码实现</h2>\n<p>代码实现没什么好说的, 套公式罢了, 由于我之前已经测试过最大数据规模, 所以<code>ans</code>也是为了省事儿用的<code>int</code><s>偷懒是可耻的</s></p>\n<div class=\"language- line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"\" data-title=\"\" style=\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\"><pre class=\"shiki shiki-themes github-light one-dark-pro vp-code\"><code><span class=\"line\"><span>  #include &lt;stdio.h&gt;</span></span>\n<span class=\"line\"><span>  #include &lt;math.h&gt;</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>  #define PI 3.141592654</span></span>\n<span class=\"line\"><span>  #define E 2.71828182846</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>  int pos(int n)</span></span>\n<span class=\"line\"><span>  {</span></span>\n<span class=\"line\"><span>      int s = 1;</span></span>\n<span class=\"line\"><span>      if(n &gt; 3)</span></span>\n<span class=\"line\"><span>          s = log10(2*PI*n) / 2 + n * log10(n/E) + 1;</span></span>\n<span class=\"line\"><span>      return s;</span></span>\n<span class=\"line\"><span>  }</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>  int main()</span></span>\n<span class=\"line\"><span>  {</span></span>\n<span class=\"line\"><span>      int num, ans;</span></span>\n<span class=\"line\"><span>      scanf(\"%d\", &amp;num);</span></span>\n<span class=\"line\"><span>      ans = pos(num);</span></span>\n<span class=\"line\"><span>      printf(\"%d\", ans);</span></span>\n<span class=\"line\"><span>  }</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2>总结</h2>\n<blockquote>\n<p>数即一切</p>\n</blockquote>\n",
      "date_published": "2024-09-17T00:00:00.000Z",
      "date_modified": "2024-09-17T08:16:53.000Z",
      "authors": [],
      "tags": [
        "数据结构与算法"
      ]
    },
    {
      "title": "CS149_Course",
      "url": "https://newzone.top/posts/CS149.html",
      "id": "https://newzone.top/posts/CS149.html",
      "content_html": "",
      "date_published": "2024-09-16T00:00:00.000Z",
      "date_modified": "2024-09-17T03:06:27.000Z",
      "authors": [],
      "tags": [
        "CS149"
      ]
    }
  ]
}