const V=Object.entries,et=Object.fromEntries,st="ENTRIES",L="KEYS",T="VALUES",_="";class D{set;_type;_path;constructor(t,s){const n=t._tree,o=Array.from(n.keys());this.set=t,this._type=s,this._path=o.length>0?[{node:n,keys:o}]:[]}next(){const t=this.dive();return this.backtrack(),t}dive(){if(this._path.length===0)return{done:!0,value:void 0};const{node:t,keys:s}=E(this._path);if(E(s)===_)return{done:!1,value:this.result()};const n=t.get(E(s));return this._path.push({node:n,keys:Array.from(n.keys())}),this.dive()}backtrack(){if(this._path.length===0)return;const t=E(this._path).keys;t.pop(),!(t.length>0)&&(this._path.pop(),this.backtrack())}key(){return this.set._prefix+this._path.map(({keys:t})=>E(t)).filter(t=>t!==_).join("")}value(){return E(this._path).node.get(_)}result(){switch(this._type){case T:return this.value();case L:return this.key();default:return[this.key(),this.value()]}}[Symbol.iterator](){return this}}const E=e=>e[e.length-1],nt=(e,t,s)=>{const n=new Map;if(t===void 0)return n;const o=t.length+1,u=o+s,i=new Uint8Array(u*o).fill(s+1);for(let r=0;r<o;++r)i[r]=r;for(let r=1;r<u;++r)i[r*o]=r;return R(e,t,s,n,i,1,o,""),n},R=(e,t,s,n,o,u,i,r)=>{const d=u*i;t:for(const c of e.keys())if(c===_){const a=o[d-1];a<=s&&n.set(r,[e.get(c),a])}else{let a=u;for(let h=0;h<c.length;++h,++a){const g=c[h],m=i*a,p=m-i;let l=o[m];const f=Math.max(0,a-s-1),y=Math.min(i-1,a+s);for(let F=f;F<y;++F){const v=g!==t[F],z=o[p+F]+ +v,A=o[p+F+1]+1,w=o[m+F]+1,j=o[m+F+1]=Math.min(z,A,w);j<l&&(l=j)}if(l>s)continue t}R(e.get(c),t,s,n,o,a,i,r+c)}};class C{_tree;_prefix;_size=void 0;constructor(t=new Map,s=""){this._tree=t,this._prefix=s}atPrefix(t){if(!t.startsWith(this._prefix))throw new Error("Mismatched prefix");const[s,n]=x(this._tree,t.slice(this._prefix.length));if(s===void 0){const[o,u]=O(n);for(const i of o.keys())if(i!==_&&i.startsWith(u)){const r=new Map;return r.set(i.slice(u.length),o.get(i)),new C(r,t)}}return new C(s,t)}clear(){this._size=void 0,this._tree.clear()}delete(t){return this._size=void 0,ot(this._tree,t)}entries(){return new D(this,st)}forEach(t){for(const[s,n]of this)t(s,n,this)}fuzzyGet(t,s){return nt(this._tree,t,s)}get(t){const s=k(this._tree,t);return s!==void 0?s.get(_):void 0}has(t){const s=k(this._tree,t);return s!==void 0&&s.has(_)}keys(){return new D(this,L)}set(t,s){if(typeof t!="string")throw new Error("key must be a string");return this._size=void 0,I(this._tree,t).set(_,s),this}get size(){if(this._size)return this._size;this._size=0;const t=this.entries();for(;!t.next().done;)this._size+=1;return this._size}update(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=I(this._tree,t);return n.set(_,s(n.get(_))),this}fetch(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=I(this._tree,t);let o=n.get(_);return o===void 0&&n.set(_,o=s()),o}values(){return new D(this,T)}[Symbol.iterator](){return this.entries()}static from(t){const s=new C;for(const[n,o]of t)s.set(n,o);return s}static fromObject(t){return C.from(Object.entries(t))}}const x=(e,t,s=[])=>{if(t.length===0||e==null)return[e,s];for(const n of e.keys())if(n!==_&&t.startsWith(n))return s.push([e,n]),x(e.get(n),t.slice(n.length),s);return s.push([e,t]),x(void 0,"",s)},k=(e,t)=>{if(t.length===0||e==null)return e;for(const s of e.keys())if(s!==_&&t.startsWith(s))return k(e.get(s),t.slice(s.length))},I=(e,t)=>{const s=t.length;t:for(let n=0;e&&n<s;){for(const u of e.keys())if(u!==_&&t[n]===u[0]){const i=Math.min(s-n,u.length);let r=1;for(;r<i&&t[n+r]===u[r];)++r;const d=e.get(u);if(r===u.length)e=d;else{const c=new Map;c.set(u.slice(r),d),e.set(t.slice(n,n+r),c),e.delete(u),e=c}n+=r;continue t}const o=new Map;return e.set(t.slice(n),o),o}return e},ot=(e,t)=>{const[s,n]=x(e,t);if(s!==void 0){if(s.delete(_),s.size===0)W(n);else if(s.size===1){const[o,u]=s.entries().next().value;q(n,o,u)}}},W=e=>{if(e.length===0)return;const[t,s]=O(e);if(t.delete(s),t.size===0)W(e.slice(0,-1));else if(t.size===1){const[n,o]=t.entries().next().value;n!==_&&q(e.slice(0,-1),n,o)}},q=(e,t,s)=>{if(e.length===0)return;const[n,o]=O(e);n.set(o+t,s),n.delete(o)},O=e=>e[e.length-1],ut=(e,t)=>{const s=e._idToShortId.get(t);if(s!=null)return e._storedFields.get(s)},it=/[\n\r -#%-*,-/:;?@[-\]_{}\u00A0\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u1680\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2000-\u200A\u2010-\u2029\u202F-\u2043\u2045-\u2051\u2053-\u205F\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u3000-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]+/u,M="or",$="and",rt="and_not",ct=(e,t)=>{e.includes(t)||e.push(t)},N=(e,t)=>{for(const s of t)e.includes(s)||e.push(s)},P=({score:e},{score:t})=>t-e,lt=()=>new Map,b=e=>{const t=new Map;for(const s of Object.keys(e))t.set(parseInt(s,10),e[s]);return t},G=(e,t)=>Object.prototype.hasOwnProperty.call(e,t)?e[t]:void 0,ht={[M]:(e,t)=>{for(const s of t.keys()){const n=e.get(s);if(n==null)e.set(s,t.get(s));else{const{score:o,terms:u,match:i}=t.get(s);n.score=n.score+o,n.match=Object.assign(n.match,i),N(n.terms,u)}}return e},[$]:(e,t)=>{const s=new Map;for(const n of t.keys()){const o=e.get(n);if(o==null)continue;const{score:u,terms:i,match:r}=t.get(n);N(o.terms,i),s.set(n,{score:o.score+u,terms:o.terms,match:Object.assign(o.match,r)})}return s},[rt]:(e,t)=>{for(const s of t.keys())e.delete(s);return e}},dt=(e,t,s,n,o,u)=>{const{k:i,b:r,d}=u;return Math.log(1+(s-t+.5)/(t+.5))*(d+e*(i+1)/(e+i*(1-r+r*n/o)))},at=e=>(t,s,n)=>{const o=typeof e.fuzzy=="function"?e.fuzzy(t,s,n):e.fuzzy||!1,u=typeof e.prefix=="function"?e.prefix(t,s,n):e.prefix===!0;return{term:t,fuzzy:o,prefix:u}},H=(e,t,s,n)=>{for(const o of Object.keys(e._fieldIds))if(e._fieldIds[o]===s){e._options.logger("warn",`SlimSearch: document with ID ${e._documentIds.get(t)} has changed before removal: term "${n}" was not present in field "${o}". Removing a document after it has changed can corrupt the index!`,"version_conflict");return}},ft=(e,t,s,n)=>{if(!e._index.has(n)){H(e,s,t,n);return}const o=e._index.fetch(n,lt),u=o.get(t);u==null||u.get(s)==null?H(e,s,t,n):u.get(s)<=1?u.size<=1?o.delete(t):u.delete(s):u.set(s,u.get(s)-1),e._index.get(n).size===0&&e._index.delete(n)},gt={k:1.2,b:.7,d:.5},mt={idField:"id",extractField:(e,t)=>e[t],tokenize:e=>e.split(it),processTerm:e=>e.toLowerCase(),fields:void 0,searchOptions:void 0,storeFields:[],logger:(e,t)=>{typeof console?.[e]=="function"&&console[e](t)},autoVacuum:!0},J={combineWith:M,prefix:!1,fuzzy:!1,maxFuzzy:6,boost:{},weights:{fuzzy:.45,prefix:.375},bm25:gt},pt={combineWith:$,prefix:(e,t,s)=>t===s.length-1},Ft={batchSize:1e3,batchWait:10},U={minDirtFactor:.1,minDirtCount:20},_t={...Ft,...U},K=Symbol("*"),yt=(e,t)=>{const s=new Map,n={...e._options.searchOptions,...t};for(const[o,u]of e._documentIds){const i=n.boostDocument?n.boostDocument(u,"",e._storedFields.get(o)):1;s.set(o,{score:i,terms:[],match:{}})}return s},X=(e,t=M)=>{if(e.length===0)return new Map;const s=t.toLowerCase(),n=ht[s];if(!n)throw new Error(`Invalid combination operator: ${t}`);return e.reduce(n)||new Map},S=(e,t,s,n,o,u,i,r,d=new Map)=>{if(o==null)return d;for(const c of Object.keys(u)){const a=u[c],h=e._fieldIds[c],g=o.get(h);if(g==null)continue;let m=g.size;const p=e._avgFieldLength[h];for(const l of g.keys()){if(!e._documentIds.has(l)){ft(e,h,l,s),m-=1;continue}const f=i?i(e._documentIds.get(l),s,e._storedFields.get(l)):1;if(!f)continue;const y=g.get(l),F=e._fieldLength.get(l)[h],v=dt(y,m,e._documentCount,F,p,r),z=n*a*f*v,A=d.get(l);if(A){A.score+=z,ct(A.terms,t);const w=G(A.match,s);w?w.push(c):A.match[s]=[c]}else d.set(l,{score:z,terms:[t],match:{[s]:[c]}})}}return d},At=(e,t,s)=>{const n={...e._options.searchOptions,...s},o=(n.fields||e._options.fields).reduce((l,f)=>({...l,[f]:G(n.boost,f)||1}),{}),{boostDocument:u,weights:i,maxFuzzy:r,bm25:d}=n,{fuzzy:c,prefix:a}={...J.weights,...i},h=e._index.get(t.term),g=S(e,t.term,t.term,1,h,o,u,d);let m,p;if(t.prefix&&(m=e._index.atPrefix(t.term)),t.fuzzy){const l=t.fuzzy===!0?.2:t.fuzzy,f=l<1?Math.min(r,Math.round(t.term.length*l)):l;f&&(p=e._index.fuzzyGet(t.term,f))}if(m)for(const[l,f]of m){const y=l.length-t.term.length;if(!y)continue;p?.delete(l);const F=a*l.length/(l.length+.3*y);S(e,t.term,l,F,f,o,u,d,g)}if(p)for(const l of p.keys()){const[f,y]=p.get(l);if(!y)continue;const F=c*l.length/(l.length+y);S(e,t.term,l,F,f,o,u,d,g)}return g},Y=(e,t,s={})=>{if(t===K)return yt(e,s);if(typeof t!="string"){const a={...s,...t,queries:void 0},h=t.queries.map(g=>Y(e,g,a));return X(h,a.combineWith)}const{tokenize:n,processTerm:o,searchOptions:u}=e._options,i={tokenize:n,processTerm:o,...u,...s},{tokenize:r,processTerm:d}=i,c=r(t).flatMap(a=>d(a)).filter(a=>!!a).map(at(i)).map(a=>At(e,a,i));return X(c,i.combineWith)},Q=(e,t,s={})=>{const n=Y(e,t,s),o=[];for(const[u,{score:i,terms:r,match:d}]of n){const c=r.length||1,a={id:e._documentIds.get(u),score:i*c,terms:Object.keys(d),queryTerms:r,match:d};Object.assign(a,e._storedFields.get(u)),(s.filter==null||s.filter(a))&&o.push(a)}return t===K&&s.boostDocument==null&&e._options.searchOptions.boostDocument==null||o.sort(P),o},Ct=(e,t,s={})=>{s={...e._options.autoSuggestOptions,...s};const n=new Map;for(const{score:u,terms:i}of Q(e,t,s)){const r=i.join(" "),d=n.get(r);d!=null?(d.score+=u,d.count+=1):n.set(r,{score:u,terms:i,count:1})}const o=[];for(const[u,{score:i,terms:r,count:d}]of n)o.push({suggestion:u,terms:r,score:i/d});return o.sort(P),o};class Et{_options;_index;_documentCount;_documentIds;_idToShortId;_fieldIds;_fieldLength;_avgFieldLength;_nextId;_storedFields;_dirtCount;_currentVacuum;_enqueuedVacuum;_enqueuedVacuumConditions;constructor(t){if(t?.fields==null)throw new Error('SlimSearch: option "fields" must be provided');const s=t.autoVacuum==null||t.autoVacuum===!0?_t:t.autoVacuum;this._options={...mt,...t,autoVacuum:s,searchOptions:{...J,...t.searchOptions||{}},autoSuggestOptions:{...pt,...t.autoSuggestOptions||{}}},this._index=new C,this._documentCount=0,this._documentIds=new Map,this._idToShortId=new Map,this._fieldIds={},this._fieldLength=new Map,this._avgFieldLength=[],this._nextId=0,this._storedFields=new Map,this._dirtCount=0,this._currentVacuum=null,this._enqueuedVacuum=null,this._enqueuedVacuumConditions=U,this.addFields(this._options.fields)}get isVacuuming(){return this._currentVacuum!=null}get dirtCount(){return this._dirtCount}get dirtFactor(){return this._dirtCount/(1+this._documentCount+this._dirtCount)}get documentCount(){return this._documentCount}get termCount(){return this._index.size}toJSON(){const t=[];for(const[s,n]of this._index){const o={};for(const[u,i]of n)o[u]=Object.fromEntries(i);t.push([s,o])}return{documentCount:this._documentCount,nextId:this._nextId,documentIds:Object.fromEntries(this._documentIds),fieldIds:this._fieldIds,fieldLength:Object.fromEntries(this._fieldLength),averageFieldLength:this._avgFieldLength,storedFields:Object.fromEntries(this._storedFields),dirtCount:this._dirtCount,index:t,serializationVersion:2}}addFields(t){for(let s=0;s<t.length;s++)this._fieldIds[t[s]]=s}}const zt=({index:e,documentCount:t,nextId:s,documentIds:n,fieldIds:o,fieldLength:u,averageFieldLength:i,storedFields:r,dirtCount:d,serializationVersion:c},a)=>{if(c!==1&&c!==2)throw new Error("SlimSearch: cannot deserialize an index created with an incompatible version");const h=new Et(a);h._documentCount=t,h._nextId=s,h._documentIds=b(n),h._idToShortId=new Map,h._fieldIds=o,h._fieldLength=b(u),h._avgFieldLength=i,h._storedFields=b(r),h._dirtCount=d||0,h._index=new C;for(const[g,m]of h._documentIds)h._idToShortId.set(m,g);for(const[g,m]of e){const p=new Map;for(const l of Object.keys(m)){let f=m[l];c===1&&(f=f.ds),p.set(parseInt(l,10),b(f))}h._index.set(g,p)}return h},B=(e,t)=>{const s=e.toLowerCase(),n=t.toLowerCase(),o=[];let u=0,i=0;const r=(c,a=!1)=>{let h="";i===0?h=c.length>20?`… ${c.slice(-20)}`:c:a?h=c.length+i>100?`${c.slice(0,100-i)}… `:c:h=c.length>20?`${c.slice(0,20)} … ${c.slice(-20)}`:c,h&&o.push(h),i+=h.length,a||(o.push(["mark",t]),i+=t.length,i>=100&&o.push(" …"))};let d=s.indexOf(n,u);if(d===-1)return null;for(;d>=0;){const c=d+n.length;if(r(e.slice(u,d)),u=c,i>100)break;d=s.indexOf(n,u)}return i<100&&r(e.slice(u),!0),o},wt=(e,t)=>t.contents.reduce((s,[,n])=>s+n,0)-e.contents.reduce((s,[,n])=>s+n,0),xt=(e,t)=>Math.max(...t.contents.map(([,s])=>s))-Math.max(...e.contents.map(([,s])=>s)),Z=(e,t,s={})=>{const n={};return Q(t,e,{boost:{h:2,t:1,c:4},prefix:!0,...s}).forEach(o=>{const{id:u,terms:i,score:r}=o,d=u.includes("@"),c=u.includes("#"),[a,h]=u.split(/[#@]/),g=Number(a),m=i.sort((l,f)=>l.length-f.length).filter((l,f)=>i.slice(f+1).every(y=>!y.includes(l))),{contents:p}=n[g]??={title:"",contents:[]};if(d)p.push([{type:"customField",id:g,index:h,display:m.map(l=>o.c.map(f=>B(f,l))).flat().filter(l=>l!==null)},r]);else{const l=m.map(f=>B(o.h,f)).filter(f=>f!==null);if(l.length&&p.push([{type:c?"heading":"title",id:g,...c&&{anchor:h},display:l},r]),"t"in o)for(const f of o.t){const y=m.map(F=>B(f,F)).filter(F=>F!==null);y.length&&p.push([{type:"text",id:g,...c&&{anchor:h},display:y},r])}}}),V(n).sort(([,o],[,u])=>"max"==="total"?wt(o,u):xt(o,u)).map(([o,{title:u,contents:i}])=>{if(!u){const r=ut(t,o);r&&(u=r.h)}return{title:u,contents:i.map(([r])=>r)}})},tt=(e,t,s={})=>{const n=Ct(t,e,{fuzzy:.2,maxFuzzy:3,...s}).map(({suggestion:o})=>o);return e.includes(" ")?n:n.filter(o=>!o.includes(" "))},bt=et(V(JSON.parse("{\"/\":{\"documentCount\":96,\"nextId\":96,\"documentIds\":{\"0\":\"1\",\"1\":\"2\",\"2\":\"2#为什么ai需要分布式系统\",\"3\":\"2#什么是分布式系统\",\"4\":\"2#为什么ai训练需要分布式系统\",\"5\":\"2#分布式系统如何发挥作用\",\"6\":\"2#数据分布式的一些基本想法\",\"7\":\"2#数据并行-dp\",\"8\":\"2#典型数据并行的流程\",\"9\":\"2#horovod\",\"10\":\"2#ring-allreduce\",\"11\":\"2#reduce-scatter\",\"12\":\"2#all-gather\",\"13\":\"2#horovod工作\",\"14\":\"2#使用方法\",\"15\":\"2#pytorch-ddp\",\"16\":\"2#python前端api\",\"17\":\"2#梯度同步算法\",\"18\":\"2#传统做法\",\"19\":\"2#改进做法\",\"20\":\"2#集合通讯库\",\"21\":\"2#fsdp并行\",\"22\":\"2#zero\",\"23\":\"2#abstract\",\"24\":\"2#extended-introduction\",\"25\":\"2#where-did-all-the-memory-go\",\"26\":\"2#model-states-optimizer-states-gradients-and-parameters\",\"27\":\"2#residual-memory-consumption\",\"28\":\"2#temporary-buffers\",\"29\":\"2#memory-fragmentation\",\"30\":\"2#zero-insights-and-overview\",\"31\":\"2#insights-and-overview-zero-dp\",\"32\":\"2#insights-and-overview-zero-r\",\"33\":\"2#reducing-activation-memory\",\"34\":\"2#managing-temporary-buffers\",\"35\":\"2#managing-fragmented-memory\",\"36\":\"2#deep-dive-into-zero-dp\",\"37\":\"2#zero1\",\"38\":\"2#zero2\",\"39\":\"2#zero3\",\"40\":\"2#deep-dive-into-zero-r\",\"41\":\"2#partitioned-activation-checkpointing\",\"42\":\"2#constant-size-buffers\",\"43\":\"2#memory-defragmentation\",\"44\":\"2#zero-offload\",\"45\":\"2#背景\",\"46\":\"2#efficiency\",\"47\":\"2#unique-optimal-offload-strategy\",\"48\":\"2#zero-offload-schedule\",\"49\":\"2#单卡策略\",\"50\":\"2#多卡策略\",\"51\":\"2#流水线并行\",\"52\":\"2#gpipe\",\"53\":\"2#gpipe-abstract\",\"54\":\"2#design\",\"55\":\"2#naive-model-parallelism\",\"56\":\"2#pipeline-parallelism-1-split-into-micro-batches\",\"57\":\"2#pipeline-parallelism-2-re-materialization\",\"58\":\"2#张量并行-tp\",\"59\":\"2#megatron-lm\",\"60\":\"2#model-parallel-transformers\",\"61\":\"2#_3d并行\",\"62\":\"2#贡献\",\"63\":\"2#数据并行\",\"64\":\"2#考虑流水线并行\",\"65\":\"2#考虑张量并行\",\"66\":\"2#性能分析\",\"67\":\"2#自动并行\",\"68\":\"2#flexflow\",\"69\":\"2#简介\",\"70\":\"2#概述\",\"71\":\"2#执行模拟器\",\"72\":\"2#执行优化器\",\"73\":\"2@0\",\"74\":\"2@1\",\"75\":\"3\",\"76\":\"3@0\",\"77\":\"3@1\",\"78\":\"4\",\"79\":\"4#prog1-mandelbort-threads\",\"80\":\"4#环境配置\",\"81\":\"4#任务分析\",\"82\":\"4#任务实现\",\"83\":\"4@0\",\"84\":\"4@1\",\"85\":\"5\",\"86\":\"5#题目引入\",\"87\":\"5#题目分析\",\"88\":\"5#斯特林公式\",\"89\":\"5#代码实现\",\"90\":\"5#总结\",\"91\":\"5@0\",\"92\":\"5@1\",\"93\":\"6\",\"94\":\"7\",\"95\":\"8\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[1,8],\"1\":[2],\"2\":[1],\"3\":[1,13],\"4\":[1,24],\"5\":[1],\"6\":[1,83],\"7\":[3],\"8\":[1,16],\"9\":[1,31],\"10\":[2,8],\"11\":[2,14],\"12\":[2,3],\"13\":[1,22],\"14\":[1,62],\"15\":[2,18],\"16\":[1,64],\"17\":[1,3],\"18\":[1,5],\"19\":[1,32],\"20\":[1,28],\"21\":[1],\"22\":[1,18],\"23\":[1,15],\"24\":[2,24],\"25\":[6,8],\"26\":[6,41],\"27\":[3],\"28\":[2,3],\"29\":[2,6],\"30\":[4,2],\"31\":[5,17],\"32\":[5],\"33\":[3,11],\"34\":[3,2],\"35\":[4,2],\"36\":[5],\"37\":[1,4],\"38\":[1,4],\"39\":[1,13],\"40\":[5],\"41\":[3,12],\"42\":[3,3],\"43\":[2,4],\"44\":[2,14],\"45\":[1,16],\"46\":[1,34],\"47\":[4,52],\"48\":[3],\"49\":[1,103],\"50\":[1,40],\"51\":[1],\"52\":[1,16],\"53\":[2,21],\"54\":[1],\"55\":[3,44],\"56\":[7,13],\"57\":[5,8],\"58\":[3],\"59\":[2,20],\"60\":[3,137],\"61\":[1,21],\"62\":[1,20],\"63\":[1,7],\"64\":[1,28],\"65\":[1,2],\"66\":[1,48],\"67\":[1],\"68\":[1,28],\"69\":[1,39],\"70\":[1,46],\"71\":[1,11],\"72\":[1,22],\"73\":[null,null,1],\"74\":[null,null,3],\"75\":[2],\"76\":[null,null,1],\"77\":[null,null,2],\"78\":[3],\"79\":[3],\"80\":[1,38],\"81\":[1,46],\"82\":[1,51],\"83\":[null,null,2],\"84\":[null,null,3],\"85\":[2],\"86\":[1,23],\"87\":[1,52],\"88\":[1,45],\"89\":[1,33],\"90\":[1,1],\"91\":[null,null,1],\"92\":[null,null,2],\"93\":[1,3],\"94\":[1],\"95\":[1]},\"averageFieldLength\":[1.9506021393782431,23.856879202891868,0.176217302691686],\"storedFields\":{\"0\":{\"h\":\"个人介绍\",\"t\":[\"计算机大二本科小白，\",\"主攻CV/NLP等AI方向，\",\"同时对分布式开发、并行运算感兴趣，\",\"算法还是0基础新人，\",\"路漫漫其修远兮。\"]},\"1\":{\"h\":\"AISys_分布式开发\"},\"2\":{\"h\":\"为什么AI需要分布式系统\"},\"3\":{\"h\":\"什么是分布式系统\",\"t\":[\"分布式系统顾名思义，就是将单一计算机节点要做的任务分布在多个计算机节点上完成的，各个节点之间通过网络进行通讯的计算机系统。\",\"这种系统的好处是显而易见的，我们可以把一台机器的Task进行切分，可能大幅度提升计算效率；我们可以把一台机器存不下的任务放到多个结点里面，拓展数据规模。\",\"但同时也可能引入更多的问题，多台机器之间通讯耗费的时间会不会比原先计算的时间更长？切分后的任务如何再将结果重新合在一起？这些都问题都有进一步研究的价值。\"]},\"4\":{\"h\":\"为什么AI训练需要分布式系统\",\"t\":[\"在训练AI时，无论在CV方向还是NLP等其他方向，无论使用哪一种模型，总是绕不开训练集和测试集这两部分，我们总要拿出一部分数据用来预训练模型，另一部分用来测试模型效果。\",\"数据集越大，训练效果越好，这基本上是在不考虑机器性能上限的情况下，我们针对AI训练达成的一种共识，所以在训练AI时我们希望能使用尽可能大的数据集，使用尽可能多的参数，来对尽可能多的标签进行刻画。但可惜一台机器的性能总是有限的。\",\"这个时候就不得不引入分布式系统来改善这种局面了，如果我们一台机器、一张GPU/TPU没办法高效完成我们的运算，那我们可以分到多张卡上面；如果我们一台机器存储不开我们的数据集，那我们可以分到多台设备上，或者考虑让CPU也存储一部分模型数据。这就是AI使用分布式系统想要解决的问题。\"]},\"5\":{\"h\":\"分布式系统如何发挥作用\"},\"6\":{\"h\":\"数据分布式的一些基本想法\",\"t\":[\"如果我们希望分布式系统在AI训练中发挥他的力量，我们要怎么做呢？大家都对ML有一些基本的认识了，无论哪一种模型，在训练过程中总会有数据（输入、输出），模型（参数、激活函数）等等需要保存的东西。\",\"现在假定我们要做一个训练任务，我们有我们自己的很大的数据集，我希望能把这个数据很快的训练完，那我们就可以考虑把数据切分成好几份，然后给不同的GPU去算每一个单独的部分，这种每个一份数据切分成多份，给不同的GPU做计算的方式，但每一个GPU均做保留完整的模型做计算，被我们称作数据并行（Data Patallel，简称DP）。\",\"既然可能有很大的数据集需要切分，那自然也可能有很大的模型进行切分，让每一个GPU仅保留几个隐藏层的模型（参数、激活函数），这样可以训练更大的模型，提升训练精度，这种按层切分模型，不切分数据的方式，被称作模型并行（Model Patallel，简称MP）。\",\"这种按层切分的方式固然可以增加可容纳的模型的大小，但是仅让一个卡存模型的几层在计算某些必须要用到之前的数据的模型时可能不尽如人意，通讯成本会比较高昂。\",\"为了解决层切分的弊端，我们可以考虑将计算过程中的算子/计算矩阵进行切分，让每一张卡只保留必须的参数和算子，产生部分输出，这样就可以将每一部分计算矩阵进行并发处理，我们将这种方式称作张量并行/算子并行（Tensor Patallel，简称TP），谷歌专门为TP开发了TPU进行并发适配，TP也是应用较广的基本并发方式。\",\"既然我们有了对数据切分的方法，有了对模型算子切分的方法，那我们也可以考虑进行结合，既切分优化器状态，又切分模型的参数、梯度，这种并行方式被称作完全分片数据并行（Fully Sharded Data Parallel，简称FSDP）。\",\"前面所提及的方法，是在利用切分层内数据/优化器状态/模型绕过MP方法按层切分时可能带来的通讯瓶颈，但是也可以利用类似CPU指令流水线执行的方式，进行数据计算，切分模型让不同GPU延后计算开始时间，从而保证通讯无boundary，这种方式被称作流水线并行（Pipe Parallel，简称PP）。\",\"在探讨了DP、PP、TP基本并行方式后，我们可以考虑将三种并行方式进行综合，考虑一些综合利用并行方式的策略，这种并行考量被称为3D并行。\",\"事实上对于采用哪种并行模式，要用多少张卡进行并行，并行中使用的参数如何调整，是一件非常复杂的事情，我们期望有可以自动为我们选定并行方法的策略，这种策略被称作自动并行。\"]},\"7\":{\"h\":\"数据并行（DP）\"},\"8\":{\"h\":\"典型数据并行的流程\",\"t\":[\"分配n块计算GPU（图中0-2）;1块梯度收集GPU\",\"每块GPU均拷贝一份完整的模型\",\"把一份Data（也可以是一个batch）切分成若干份给不同的GPU\",\"每一块GPU完成Forward和Backward后，计算出本地的梯度\",\"把本地梯度push到梯度收集GPU，梯度收集GPU聚合梯度\",\"计算GPU从聚合GPU中pull完整梯度，更新模型参数，保证各个计算GPU模型同步\",\"聚合再下发梯度操作被称为AllReduce\"]},\"9\":{\"h\":\"Horovod\",\"t\":[\"Horovod: fast and easy distributed deep learning in TensorFlow\",\"https://arxiv.org/abs/1802.05799https://github.com/uber/horovod\",\"传统的DP在带来使用大数据集可能的同时，又同时增加了额外的通讯开销，本文还指出DP代码重构成本较大。\",\"本文通过在不同数量卡上训练结果进行说明：\",\"可以明显看到GPU数量增多时，TensorFlow框架下的通讯开销越大，在128卡时甚至已经超过训练开销。\",\"为了解决传统DP计算节点和聚合节点比例不好确定导致的通讯成本/计算成本过大的问题，本文指出了ring-allreduce的方式。\"]},\"10\":{\"h\":\"Ring-AllReduce\",\"t\":[\"假设有4块GPU，每块GPU上的数据也对应被切成4份。AllReduce就是要让每块GPU上的数据都变成箭头右边汇总的样子。\",\"Ring-AllReduce将这个过程分为Reduce-Scatter和All-Gather。\"]},\"11\":{\"h\":\"Reduce-Scatter\",\"t\":[\"定义网络拓扑关系，使得每个GPU只和其相邻的两块GPU通讯。每次发送对应位置的数据进行累加。每一次累加更新都形成一个拓扑环。\",\"3次更新之后，每块GPU上都有一块数据拥有了对应位置完整的聚合（图中红色）。此时，Reduce-Scatter阶段结束。进入All-Gather阶段。目标是把红色块的数据广播到其余GPU对应的位置上。\"]},\"12\":{\"h\":\"All-Gather\",\"t\":[\"相邻GPU对应位置进行通讯，对应位置数据不再做相加，而是直接替换\"]},\"13\":{\"h\":\"Horovod工作\",\"t\":[\"将百度的 TensorFlow ring-allreduce 算法的实现转化为一个独立的 Python 包，命名为 Horovod\",\"使用 NCCL 库实现了 TensorFlow ring-allreduce，并优化了性能\",\"添加了对单机多卡的支持\",\"改进了 API，添加 broadcast 操作，仅需 4 步即可使用 Horovod\"]},\"14\":{\"h\":\"使用方法\",\"t\":[\"import tensorflow as tf import horovod.tensorflow as hvd # 初始化 Horovod hvd.init() # 固定 GPU 以处理本地 rank（每个进程一个 GPU） config = tf.ConfigProto() config.gpu_options.visible_device_list = str(hvd.local_rank()) # 构建模型... loss = ... opt = tf.train.AdagradOptimizer(0.01) # 添加 Horovod 分布式优化器 opt = hvd.DistributedOptimizer(opt) # 添加hook，在初始化期间将变量从 rank 0 广播到所有其他进程 hooks = [hvd.BroadcastGlobalVariablesHook(0)] # 创建训练操作 train_op = opt.minimize(loss) # MonitoredTrainingSession 负责会话初始化、从检查点恢复、保存到检查点以及在完成或发生错误时关闭 with tf.train.MonitoredTrainingSession(checkpoint_dir=\\\"/tmp/train_logs\\\", config=config, hooks=hooks) as mon_sess: while not mon_sess.should_stop(): # 执行同步训练 mon_sess.run(train_op)\"]},\"15\":{\"h\":\"PyTorch DDP\",\"t\":[\"PyTorch Distributed: Experiences on Accelerating Data Parallel Training\",\"https://arxiv.org/abs/2006.15704https://github.com/pytorch/pytorch/\"]},\"16\":{\"h\":\"Python前端API\",\"t\":[\" 1 import torch 2 import torch.nn as nn 3 import torch.nn.parallel as par 4 import torch.optim as optim 5 6 # initialize torch.distributed properly 7 # with init_process_group 8 9 # setup model and optimizer 10 net = nn.Linear(10, 10) 11 net = par.DistributedDataParallel(net) 12 opt = optim.SGD(net.parameters(), lr=0.01) 13 14 # run forward pass 15 inp = torch.randn(20, 10) 16 exp = torch.randn(20, 10) 17 out = net(inp) 18 19 # run backward pass 20 nn.MSELoss()(out, exp).backward() 21 22 # update parameters 23 opt.step()\",\"PyTorch在设计API时做到了仅调用第11行代码中的DistributedDataParallel部分，就可以实现从本机训练到分布式训练的部署。\"]},\"17\":{\"h\":\"梯度同步算法\",\"t\":[\"论文中所提到的DP背景本篇blog前文均有提及，不再赘述。\"]},\"18\":{\"h\":\"传统做法\",\"t\":[\"batch较小时，通讯效率低\",\"计算与聚合之间存在间隔，很难做到即时通讯。\"]},\"19\":{\"h\":\"改进做法\",\"t\":[\"PyTorch使用Gradient Bucketing，在小batch时，选择收集到一定量的梯度，再做聚合和同步。\",\"PyTorch使用hook机制，在反向传播计算完成后，调用自定义函数，当在同一个bucket中的梯度的hook都被调用后，就调用AllReduce对该bucket进行通信。\",\"这种方式有两个问题需要注意：\",\"（1）由于每个机器（进程）是独立计算的，因此不同机器之间处理的bucket的顺序将会不一致，这会导致梯度同步结果出现错误。因此，我们需要保证不同机器处理bucket的顺序一致。\",\"使用参数的反序作为梯度放入bucket的顺序。依据是，后向传播的顺序与梯度更新的顺序大致可认为是相同的。\",\"（2）不同迭代中，使用的参数可能不相同，使得某些参数的梯度不需要用到。\",\"前向传播结束后从输出开始遍历计算图，记录哪些参数参与计算，哪些参数没有参与计算，对于没有参与计算的参数，则直接标记为ready。\"]},\"20\":{\"h\":\"集合通讯库\",\"t\":[\"PyTorch DDP支持三种通讯库：NCCL，Gloo和MPI。DDP支持用户使用统一的API ProcessGroup来调用不同的集合通讯库。\",\"NCCL doc:https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/api.html\",\"Gloo doc:https://docs.solo.io/gateway/latest\",\"MPI doc:https://www.open-mpi.org/doc/\"]},\"21\":{\"h\":\"FSDP并行\"},\"22\":{\"h\":\"ZeRO\",\"t\":[\"ZeRO: memory optimizations toward Training trillion parameter Models\",\"https://github.com/microsoft/DeepSpeedhttps://arxiv.org/abs/1910.02054\"]},\"23\":{\"h\":\"Abstract\",\"t\":[\"深度学习模型在训练万亿级别参数时存在根本性限制，现有DP（数据并行）、MP（模型并行）方法无法满足日益增长的参数量需求，ZeRO（零冗余优化器）消除了数据和模型并行训练中的内存冗余，同时保持了低通信量和高计算粒度（计算与通信比率的定量或定性度量），使我们能够根据设备数量按比例扩展模型大小，同时保持高效率，实现超线性优化。\"]},\"24\":{\"h\":\"Extended Introduction\",\"t\":[\"巨量参数可以大幅提升NLP处理能力，但参数量的上升在传统的单机GPU、TPU运算中无以为继，简单增加机器数量也用处不大。\",\"现有的PP（流水线并行）、MP都在通信和计算效率之间权衡，但重点是计算规模和速度。\",\"现有系统在模型训练中内存消耗的全部范围，并将其分为两部分:\",\"1）对于大型模型，【大部分内存】被模型状态占用，包括优化器状态、梯度和参数（不得不保存的模型内容）。\",\"2）剩余内存被激活、临时缓冲区和不可用的碎片内存所消耗，本文将其统称为残差状态（residual states）。\"]},\"25\":{\"h\":\"Where Did All the Memory Go\",\"t\":[\"在模型计算的过程中，只有很少一部分被过程中产生的冗余量使用了（residual states），大部分内存都被用于模型本身数据的存储和运算（model states），ZeRO使用不同的方式优化这两种内存使用。\"]},\"26\":{\"h\":\"Model States: Optimizer States, Gradients and Parameters\",\"t\":[\"论文以Adam优化器为例说明了模型造成的内存浪费是一件难以接受的事情，Adam本身对每一个参数都需要保留momentum和variance两个参数进行数据更新。\",\"看上去这是仅仅由1变2的内存保留变化，但是由于NVIDIA对于fp16精度计算的高优化度，要服务于计算速度内存变化就会发生膨胀。\",\"一般来说，在计算时，参数、输入、输出，均采用fp16半精度运算，但是考虑在更新权重的时候，可能在模型训练过程中梯度不大等原因，如果还是使用半精度进行运算，可能并不会产生权重累计，导致模型训练失效，所以此时应采用fp32的全精度计算，这又是一个仅在计算时才能用到的额外copy。\",\"FP32:1位符号位，8位指数位，23位尾数位 FP16:1位符号位，5位指数位，10位尾数位 BF16:1位符号位，8位指数位，7位尾数位\",\"假设有Ψ个参数，那就有4Ψ个byte（fp16）存储模型的参数和输入，同时又有12Ψ个byte（fp32）存储momentum和variance（Adam），也就是单计算仅需4Ψ，但是在更新参数进行新的计算时，需要额外的12Ψ，本文将其记作2Ψ+2Ψ+KΨ，其中K取决于模型。\"]},\"27\":{\"h\":\"Residual Memory Consumption\"},\"28\":{\"h\":\"Temporary buﬀers\",\"t\":[\"是指通讯过程中、计算过程中产生的一些临时数据.\"]},\"29\":{\"h\":\"Memory Fragmentation\",\"t\":[\"是指碎片化内存，用pytorch等使用虚拟内存分配方式的库时，可能内存池的维护并不能做到完全利用，论文假设有30%内存其实根本无法使用。\"]},\"30\":{\"h\":\"ZeRO: Insights and Overview\",\"t\":[\"这一部分主要介绍作者使用ZeRO的一些想法。\"]},\"31\":{\"h\":\"Insights and Overview: ZeRO-DP\",\"t\":[\"a）数据并行比模型并行更好，效率更高，因为通讯更少，计算粒度更精细\",\"b）数据并行内存使用并不高效，因为每一个分发计算都需要完全copy所有数据\",\"c）两种并行都需要存储模型状态变量，单就这一块部分内存而言，两者使用均不高效。\",\"我们可以考虑在某一个GPU中存储和更新参数，而在其他GPU需要使用其进行计算时，再进行通讯获取参数，从而降低内存占用。\"]},\"32\":{\"h\":\"Insights and Overview: ZeRO-R\"},\"33\":{\"h\":\"Reducing Activation Memory\",\"t\":[\"a）MP占据模型内存，但是需要时常更新\",\"b）大模型即使的带宽小的情况下，也可以考虑每个GPU都各自保存和重算部分数据\",\"ZeRO考虑可以使用将模型内存切分成多分，分开重算，多次通讯的方式收集数据，减少内存使用。\"]},\"34\":{\"h\":\"Managing Temporary buﬀers\",\"t\":[\"对于临时缓存采用开一段固定大小内存的方式进行反复存储。\"]},\"35\":{\"h\":\"Managing fragmented Memory.\",\"t\":[\"内存碎片通过对不同寿命的内存进行整理，减少内存释放和分配的时间\"]},\"36\":{\"h\":\"Deep Dive into ZeRO-DP\"},\"37\":{\"h\":\"ZeRO1\",\"t\":[\"对优化器本身存储的fp32数据进行切分，使每个GPU仅留1/N份数据。\"]},\"38\":{\"h\":\"ZeRO2\",\"t\":[\"对数据并行中存储的fp16梯度进行切分，使每个GPU仅留1/N份数据。\"]},\"39\":{\"h\":\"ZeRO3\",\"t\":[\"对数据并行中存储的fp16参数进行切分，使每个GPU仅留1/N份数据，使用时通讯获取完整参数。\",\"ZeRO1/2依托allreduce算法实现，NVIDIA本身支持这种优化并不会有通讯增加，但是ZeRO3需要对参数进行切分和更新，每次都会有Ψ 的额外通讯开销，但是事实上可以考虑在不同隐藏层中实现异步更新参数 ，使得参数额外开销尽可能减少。\"]},\"40\":{\"h\":\"Deep Dive into ZeRO-R\"},\"41\":{\"h\":\"Partitioned Activation Checkpointing\",\"t\":[\"采用Megatron的模型并行方式，每个GPU保存1/N参数，对切分后部分输入分开运算，使用reduce-scatter更新各个参数状态，与ZeRO-DP的区别是，计算参数时，每个GPU都没有保存或通讯获取完整的参数，而是对输出进行通讯和更新。\"]},\"42\":{\"h\":\"Constant Size Buﬀers\",\"t\":[\"使用固定大小buffer指定数据的单批发送量，保证带宽不浪费。\"]},\"43\":{\"h\":\"Memory Defragmentation\",\"t\":[\"将数据池分为两部分，一部分存储大批量的计算数据，另一部分动态存储临时数据。\"]},\"44\":{\"h\":\"ZeRO-Offload\",\"t\":[\"ZeRO-Offload：Democratizing Billion-Scale Model Training\",\"https://arxiv.org/pdf/2101.06840https://arxiv.org/pdf/2101.06840\"]},\"45\":{\"h\":\"背景\",\"t\":[\"GPU内存占用是一件非常昂贵的事情，在过去训练中人们往往忽略了CPU的计算潜力，高估了GPU的存储性能。\",\"ZeRO-Offload 优化：尽量减少数据在 GPU 与 CPU 之间的移动，并减少 CPU 计算时间，同时最大限度地节省 GPU 上的内存。\"]},\"46\":{\"h\":\"Efficiency\",\"t\":[\"论文提出了一种名为Efficiency的offload策略，通过分析确定了CPU和GPU设备之间的最佳计算和数据划分策略，以在三个关键方面达到最优化：\",\"在CPU上的计算量比GPU少多个数量级，防止CPU性能瓶颈；\",\"最小化CPU和GPU之间的通信量，防止通信瓶颈；\",\"在实现最小通信量的同时，可证明地最大化节约GPU内存。\",\"offload 优化器计算要求CPU进行O(M)次计算，而GPU需进行O(MB)次计算，其中M和B分别为模型规模和 batch size 。在大多数情况下， batch size 较大，CPU计算量并不是瓶颈，但对于小 batch size，CPU计算量可能成为瓶颈。为了解决这个问题，采取了两种优化措施：\",\"高效的CPU优化器，其速度比现有技术快6倍；\",\"延迟一步的参数更新，允许将CPU优化器步骤与GPU计算重叠，同时确保准确性。这两种措施共同保证了ZeRO-Offload在小 batch size 下也能保持效率。\"]},\"47\":{\"h\":\"Unique Optimal Offload Strategy\",\"t\":[\"为了确定最佳的下载策略，ZeRO-Offload将深度学习训练建模为数据流图，将该图分割为CPU和GPU设备之间的部分。\",\"训练的计算复杂度通常为O(MB)，其中M为模型大小，B为有效batch size。为避免CPU计算成为瓶颈，只有那些计算复杂度低于O(MB)的计算才能转移到CPU上\",\"FWD 和 BWD 的计算复杂度都是O(MB)，必须在GPU上进行，而其余的计算，如范数计算、权重更新等，其复杂度为O(M)，可以转移到CPU上\",\"还需要最小化 CPU 与 GPU 的通信带宽，如图中所示，最小通信量为 BWD后 GPU 发送到 CPU 的 2M 梯度与 CPU 发送到 GPU 的 2M 参数，只有将 fp32 模型状态（momentum 32、variance 32和p32），Param Update 和 float2half 计算放置在一起，为一个 CPU 上的 Update Super Node，才能达成最小通信量策略\"]},\"48\":{\"h\":\"ZeRO-Offload Schedule\"},\"49\":{\"h\":\"单卡策略\",\"t\":[\"ZeRO-Offload将数据进行分区，将fp16参数存储在GPU上，fp16梯度和所有优化器状态存储在CPU上。\",\"在训练过程中，首先通过 FWD 计算损失。由于fp16参数已经位于GPU上，因此这部分计算不需要与CPU进行通信。\",\"在 BWD 过程中，不同参数的梯度在后向调度的不同位置计算。ZeRO-Offload可以立即将这些梯度逐个或切分传输到 CPU 内存中。\",\"因此，在将梯度传输到CPU内存之前，只需要在GPU内存中临时保存少量的梯度。此外，每个梯度传输可以与反向计算重叠，消除大部分通信成本。\",\"在 BWD 之后，ZeRO-Offload在CPU上直接更新fp32参数和剩余的优化器状态，并将更新后的 fp32 参数从 CPU 内存复制到 GPU 内存中的fp16参数中。\",\"下图GPU与CPU二次通信应该是从CPU到GPU\",\"for_parallel rank in range(world_size): # 初始化每个进程的层 initialize_layers() for batch in dataset: # 前向传播 x = forward(batch) # 计算损失并反向传播 compute_loss(x, batch).backward() # 反向传播梯度 backward(x.grad) # 更新参数 step() def _is_owner(i): # 判断当前进程是否拥有第 i 层 return True if rank owns i else False def initialize_layers(): for i in range(num_layers): l = layers[i] # 在 GPU 上分配半精度参数 allocate_on_gpu l.param_fp16 if _is_owner(i): # 在 CPU 上分配全精度参数、优化器状态和梯度 allocate_on_cpu l.param_fp32 allocate_on_cpu l.optim_states_fp32 allocate_on_cpu l.param_grad def forward(x): # 前向传播逻辑 for i in range(num_layers): x = layers[i].forward(x) return x def backward(dx): # 反向传播逻辑 for i in range(num_layers, 0, -1): dx = layers[i].backward(dx) # 将梯度减少到拥有该层的进程 reduce(layers[i].grad, dest_rank = _owner_rank(i)) if _is_owner(i): # 将梯度复制到 CPU l.cpu_grad.copy(l.grad) else: pass # 删除 GPU 上的梯度 del layers[i].grad def step(): # 参数更新逻辑 for i in range(num_layers): l = layers[i] if _is_owner(i): # 在 CPU 上更新参数 update_in_cpu(l.optim_states_fp32, l.cpu_grad, l.param_fp32) # 将更新后的参数复制回 GPU l.param_fp16.copy(l.param_fp32) # 广播更新后的参数 BROADCAST(l.param_fp16, src = _owner_rank(i))\"]},\"50\":{\"h\":\"多卡策略\",\"t\":[\"ZeRO-Offload 将梯度和优化器状态在不同的 GPU 之间进行 partition，并且每个 GPU 将自己的 part offload 到 CPU 内存中，存储持续整个训练过程\",\"BWD 过程中，在 GPU 上 reduce-scatter 计算梯度并平均，每个 GPU 仅将属于其 part 的平均梯度 offload 到 CPU 内存中\",\"一旦梯度在 CPU 上可用，优化器状态 part 对应的每个 DP 进程直接在 CPU 上并行更新对应的参数 part\",\"更新完成后，参数 part 发送到 GPU，在 GPU 上对参数进行类似 ZeRO-2 的 all-gather 操作\"]},\"51\":{\"h\":\"流水线并行\"},\"52\":{\"h\":\"GPipe\",\"t\":[\"GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism\",\"https://arxiv.org/abs/1811.06965\"]},\"53\":{\"h\":\"Gpipe Abstract\",\"t\":[\"增大模型规模可以提升模型效果，但是单卡/单机GPU内存有限，必须引入分布式系统\",\"GPipe使用模型并行（MP）方案，将模型切分成一连串stage，每个stage放在独立的设备（GPU/TPU）上，实现对超大规模模型的支持\",\"利用Pipeline（PP）的方案，提高了模型并行模式下的设备利用率\",\"最终GPipe通过更大规模的模型和更大的batch_size，在图像和NLP的模型上都得到更好的模型效果。\"]},\"54\":{\"h\":\"Design\"},\"55\":{\"h\":\"Naive Model Parallelism\",\"t\":[\"论文中提到的MP就是传统的MP方案，不是Magatron-LM提出的新MP方案（事实上是TP），对数据按层切分，而非对所有输入、输出、参数都按块切分。\",\"模型有 12 层（layer），可以切为 4 份（4个cell），每份 3 层。然后每份放到一块 GPU 上\",\"第 k 个 cell 的模型参数，就放在第 k 块 GPU 上。\",\"Fk和 Bk 分别表示第 k 个 cell 的 forward 和 backward 计算\",\"单批量以这种顺序进行计算，Fk和 Bk 分别表示第 k 个批次的forward和backward运算（注意与上张图不同），每一种颜色代表一块 GPU，每一列代表一个时间段\",\"问题是：每块 GPU 都会有大量的空闲时间\"]},\"56\":{\"h\":\"Pipeline Parallelism 1 - Split into micro-batches\",\"t\":[\"单batch（mini-batch）切成更小的micro-batch，然后流水线并行（类似CPU指令执行）\",\"为什么不流水线并行batch，而是切分后再流水线并行？ 多batch可以提速，但占用空间会多很多 多batch训练时，可能会导致梯度更新不稳定，结果收敛不明显\"]},\"57\":{\"h\":\"Pipeline Parallelism 2 - re-materialization\",\"t\":[\"GPU 只保留最开始的输入，中间结果全部丢掉；计算梯度时，再重新计算这些中间结果。\",\"减少计算时内存占用，但要增加计算时长。\"]},\"58\":{\"h\":\"张量并行（TP）\"},\"59\":{\"h\":\"Megatron-LM\",\"t\":[\"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\",\"https://arxiv.org/abs/1909.08053https://github.com/NVIDIA/Megatron-LM\"]},\"60\":{\"h\":\"Model Parallel Transformers\",\"t\":[\"在MLP中最常用的操作是MM + GELU，即输入与参数矩阵相乘 和 激活函数\",\"一种方法是沿着其行(row)将weight矩阵A分割，并沿着其列(columns)输入X分割，来实现tensor-model-parallel，从下图中我们可以看出，在该方法下，需要通过同步来保障语义对等。\",\"另一种方法是沿着它的列(columns)分割A，这种方法的好处是保障了各自在独立计算时的语义对等，不需要进行额外通讯\",\"不过由于我们使用的A是同一个，在反向传播时要保证在保存不同切分W的GPU中均及时更新A，在PyTorch中可以通过下面的代码简单实现：\",\"class f(torch.autograd.Function): def forward(ctx, x): return x def backward(ctx, gradient): all_reduce(gradient) return gradient\",\"通过结合上述两种方法，可以在transformer中实现简单并发，针对MLP、SA两个环节做了如下优化，实现MLP的整体的tensor-model-parallel且语义和原始MLP对等：\",\"在优化 embedding 层时，PyTorch 将 embedding 操作视为对输入进行索引操作，即在权重矩阵上执行 index_select 操作。实际上，这个操作等价于先对输入进行 one-hot 编码，然后与权重矩阵进行矩阵乘法（mm）操作。可以将 embedding 层视为线性层来处理，并使用模型并行操作来优化。\",\"class VocabParallelEmbedding(): def __init__(self, num_embeddings, embedding_dim, init_method=init.xavier_normal_): super(VocabParallelEmbedding, self).__init__() ... # 通过获取当前 tensor_model_parallel 的 rank 来确定当前卡要 embedding 的 category id，初始化权重 self.vocab_start_index, self.vocab_end_index = VocabUtility.vocab_range_from_global_vocab_size( self.num_embeddings, get_tensor_model_parallel_rank(), self.tensor_model_parallel_size) self.num_embeddings_per_partition = self.vocab_end_index - self.vocab_start_index self.weight = Parameter(torch.empty( self.num_embeddings_per_partition, self.embedding_dim, dtype=args.params_dtype)) ... def forward(self, input_): if self.tensor_model_parallel_size > 1: # 把当前卡上不要的 category idx mask 掉 input_mask = (input_ < self.vocab_start_index) | \\\\ (input_ >= self.vocab_end_index) # Mask 掉的输入 masked_input = input_.clone() - self.vocab_start_index masked_input[input_mask] = 0 else: masked_input = input_ # 获取嵌入向量 output_parallel = F.embedding(masked_input, self.weight, self.padding_idx, self.max_norm, self.norm_type, self.scale_grad_by_freq, self.sparse) # 把 mask 掉的 category idx 对应的嵌入向量处理成 0 if self.tensor_model_parallel_size > 1: output_parallel[input_mask, :] = 0.0 # 在所有模型并行 GPU 上进行 reduce 操作 output = reduce_from_tensor_model_parallel_region(output_parallel) return output\"]},\"61\":{\"h\":\"3D并行\",\"t\":[\"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM\",\"https://arxiv.org/pdf/2104.04473https://github.com/NVIDIA/Megatron-LM\"]},\"62\":{\"h\":\"贡献\",\"t\":[\"如何合理的使用上面的多种并行技术一直是一个困难的命题，本文中研究人员提出了一种名为PTD-P的策略，在一个大规模的GPU集群上达到超过50%的效能。\",\"本文探讨了以下几种因素对效率的影响：\",\"不同的并行策略：通常张量并行只适用于一个multi-GPU服务器内部，而流水线并行则几乎只用于更大的模型（多机集群）\",\"流水线并行中的schedule：对通信、pipeline bubble的大小、内存都有重要的影响\",\"参数的选取（如microbatch的大小）：对于内存使用和kernel计算效率、pipeline bubble大小也有影响\"]},\"63\":{\"h\":\"数据并行\",\"t\":[\"问题：\",\"batch过小，会导致单块GPU利用率降低，而通信成本大大增长\",\"理论上GPU数量等于batch size，这也限制了可以使用的卡的规模\"]},\"64\":{\"h\":\"考虑流水线并行\",\"t\":[\"流水线并行技术将一个模型（Transformer）中的不同层发放到多块GPU上，将原本一个batch的数据分解为多个更小的micro batch，通过编排forward pass和backward pass可以来获取不同的性能。 为了确保optimizer semantics（也就是端到端的计算能够正确的完成），不同GPU之间需要进行定期同步---在每一个batch计算完毕时执行pipeline flush操作（完成一次周期内所有micro batch的操作，此时不再提供任何其他新的输入），我们称这个过程中的等待时间为pipeline bubble。 在流水线并行技术中，micro batch的数量/pipeline尺寸（并行使用的GPU的数量）越大，通常pipeline flush消耗的时间则越小。\"]},\"65\":{\"h\":\"考虑张量并行\",\"t\":[\"见前文TP内容。\"]},\"66\":{\"h\":\"性能分析\",\"t\":[\"令：\",\"(p,t,d)分别表示PP/TP/DP并行维度\",\"n:GPU总数，有$ n=ptd $\",\"B:Global Batch Size\",\"Micro Batch Size\",\"m=B/(b*d)：每Pipeline中的microbatch的数量\",\"可以得到以下结论：\",\"对于多个GPU集群，通常建议在集群上采用流水线并行，每一个集群上的节点假如包含g个GPU卡，通常在一个节点内部采用不超过g张卡做张量并行\",\"考虑使用模型并行（包括流水线并行和张量并行）和数据并行时，通常建议在GPU内存满足的情况下最大化模型并行（t和p），然后通过数据并行技术扩展集群上进行加速\",\"microbatch的选择也非常重要，取决于最终的throughput（吞吐量）和memory，需要综合流水线并行p、数据并行d、全局BatchSize B考虑\",\"Activation Recompute也是一种可以考虑的方法，在大模型训练中内存往往比算力更加宝贵，所以一种可取的方法是将一部中间过程结果丢弃，在需要时（如进行backward更新）重新计算，以节省内存。\"]},\"67\":{\"h\":\"自动并行\"},\"68\":{\"h\":\"FlexFlow\",\"t\":[\"Beyond Data and Model Parallelism for Deep Neural Networks\",\"https://arxiv.org/pdf/1807.05358\",\"本文引入了 SOAP（一个更加全面的并行策略搜索空间） 和 FlexFlow（一个高效的并行策略搜索引擎）, 为了加速并行策略的搜索， FlexFlow 引入了一个 novel execution simulator, 可以准确预测并行策略的性能。\"]},\"69\":{\"h\":\"简介\",\"t\":[\"论文提出从 SOAP 4个维度描述搜索空间:\",\"Operator: 描述不同的 Operator 的并行方法 -- OP并行(如何将一个 大OP 拆分到 多个 devices 上)\",\"Sample: 对于单个 Operator, Sample 描述训练数据如何并行 -- 数据并行\",\"Parameter: 对于单个 Operator, Parameter 描述参数如何并行 -- 模型并行\",\"Attribute: 对于单个 Sample, Attribute 描述单个 Sample 不同属性如何并行 -- Sample并行(如何将一个 Sample 拆分到多个 devices 上)\",\"关键的问题是: 如何快速搜索 SOAP 空间\",\"快速，增量的执行模拟器 -- execution simulator\",\"Markov Chain Monte Carlo (马尔可夫链蒙特卡洛) 搜索算法 -- execution optimizer\"]},\"70\":{\"h\":\"概述\",\"t\":[\"同时输入 Compute Graph 和 Device Topology，FlexFlow负责将 Operator 分发到不同的设备上，确定 Operator 的执行顺序。\",\"SOAP 搜索空间对于不同的 Operator 【卷积、池化、全连接层、激活函数、归一化、嵌入、矩阵乘法、损失函数】，可拆分的维度并不一样，但大多数 Operator(除去BatchNormalization)，都支持 Sample 维度的拆分, 大多数 Operator 都能支持2种或者更多的拆分方式。 假设模型包含 N 个 Operator，那并行配置 至少有 2^N 种。当然，实际情况种，通常还会加一些约束条件, 比如 co-location（操作符的共置）, 但即使这样，要在合理时间内找到最优解依然比较困难。\"]},\"71\":{\"h\":\"执行模拟器\",\"t\":[\"接受 operator graph, device topology 和 parallelization strategy 作为输入，预测模型的执行时间。\"]},\"72\":{\"h\":\"执行优化器\",\"t\":[\"执行优化器，接受 operator graph 和 device topology 作为输入，自动查找高效的 parallelization strategy. 论文基于当前的 parallelization strategy 随机选择 operator，并随机替换被选择的 operator 的 parallelization strategy, 进而生成 proposals。同时，MCMC算法内部维护一个 最优 parallelization strategy, 依据如下规则进行更新:\"]},\"73\":{\"c\":[\"SOSD\"]},\"74\":{\"c\":[\"分布式系统\",\"AISys\",\"并行运算\"]},\"75\":{\"h\":\"CS149_Course\"},\"76\":{\"c\":[\"CS149\"]},\"77\":{\"c\":[\"公开课\",\"并行计算\"]},\"78\":{\"h\":\"CS149 Lab Assignment1\"},\"79\":{\"h\":\"Prog1_mandelbort_threads\"},\"80\":{\"h\":\"环境配置\",\"t\":[\"本人使用OS为Ubuntu 22.04, 还是建议使用Linux系统做Lab, 很多环境配置会方便一些.\",\"CS149_Asst1并不需要额外配置运行环境, 下载解压一下编译环境就好啦! 下载包:\",\" wget https://github.com/ispc/ispc/releases/download/v1.21.0/ispc-v1.21.0-linux.tar.gz\",\"解压包:\",\" tar -xvf ispc-v1.21.0-linux.tar.gz\",\"配置环境路径:\",\" export PATH=$PATH:${HOME}/Downloads/ispc-v1.21.0-linux/bin\",\"环境配置完成后就可以clone repo到本地来开始lab了:\",\" git clone https://github.com/stanford-cs149/asst1.git\"]},\"81\":{\"h\":\"任务分析\",\"t\":[\"Pro1的内容主要是为了让学生了解std::thread的并行机制和\\\"多线程不一定高效率\\\"的并发事实, 所以难度并不算大~~(这是我的事后诸葛亮)~~, 整体框架已经在源码中基本完成了.完成后可以通过make + ./mandelbort --<args>检验正确与否.\",\"task :\",\"创建线程0和线程1, 分别计算图像的上下两个部分, 即将图像的不同空间交给不同线程计算, 这被称为空间分解(spatial decomposition).\",\"扩展代码使其能够使用2, 3, 4, 5, 6, 7, 8个线程, 进行空间分解, 生成加速图, 假设加速是否与线程数线性相关并加以验证.\",\"在workerThreadStart()的开头和结尾插入计时代码, 验证并解释task2中提出的猜想.\",\"修改一开始的线程分配方式, 实现将两个图片都拉到8线程时7-8倍加速比的效果, 找到适应任何线程数的泛型分配方式(不需要线程之间进行响应和同步), 报告最后得出的8线程加速比.\",\"使用16个线程运行改进后代码, 回答性能是否明显高于8线程并解释原因.\",\"事实上task中给的提示还是比较明显的, 在task1中解释了空间分解的概念, 那么通过对图片本身的上下多份分割,就可以解决这个问题,要注意分割的时候会不会漏行.\"]},\"82\":{\"h\":\"任务实现\",\"t\":[\"我们将一开始就对任务给出多线程的解决方式, 并在后续针对数据结果决定是否要进行优化.\",\"首先我们可以根据阅读mandelbrotSerial.cpp中的源码, 得到mandelbrotSerial()函数事实上是用来计算Mandelbrot图像的, 可以简单分析一下mandelbrotSerial()函数的各个参数:\",\" void mandelbrotSerial( float x0, float y0, float x1, float y1, // 复平面左上和右下两个点坐标 int width, int height, // 图像宽度和高度 int startRow, int numRows, // 开始行和总计算行数 int maxIterations, // 最大迭代次数 int output[]); // 每个点的迭代次数\",\"不难发现只要我们给出startRow, numRows, 其余保持图像默认参数, 就可以完成计算了. 所以可以给出函数workerThreadStart(WorkerArgs * const args)的代码:\",\" size_t rows = args -> height / args -> numThreads; // 确定要计算的行数 if (args -> height % args -> numThreads) { // 如果该遇到整除要加一行避免遗漏 rows++; } size_t startRow = args -> threadId * rows; // 确定开始行 // 如果已经到最后部分不够切分, 直接处理最后部分 rows = rows > args -> height - startRow ? args -> height - startRow : rows; // 调用mandelbrotSerial mandelbrotSerial(args -> x0, args -> y0, args -> x1, args -> y1, args -> width, args -> height, startRow, rows, args -> maxIterations, args -> output);\"]},\"83\":{\"c\":[\"CS149_Lab\"]},\"84\":{\"c\":[\"公开课\",\"并行计算\",\"Lab\"]},\"85\":{\"h\":\"阶乘的位数估算--数学在计算机算法研究中的作用\"},\"86\":{\"h\":\"题目引入\",\"t\":[\"算法与数据结构实验题 1.10 单身狗进化 这一天晚上，弯通又做梦了，并且梦到了一个帅气的男孩纸！这个男孩给了弯通一个数字 n。男孩离开前告诉弯通，n!（n 的阶乘）的位数就是距离弯通脱单的天数。矜（ji）持（ke）的弯通想知道自己还有多久能脱单，快写个程序帮助他！ 输入: 输入第一行为一个正整数 n（1<=n<=25000）。 输出: n阶乘的位数\"]},\"87\":{\"h\":\"题目分析\",\"t\":[\"这道题看上去还挺有意思的很符合大学生的心理状态, 实际上就是要求阶乘的位数倒也没有拐弯抹角. 但是我们都知道, 要是用递归或者循环写阶乘, 这将是一件极为恐怖的事情. 在数据存储(空间复杂度)&计算用时(时间复杂度)上的开销, 将成为任何一台机器的噩梦, 更不可能过测试了. 举个栗子:\",\" int n; long long ans = 1; std::cin >> n; for (int i = 1; i < MAX; i++) ans *= i; std::cout << ans;\",\"大家可以简单跑一下这个程序, 然后就会发现, 在n = 27的时候, 就已经溢出了, 完全无法满足题目要求. 这就是第一种错误的可能, 忘记了估计数据规模, 随便算算就存爆了.\",\"还有一种可能, 就是采用高精度的算法, 将阶乘结果用表存储, 每个内存存有限位数据, 在乘法时做类似竖式乘法的高精度运算.\",\"这种方式能不能过这个题我没有试过因为我懒, 但是一般来说高精度阶乘的时间复杂度是O(n2)\",\"程序代码的复杂度和 n = 25000 所要存储的数据规模, 也会是比较大的开销.\",\"下文将介绍一种用数学方法巧妙估算阶乘结果规模的方式.\"]},\"88\":{\"h\":\"斯特林公式\",\"t\":[\"n!≈2πn​(en​)n\",\"这个公式以詹姆斯·斯特林的名字命名，虽然亚伯拉罕·棣美弗早于斯特林提出了一个类似的公式，但结果较不精确. 当n很大的时候，n阶乘的计算量十分大，所以斯特林公式十分好用，而且，即使在n很小的时候，斯特林公式的取值已经十分准确.\",\"可以通过计算对比来估计一下斯特林公式算出结果, 和阶乘计算结果的误差程度.\",\"我们可以看到, 随着n的增大, 斯特林公式估算的误差已经降到了十万分之一以下, 这对估算阶乘的规模来说是完全可以接受的误差.\",\"通过斯特林公式我们可以简单估算阶乘的位数, 我们知道对于一个n进制数x, 都可以对其取$ [\\\\log_{n}x] + 1 $来得到这个n进制数的位数, 我们将进一步推导用斯特林公式估算阶乘位数N的公式.\",\"N=[log10​[2πn​(en​)n]]+1\",\"其中内层中括号标记运算顺序, 外层中括号意为高斯取整(即向下取整).\",\"N=[21​log10​(2πn)+nlog10​(en​)]+1\",\"通过代入n, 即可轻松求得n!的位数, 时间复杂度是梦寐以求的O(1), 即常数时间复杂度.\"]},\"89\":{\"h\":\"代码实现\",\"t\":[\"代码实现没什么好说的, 套公式罢了, 由于我之前已经测试过最大数据规模, 所以ans也是为了省事儿用的int偷懒是可耻的\",\" #include <stdio.h> #include <math.h> #define PI 3.141592654 #define E 2.71828182846 int pos(int n) { int s = 1; if(n > 3) s = log10(2*PI*n) / 2 + n * log10(n/E) + 1; return s; } int main() { int num, ans; scanf(\\\"%d\\\", &num); ans = pos(num); printf(\\\"%d\\\", ans); }\"]},\"90\":{\"h\":\"总结\",\"t\":[\"数即一切\"]},\"91\":{\"c\":[\"数据结构与算法\"]},\"92\":{\"c\":[\"算法\",\"数学\"]},\"93\":{\"h\":\"\",\"t\":[\"404 Not Found\"]},\"94\":{\"h\":\"\"},\"95\":{\"h\":\"Posts\"}},\"dirtCount\":0,\"index\":[[\"总结\",{\"0\":{\"90\":1}}],[\"总是绕不开训练集和测试集这两部分\",{\"1\":{\"4\":1}}],[\"套公式罢了\",{\"1\":{\"89\":1}}],[\"代码实现没什么好说的\",{\"1\":{\"89\":1}}],[\"代码实现\",{\"0\":{\"89\":1}}],[\"外层中括号意为高斯取整\",{\"1\":{\"88\":1}}],[\"棣美弗早于斯特林提出了一个类似的公式\",{\"1\":{\"88\":1}}],[\"虽然亚伯拉罕\",{\"1\":{\"88\":1}}],[\"斯特林的名字命名\",{\"1\":{\"88\":1}}],[\"斯特林公式估算的误差已经降到了十万分之一以下\",{\"1\":{\"88\":1}}],[\"斯特林公式的取值已经十分准确\",{\"1\":{\"88\":1}}],[\"斯特林公式\",{\"0\":{\"88\":1}}],[\"≈2πn​\",{\"1\":{\"88\":1}}],[\"所要存储的数据规模\",{\"1\":{\"87\":1}}],[\"所以ans也是为了省事儿用的int偷懒是可耻的\",{\"1\":{\"89\":1}}],[\"所以斯特林公式十分好用\",{\"1\":{\"88\":1}}],[\"所以可以给出函数workerthreadstart\",{\"1\":{\"82\":1}}],[\"所以难度并不算大~~\",{\"1\":{\"81\":1}}],[\"所以一种可取的方法是将一部中间过程结果丢弃\",{\"1\":{\"66\":1}}],[\"所以此时应采用fp32的全精度计算\",{\"1\":{\"26\":1}}],[\"所以在训练ai时我们希望能使用尽可能大的数据集\",{\"1\":{\"4\":1}}],[\"程序代码的复杂度和\",{\"1\":{\"87\":1}}],[\"随着n的增大\",{\"1\":{\"88\":1}}],[\"随便算算就存爆了\",{\"1\":{\"87\":1}}],[\"随机选择\",{\"1\":{\"72\":1}}],[\"忘记了估计数据规模\",{\"1\":{\"87\":1}}],[\"完全无法满足题目要求\",{\"1\":{\"87\":1}}],[\"完成后可以通过make\",{\"1\":{\"81\":1}}],[\"完成一次周期内所有micro\",{\"1\":{\"64\":1}}],[\"举个栗子\",{\"1\":{\"87\":1}}],[\"更不可能过测试了\",{\"1\":{\"87\":1}}],[\"更新完成后\",{\"1\":{\"50\":1}}],[\"更新参数\",{\"1\":{\"49\":1}}],[\"更新模型参数\",{\"1\":{\"8\":1}}],[\"时间复杂度是梦寐以求的o\",{\"1\":{\"88\":1}}],[\"时间复杂度\",{\"1\":{\"87\":1}}],[\"题目分析\",{\"0\":{\"87\":1}}],[\"题目引入\",{\"0\":{\"86\":1}}],[\"快写个程序帮助他\",{\"1\":{\"86\":1}}],[\"快速\",{\"1\":{\"69\":1}}],[\"持\",{\"1\":{\"86\":1}}],[\"ji\",{\"1\":{\"86\":1}}],[\"矜\",{\"1\":{\"86\":1}}],[\"男孩离开前告诉弯通\",{\"1\":{\"86\":1}}],[\"弯通又做梦了\",{\"1\":{\"86\":1}}],[\"数学\",{\"2\":{\"92\":1}}],[\"数学在计算机算法研究中的作用\",{\"0\":{\"85\":1}}],[\"数即一切\",{\"1\":{\"90\":1}}],[\"数据结构与算法\",{\"2\":{\"91\":1}}],[\"数据并行d\",{\"1\":{\"66\":1}}],[\"数据并行内存使用并不高效\",{\"1\":{\"31\":1}}],[\"数据并行比模型并行更好\",{\"1\":{\"31\":1}}],[\"数据并行\",{\"0\":{\"7\":1,\"63\":1},\"1\":{\"23\":1,\"69\":1}}],[\"数据分布式的一些基本想法\",{\"0\":{\"6\":1}}],[\"数据集越大\",{\"1\":{\"4\":1}}],[\"阶乘的位数估算\",{\"0\":{\"85\":1}}],[\"调用mandelbrotserial\",{\"1\":{\"82\":1}}],[\"调用自定义函数\",{\"1\":{\"19\":1}}],[\"直接处理最后部分\",{\"1\":{\"82\":1}}],[\"开始行和总计算行数\",{\"1\":{\"82\":1}}],[\"图像宽度和高度\",{\"1\":{\"82\":1}}],[\"图中红色\",{\"1\":{\"11\":1}}],[\"图中0\",{\"1\":{\"8\":1}}],[\"复平面左上和右下两个点坐标\",{\"1\":{\"82\":1}}],[\"y1\",{\"1\":{\"82\":2}}],[\"y0\",{\"1\":{\"82\":2}}],[\"函数的各个参数\",{\"1\":{\"82\":1}}],[\"函数事实上是用来计算mandelbrot图像的\",{\"1\":{\"82\":1}}],[\"得到mandelbrotserial\",{\"1\":{\"82\":1}}],[\"首先我们可以根据阅读mandelbrotserial\",{\"1\":{\"82\":1}}],[\"首先通过\",{\"1\":{\"49\":1}}],[\"任务实现\",{\"0\":{\"82\":1}}],[\"任务分析\",{\"0\":{\"81\":1}}],[\"回答性能是否明显高于8线程并解释原因\",{\"1\":{\"81\":1}}],[\"报告最后得出的8线程加速比\",{\"1\":{\"81\":1}}],[\"找到适应任何线程数的泛型分配方式\",{\"1\":{\"81\":1}}],[\"修改一开始的线程分配方式\",{\"1\":{\"81\":1}}],[\"验证并解释task2中提出的猜想\",{\"1\":{\"81\":1}}],[\"生成加速图\",{\"1\":{\"81\":1}}],[\"扩展代码使其能够使用2\",{\"1\":{\"81\":1}}],[\"创建线程0和线程1\",{\"1\":{\"81\":1}}],[\"创建训练操作\",{\"1\":{\"14\":1}}],[\"整体框架已经在源码中基本完成了\",{\"1\":{\"81\":1}}],[\"~~\",{\"1\":{\"81\":1}}],[\"配置环境路径\",{\"1\":{\"80\":1}}],[\"解压包\",{\"1\":{\"80\":1}}],[\"很多环境配置会方便一些\",{\"1\":{\"80\":1}}],[\"很难做到即时通讯\",{\"1\":{\"18\":1}}],[\"还有一种可能\",{\"1\":{\"87\":1}}],[\"还是建议使用linux系统做lab\",{\"1\":{\"80\":1}}],[\"还需要最小化\",{\"1\":{\"47\":1}}],[\"本人使用os为ubuntu\",{\"1\":{\"80\":1}}],[\"本文引入了\",{\"1\":{\"68\":1}}],[\"本文探讨了以下几种因素对效率的影响\",{\"1\":{\"62\":1}}],[\"本文中研究人员提出了一种名为ptd\",{\"1\":{\"62\":1}}],[\"本文将其记作2ψ+2ψ+kψ\",{\"1\":{\"26\":1}}],[\"本文将其统称为残差状态\",{\"1\":{\"24\":1}}],[\"本文指出了ring\",{\"1\":{\"9\":1}}],[\"本文通过在不同数量卡上训练结果进行说明\",{\"1\":{\"9\":1}}],[\"本文还指出dp代码重构成本较大\",{\"1\":{\"9\":1}}],[\"环境配置完成后就可以clone\",{\"1\":{\"80\":1}}],[\"环境配置\",{\"0\":{\"80\":1}}],[\"公开课\",{\"2\":{\"77\":1,\"84\":1}}],[\"依据如下规则进行更新\",{\"1\":{\"72\":1}}],[\"依据是\",{\"1\":{\"19\":1}}],[\"自动查找高效的\",{\"1\":{\"72\":1}}],[\"自动并行\",{\"0\":{\"67\":1}}],[\"预测模型的执行时间\",{\"1\":{\"71\":1}}],[\"作为输入\",{\"1\":{\"71\":1,\"72\":1}}],[\"接受\",{\"1\":{\"71\":1,\"72\":1}}],[\"执行优化器\",{\"0\":{\"72\":1},\"1\":{\"72\":1}}],[\"执行模拟器\",{\"0\":{\"71\":1}}],[\"执行同步训练\",{\"1\":{\"14\":1}}],[\"比如\",{\"1\":{\"70\":1}}],[\"当n很大的时候\",{\"1\":{\"88\":1}}],[\"当然\",{\"1\":{\"70\":1}}],[\"当在同一个bucket中的梯度的hook都被调用后\",{\"1\":{\"19\":1}}],[\"种\",{\"1\":{\"70\":1}}],[\"至少有\",{\"1\":{\"70\":1}}],[\"假设加速是否与线程数线性相关并加以验证\",{\"1\":{\"81\":1}}],[\"假设模型包含\",{\"1\":{\"70\":1}}],[\"假设有ψ个参数\",{\"1\":{\"26\":1}}],[\"假设有4块gpu\",{\"1\":{\"10\":1}}],[\"维度的拆分\",{\"1\":{\"70\":1}}],[\"都可以对其取$\",{\"1\":{\"88\":1}}],[\"都能支持2种或者更多的拆分方式\",{\"1\":{\"70\":1}}],[\"都支持\",{\"1\":{\"70\":1}}],[\"都会有大量的空闲时间\",{\"1\":{\"55\":1}}],[\"除去batchnormalization\",{\"1\":{\"70\":1}}],[\"损失函数\",{\"1\":{\"70\":1}}],[\"矩阵乘法\",{\"1\":{\"70\":1}}],[\"嵌入\",{\"1\":{\"70\":1}}],[\"归一化\",{\"1\":{\"70\":1}}],[\"全连接层\",{\"1\":{\"70\":1}}],[\"全局batchsize\",{\"1\":{\"66\":1}}],[\"池化\",{\"1\":{\"70\":1}}],[\"卷积\",{\"1\":{\"70\":1}}],[\"搜索空间对于不同的\",{\"1\":{\"70\":1}}],[\"搜索算法\",{\"1\":{\"69\":1}}],[\"确定开始行\",{\"1\":{\"82\":1}}],[\"确定要计算的行数\",{\"1\":{\"82\":1}}],[\"确定\",{\"1\":{\"70\":1}}],[\"概述\",{\"0\":{\"70\":1}}],[\"马尔可夫链蒙特卡洛\",{\"1\":{\"69\":1}}],[\"增量的执行模拟器\",{\"1\":{\"69\":1}}],[\"增大模型规模可以提升模型效果\",{\"1\":{\"53\":1}}],[\"空间复杂度\",{\"1\":{\"87\":1}}],[\"空间\",{\"1\":{\"69\":1}}],[\"关键的问题是\",{\"1\":{\"69\":1}}],[\"描述单个\",{\"1\":{\"69\":1}}],[\"描述参数如何并行\",{\"1\":{\"69\":1}}],[\"描述训练数据如何并行\",{\"1\":{\"69\":1}}],[\"描述不同的\",{\"1\":{\"69\":1}}],[\"拆分到多个\",{\"1\":{\"69\":1}}],[\"拆分到\",{\"1\":{\"69\":1}}],[\"引入了一个\",{\"1\":{\"68\":1}}],[\"重新计算\",{\"1\":{\"66\":1}}],[\"吞吐量\",{\"1\":{\"66\":1}}],[\"取决于最终的throughput\",{\"1\":{\"66\":1}}],[\"$来得到这个n进制数的位数\",{\"1\":{\"88\":1}}],[\"$\",{\"1\":{\"66\":1,\"80\":1}}],[\"有$\",{\"1\":{\"66\":1}}],[\"有了对模型算子切分的方法\",{\"1\":{\"6\":1}}],[\"令\",{\"1\":{\"66\":1}}],[\"性能分析\",{\"0\":{\"66\":1}}],[\"见前文tp内容\",{\"1\":{\"65\":1}}],[\"越大\",{\"1\":{\"64\":1}}],[\"中的不同层发放到多块gpu上\",{\"1\":{\"64\":1}}],[\"中间结果全部丢掉\",{\"1\":{\"57\":1}}],[\"考虑使用模型并行\",{\"1\":{\"66\":1}}],[\"考虑张量并行\",{\"0\":{\"65\":1}}],[\"考虑流水线并行\",{\"0\":{\"64\":1}}],[\"考虑一些综合利用并行方式的策略\",{\"1\":{\"6\":1}}],[\"理论上gpu数量等于batch\",{\"1\":{\"63\":1}}],[\"会导致单块gpu利用率降低\",{\"1\":{\"63\":1}}],[\"问题\",{\"1\":{\"63\":1}}],[\"问题是\",{\"1\":{\"55\":1}}],[\"贡献\",{\"0\":{\"62\":1}}],[\"获取嵌入向量\",{\"1\":{\"60\":1}}],[\"|\",{\"1\":{\"60\":1}}],[\"<math\",{\"1\":{\"89\":1}}],[\"<stdio\",{\"1\":{\"89\":1}}],[\"<<\",{\"1\":{\"87\":1}}],[\"<args>检验正确与否\",{\"1\":{\"81\":1}}],[\"<\",{\"1\":{\"60\":1,\"87\":1}}],[\"掉的\",{\"1\":{\"60\":1}}],[\"掉的输入\",{\"1\":{\"60\":1}}],[\"掉\",{\"1\":{\"60\":1}}],[\">>\",{\"1\":{\"87\":1}}],[\">=\",{\"1\":{\"60\":1}}],[\">\",{\"1\":{\"60\":2,\"82\":16,\"89\":1}}],[\"编码\",{\"1\":{\"60\":1}}],[\"实际情况种\",{\"1\":{\"70\":1}}],[\"实际上就是要求阶乘的位数倒也没有拐弯抹角\",{\"1\":{\"87\":1}}],[\"实际上\",{\"1\":{\"60\":1}}],[\"实现将两个图片都拉到8线程时7\",{\"1\":{\"81\":1}}],[\"实现mlp的整体的tensor\",{\"1\":{\"60\":1}}],[\"实现对超大规模模型的支持\",{\"1\":{\"53\":1}}],[\"实现超线性优化\",{\"1\":{\"23\":1}}],[\"即常数时间复杂度\",{\"1\":{\"88\":1}}],[\"即可轻松求得n\",{\"1\":{\"88\":1}}],[\"即向下取整\",{\"1\":{\"88\":1}}],[\"即使在n很小的时候\",{\"1\":{\"88\":1}}],[\"即将图像的不同空间交给不同线程计算\",{\"1\":{\"81\":1}}],[\"即在权重矩阵上执行\",{\"1\":{\"60\":1}}],[\"即输入与参数矩阵相乘\",{\"1\":{\"60\":1}}],[\"针对mlp\",{\"1\":{\"60\":1}}],[\"另一种方法是沿着它的列\",{\"1\":{\"60\":1}}],[\"另一部分动态存储临时数据\",{\"1\":{\"43\":1}}],[\"另一部分用来测试模型效果\",{\"1\":{\"4\":1}}],[\"需要综合流水线并行p\",{\"1\":{\"66\":1}}],[\"需要通过同步来保障语义对等\",{\"1\":{\"60\":1}}],[\"需要额外的12ψ\",{\"1\":{\"26\":1}}],[\"来确定当前卡要\",{\"1\":{\"60\":1}}],[\"来实现tensor\",{\"1\":{\"60\":1}}],[\"来对尽可能多的标签进行刻画\",{\"1\":{\"4\":1}}],[\"+nlog10​\",{\"1\":{\"88\":1}}],[\"+1\",{\"1\":{\"88\":2}}],[\"+\",{\"1\":{\"60\":1,\"81\":1,\"88\":1,\"89\":2}}],[\"张量并行\",{\"0\":{\"58\":1}}],[\"减少计算时内存占用\",{\"1\":{\"57\":1}}],[\"减少内存释放和分配的时间\",{\"1\":{\"35\":1}}],[\"减少内存使用\",{\"1\":{\"33\":1}}],[\"结果收敛不明显\",{\"1\":{\"56\":1}}],[\"类似cpu指令执行\",{\"1\":{\"56\":1}}],[\"切成更小的micro\",{\"1\":{\"56\":1}}],[\"切分成若干份给不同的gpu\",{\"1\":{\"8\":1}}],[\"切分模型让不同gpu延后计算开始时间\",{\"1\":{\"6\":1}}],[\"切分后的任务如何再将结果重新合在一起\",{\"1\":{\"3\":1}}],[\"注意与上张图不同\",{\"1\":{\"55\":1}}],[\"块\",{\"1\":{\"55\":1}}],[\"个批次的forward和backward运算\",{\"1\":{\"55\":1}}],[\"个\",{\"1\":{\"55\":2,\"70\":1}}],[\"个人介绍\",{\"0\":{\"0\":1}}],[\"ke\",{\"1\":{\"86\":1}}],[\"k\",{\"1\":{\"55\":4}}],[\"第\",{\"1\":{\"55\":1}}],[\"然后就会发现\",{\"1\":{\"87\":1}}],[\"然后通过数据并行技术扩展集群上进行加速\",{\"1\":{\"66\":1}}],[\"然后与权重矩阵进行矩阵乘法\",{\"1\":{\"60\":1}}],[\"然后流水线并行\",{\"1\":{\"56\":1}}],[\"然后每份放到一块\",{\"1\":{\"55\":1}}],[\"然后给不同的gpu去算每一个单独的部分\",{\"1\":{\"6\":1}}],[\"份\",{\"1\":{\"55\":1}}],[\"事实上task中给的提示还是比较明显的\",{\"1\":{\"81\":1}}],[\"事实上是tp\",{\"1\":{\"55\":1}}],[\"事实上对于采用哪种并行模式\",{\"1\":{\"6\":1}}],[\"最大迭代次数\",{\"1\":{\"82\":1}}],[\"最优\",{\"1\":{\"72\":1}}],[\"最终gpipe通过更大规模的模型和更大的batch\",{\"1\":{\"53\":1}}],[\"最小通信量为\",{\"1\":{\"47\":1}}],[\"最小化cpu和gpu之间的通信量\",{\"1\":{\"46\":1}}],[\"提高了模型并行模式下的设备利用率\",{\"1\":{\"53\":1}}],[\"提升训练精度\",{\"1\":{\"6\":1}}],[\"利用pipeline\",{\"1\":{\"53\":1}}],[\"方案\",{\"1\":{\"53\":1}}],[\"方法无法满足日益增长的参数量需求\",{\"1\":{\"23\":1}}],[\"必须引入分布式系统\",{\"1\":{\"53\":1}}],[\"必须在gpu上进行\",{\"1\":{\"47\":1}}],[\"仅将属于其\",{\"1\":{\"50\":1}}],[\"仅需\",{\"1\":{\"13\":1}}],[\"到\",{\"1\":{\"50\":2}}],[\"广播更新后的参数\",{\"1\":{\"49\":1}}],[\"广播到所有其他进程\",{\"1\":{\"14\":1}}],[\"删除\",{\"1\":{\"49\":1}}],[\"反向传播逻辑\",{\"1\":{\"49\":1}}],[\"反向传播梯度\",{\"1\":{\"49\":1}}],[\"上进行\",{\"1\":{\"60\":1}}],[\"上对参数进行类似\",{\"1\":{\"50\":1}}],[\"上并行更新对应的参数\",{\"1\":{\"50\":1}}],[\"上可用\",{\"1\":{\"50\":1}}],[\"上\",{\"1\":{\"50\":1,\"53\":1,\"55\":2,\"69\":2}}],[\"上更新参数\",{\"1\":{\"49\":1}}],[\"上分配全精度参数\",{\"1\":{\"49\":1}}],[\"上分配半精度参数\",{\"1\":{\"49\":1}}],[\"上的开销\",{\"1\":{\"87\":1}}],[\"上的梯度\",{\"1\":{\"49\":1}}],[\"上的\",{\"1\":{\"47\":1}}],[\"上的内存\",{\"1\":{\"45\":1}}],[\"层视为线性层来处理\",{\"1\":{\"60\":1}}],[\"层时\",{\"1\":{\"60\":1}}],[\"层\",{\"1\":{\"49\":1,\"55\":2}}],[\"判断当前进程是否拥有第\",{\"1\":{\"49\":1}}],[\"x1\",{\"1\":{\"82\":2}}],[\"x0\",{\"1\":{\"82\":2}}],[\"xvf\",{\"1\":{\"80\":1}}],[\"xavier\",{\"1\":{\"60\":1}}],[\"x\",{\"1\":{\"49\":7,\"60\":2,\"88\":1}}],[\"下文将介绍一种用数学方法巧妙估算阶乘结果规模的方式\",{\"1\":{\"87\":1}}],[\"下载包\",{\"1\":{\"80\":1}}],[\"下载解压一下编译环境就好啦\",{\"1\":{\"80\":1}}],[\"下图gpu与cpu二次通信应该是从cpu到gpu\",{\"1\":{\"49\":1}}],[\"下也能保持效率\",{\"1\":{\"46\":1}}],[\"之间进行\",{\"1\":{\"50\":1}}],[\"之间的移动\",{\"1\":{\"45\":1}}],[\"之后\",{\"1\":{\"49\":1}}],[\"消除大部分通信成本\",{\"1\":{\"49\":1}}],[\"消除了数据和模型并行训练中的内存冗余\",{\"1\":{\"23\":1}}],[\"此外\",{\"1\":{\"49\":1}}],[\"此时不再提供任何其他新的输入\",{\"1\":{\"64\":1}}],[\"此时\",{\"1\":{\"11\":1}}],[\"只保留最开始的输入\",{\"1\":{\"57\":1}}],[\"只需要在gpu内存中临时保存少量的梯度\",{\"1\":{\"49\":1}}],[\"只有将\",{\"1\":{\"47\":1}}],[\"只有那些计算复杂度低于o\",{\"1\":{\"47\":1}}],[\"只有很少一部分被过程中产生的冗余量使用了\",{\"1\":{\"25\":1}}],[\"过程中\",{\"1\":{\"49\":1,\"50\":1}}],[\"由于我之前已经测试过最大数据规模\",{\"1\":{\"89\":1}}],[\"由于fp16参数已经位于gpu上\",{\"1\":{\"49\":1}}],[\"由于每个机器\",{\"1\":{\"19\":1}}],[\"单身狗进化\",{\"1\":{\"86\":1}}],[\"单batch\",{\"1\":{\"56\":1}}],[\"单批量以这种顺序进行计算\",{\"1\":{\"55\":1}}],[\"单机gpu内存有限\",{\"1\":{\"53\":1}}],[\"单卡策略\",{\"0\":{\"49\":1}}],[\"单就这一块部分内存而言\",{\"1\":{\"31\":1}}],[\"才能达成最小通信量策略\",{\"1\":{\"47\":1}}],[\"void\",{\"1\":{\"82\":1}}],[\"vocabutility\",{\"1\":{\"60\":1}}],[\"vocab\",{\"1\":{\"60\":9}}],[\"vocabparallelembedding\",{\"1\":{\"60\":2}}],[\"v1\",{\"1\":{\"80\":4}}],[\"variance\",{\"1\":{\"47\":1}}],[\"visible\",{\"1\":{\"14\":1}}],[\"发送到\",{\"1\":{\"47\":2,\"50\":1}}],[\"权重更新等\",{\"1\":{\"47\":1}}],[\"如何快速搜索\",{\"1\":{\"69\":1}}],[\"如何将一个\",{\"1\":{\"69\":2}}],[\"如何合理的使用上面的多种并行技术一直是一个困难的命题\",{\"1\":{\"62\":1}}],[\"如进行backward更新\",{\"1\":{\"66\":1}}],[\"如microbatch的大小\",{\"1\":{\"62\":1}}],[\"如图中所示\",{\"1\":{\"47\":1}}],[\"如范数计算\",{\"1\":{\"47\":1}}],[\"如果已经到最后部分不够切分\",{\"1\":{\"82\":1}}],[\"如果该遇到整除要加一行避免遗漏\",{\"1\":{\"82\":1}}],[\"如果还是使用半精度进行运算\",{\"1\":{\"26\":1}}],[\"如果我们希望分布式系统在ai训练中发挥他的力量\",{\"1\":{\"6\":1}}],[\"如果我们一台机器存储不开我们的数据集\",{\"1\":{\"4\":1}}],[\"如果我们一台机器\",{\"1\":{\"4\":1}}],[\"和阶乘计算结果的误差程度\",{\"1\":{\"88\":1}}],[\"和memory\",{\"1\":{\"66\":1}}],[\"和数据并行时\",{\"1\":{\"66\":1}}],[\"和\",{\"1\":{\"47\":2,\"55\":1,\"60\":1,\"68\":1,\"70\":1,\"71\":1,\"72\":1}}],[\"的位数\",{\"1\":{\"88\":1}}],[\"的位数就是距离弯通脱单的天数\",{\"1\":{\"86\":1}}],[\"的弯通想知道自己还有多久能脱单\",{\"1\":{\"86\":1}}],[\"的阶乘\",{\"1\":{\"86\":1}}],[\"的代码\",{\"1\":{\"82\":1}}],[\"的开头和结尾插入计时代码\",{\"1\":{\"81\":1}}],[\"的并发事实\",{\"1\":{\"81\":1}}],[\"的并行方法\",{\"1\":{\"69\":1}}],[\"的执行顺序\",{\"1\":{\"70\":1}}],[\"的效能\",{\"1\":{\"62\":1}}],[\"的模型参数\",{\"1\":{\"55\":1}}],[\"的方案\",{\"1\":{\"53\":1}}],[\"的平均梯度\",{\"1\":{\"50\":1}}],[\"的\",{\"1\":{\"47\":2,\"50\":1,\"55\":1,\"60\":2,\"72\":1}}],[\"的通信带宽\",{\"1\":{\"47\":1}}],[\"的计算复杂度都是o\",{\"1\":{\"47\":1}}],[\"的计算才能转移到cpu上\",{\"1\":{\"47\":1}}],[\"的额外通讯开销\",{\"1\":{\"39\":1}}],[\"训练的计算复杂度通常为o\",{\"1\":{\"47\":1}}],[\"训练效果越好\",{\"1\":{\"4\":1}}],[\"允许将cpu优化器步骤与gpu计算重叠\",{\"1\":{\"46\":1}}],[\"延迟一步的参数更新\",{\"1\":{\"46\":1}}],[\"其余保持图像默认参数\",{\"1\":{\"82\":1}}],[\"其复杂度为o\",{\"1\":{\"47\":1}}],[\"其速度比现有技术快6倍\",{\"1\":{\"46\":1}}],[\"其中内层中括号标记运算顺序\",{\"1\":{\"88\":1}}],[\"其中m为模型大小\",{\"1\":{\"47\":1}}],[\"其中m和b分别为模型规模和\",{\"1\":{\"46\":1}}],[\"其中k取决于模型\",{\"1\":{\"26\":1}}],[\"高效的cpu优化器\",{\"1\":{\"46\":1}}],[\"高估了gpu的存储性能\",{\"1\":{\"45\":1}}],[\"采取了两种优化措施\",{\"1\":{\"46\":1}}],[\"采用megatron的模型并行方式\",{\"1\":{\"41\":1}}],[\"较大\",{\"1\":{\"46\":1}}],[\"次计算\",{\"1\":{\"46\":2}}],[\"防止通信瓶颈\",{\"1\":{\"46\":1}}],[\"防止cpu性能瓶颈\",{\"1\":{\"46\":1}}],[\"以节省内存\",{\"1\":{\"66\":1}}],[\"以在三个关键方面达到最优化\",{\"1\":{\"46\":1}}],[\"以处理本地\",{\"1\":{\"14\":1}}],[\"通常还会加一些约束条件\",{\"1\":{\"70\":1}}],[\"通常建议在gpu内存满足的情况下最大化模型并行\",{\"1\":{\"66\":1}}],[\"通常建议在集群上采用流水线并行\",{\"1\":{\"66\":1}}],[\"通常在一个节点内部采用不超过g张卡做张量并行\",{\"1\":{\"66\":1}}],[\"通常pipeline\",{\"1\":{\"64\":1}}],[\"通常张量并行只适用于一个multi\",{\"1\":{\"62\":1}}],[\"通过代入n\",{\"1\":{\"88\":1}}],[\"通过斯特林公式我们可以简单估算阶乘的位数\",{\"1\":{\"88\":1}}],[\"通过编排forward\",{\"1\":{\"64\":1}}],[\"通过获取当前\",{\"1\":{\"60\":1}}],[\"通过结合上述两种方法\",{\"1\":{\"60\":1}}],[\"通过分析确定了cpu和gpu设备之间的最佳计算和数据划分策略\",{\"1\":{\"46\":1}}],[\"通讯效率低\",{\"1\":{\"18\":1}}],[\"通讯成本会比较高昂\",{\"1\":{\"6\":1}}],[\"与\",{\"1\":{\"45\":1,\"47\":1}}],[\"与zero\",{\"1\":{\"41\":1}}],[\"尽量减少数据在\",{\"1\":{\"45\":1}}],[\"优化器计算要求cpu进行o\",{\"1\":{\"46\":1}}],[\"优化器状态和梯度\",{\"1\":{\"49\":1}}],[\"优化器状态\",{\"1\":{\"6\":1,\"50\":1}}],[\"优化\",{\"1\":{\"45\":1}}],[\"背景\",{\"0\":{\"45\":1}}],[\"将阶乘结果用表存储\",{\"1\":{\"87\":1}}],[\"将成为任何一台机器的噩梦\",{\"1\":{\"87\":1}}],[\"将原本一个batch的数据分解为多个更小的micro\",{\"1\":{\"64\":1}}],[\"将\",{\"1\":{\"60\":1}}],[\"将weight矩阵a分割\",{\"1\":{\"60\":1}}],[\"将模型切分成一连串stage\",{\"1\":{\"53\":1}}],[\"将自己的\",{\"1\":{\"50\":1}}],[\"将更新后的参数复制回\",{\"1\":{\"49\":1}}],[\"将梯度和优化器状态在不同的\",{\"1\":{\"50\":1}}],[\"将梯度复制到\",{\"1\":{\"49\":1}}],[\"将梯度减少到拥有该层的进程\",{\"1\":{\"49\":1}}],[\"将fp16参数存储在gpu上\",{\"1\":{\"49\":1}}],[\"将该图分割为cpu和gpu设备之间的部分\",{\"1\":{\"47\":1}}],[\"将数据池分为两部分\",{\"1\":{\"43\":1}}],[\"将百度的\",{\"1\":{\"13\":1}}],[\"内存都有重要的影响\",{\"1\":{\"62\":1}}],[\"内存复制到\",{\"1\":{\"49\":1}}],[\"内存中的fp16参数中\",{\"1\":{\"49\":1}}],[\"内存中\",{\"1\":{\"49\":1,\"50\":2}}],[\"内存碎片通过对不同寿命的内存进行整理\",{\"1\":{\"35\":1}}],[\"内存其实根本无法使用\",{\"1\":{\"29\":1}}],[\"多线程不一定高效率\",{\"1\":{\"81\":1}}],[\"多个\",{\"1\":{\"69\":1}}],[\"多机集群\",{\"1\":{\"62\":1}}],[\"多batch训练时\",{\"1\":{\"56\":1}}],[\"多batch可以提速\",{\"1\":{\"56\":1}}],[\"多卡策略\",{\"0\":{\"50\":1}}],[\"多次通讯的方式收集数据\",{\"1\":{\"33\":1}}],[\"多台机器之间通讯耗费的时间会不会比原先计算的时间更长\",{\"1\":{\"3\":1}}],[\"再重新计算这些中间结果\",{\"1\":{\"57\":1}}],[\"再进行通讯获取参数\",{\"1\":{\"31\":1}}],[\"再做聚合和同步\",{\"1\":{\"19\":1}}],[\"而且\",{\"1\":{\"88\":1}}],[\"而通信成本大大增长\",{\"1\":{\"63\":1}}],[\"而流水线并行则几乎只用于更大的模型\",{\"1\":{\"62\":1}}],[\"而非对所有输入\",{\"1\":{\"55\":1}}],[\"而其余的计算\",{\"1\":{\"47\":1}}],[\"而gpu需进行o\",{\"1\":{\"46\":1}}],[\"而是切分后再流水线并行\",{\"1\":{\"56\":1}}],[\"而是对输出进行通讯和更新\",{\"1\":{\"41\":1}}],[\"而是直接替换\",{\"1\":{\"12\":1}}],[\"而在其他gpu需要使用其进行计算时\",{\"1\":{\"31\":1}}],[\"两者使用均不高效\",{\"1\":{\"31\":1}}],[\"两种并行都需要存储模型状态变量\",{\"1\":{\"31\":1}}],[\"因为每一个分发计算都需要完全copy所有数据\",{\"1\":{\"31\":1}}],[\"因为通讯更少\",{\"1\":{\"31\":1}}],[\"因此这部分计算不需要与cpu进行通信\",{\"1\":{\"49\":1}}],[\"因此\",{\"1\":{\"19\":1,\"49\":1}}],[\"因此不同机器之间处理的bucket的顺序将会不一致\",{\"1\":{\"19\":1}}],[\"效率更高\",{\"1\":{\"31\":1}}],[\"用pytorch等使用虚拟内存分配方式的库时\",{\"1\":{\"29\":1}}],[\"也会是比较大的开销\",{\"1\":{\"87\":1}}],[\"也就是端到端的计算能够正确的完成\",{\"1\":{\"64\":1}}],[\"也就是单计算仅需4ψ\",{\"1\":{\"26\":1}}],[\"也可以考虑每个gpu都各自保存和重算部分数据\",{\"1\":{\"33\":1}}],[\"也可以是一个batch\",{\"1\":{\"8\":1}}],[\"存储持续整个训练过程\",{\"1\":{\"50\":1}}],[\"存储momentum和variance\",{\"1\":{\"26\":1}}],[\"存储模型的参数和输入\",{\"1\":{\"26\":1}}],[\"导致模型训练失效\",{\"1\":{\"26\":1}}],[\"均采用fp16半精度运算\",{\"1\":{\"26\":1}}],[\"一个高效的并行策略搜索引擎\",{\"1\":{\"68\":1}}],[\"一个更加全面的并行策略搜索空间\",{\"1\":{\"68\":1}}],[\"一种方法是沿着其行\",{\"1\":{\"60\":1}}],[\"一旦梯度在\",{\"1\":{\"50\":1}}],[\"一部分存储大批量的计算数据\",{\"1\":{\"43\":1}}],[\"一般来说\",{\"1\":{\"26\":1}}],[\"一张gpu\",{\"1\":{\"4\":1}}],[\"要是用递归或者循环写阶乘\",{\"1\":{\"87\":1}}],[\"要注意分割的时候会不会漏行\",{\"1\":{\"81\":1}}],[\"要在合理时间内找到最优解依然比较困难\",{\"1\":{\"70\":1}}],[\"要服务于计算速度内存变化就会发生膨胀\",{\"1\":{\"26\":1}}],[\"要用多少张卡进行并行\",{\"1\":{\"6\":1}}],[\"看上去这是仅仅由1变2的内存保留变化\",{\"1\":{\"26\":1}}],[\"论文基于当前的\",{\"1\":{\"72\":1}}],[\"论文提出从\",{\"1\":{\"69\":1}}],[\"论文提出了一种名为efficiency的offload策略\",{\"1\":{\"46\":1}}],[\"论文中提到的mp就是传统的mp方案\",{\"1\":{\"55\":1}}],[\"论文中所提到的dp背景本篇blog前文均有提及\",{\"1\":{\"17\":1}}],[\"论文假设有30\",{\"1\":{\"29\":1}}],[\"论文以adam优化器为例说明了模型造成的内存浪费是一件难以接受的事情\",{\"1\":{\"26\":1}}],[\"临时缓冲区和不可用的碎片内存所消耗\",{\"1\":{\"24\":1}}],[\"剩余内存被激活\",{\"1\":{\"24\":1}}],[\"大家可以简单跑一下这个程序\",{\"1\":{\"87\":1}}],[\"大家都对ml有一些基本的认识了\",{\"1\":{\"6\":1}}],[\"大多数\",{\"1\":{\"70\":1}}],[\"大op\",{\"1\":{\"69\":1}}],[\"大模型即使的带宽小的情况下\",{\"1\":{\"33\":1}}],[\"大部分内存都被用于模型本身数据的存储和运算\",{\"1\":{\"25\":1}}],[\"大部分内存\",{\"1\":{\"24\":1}}],[\"流水线并行技术将一个模型\",{\"1\":{\"64\":1}}],[\"流水线并行中的schedule\",{\"1\":{\"62\":1}}],[\"流水线并行\",{\"0\":{\"51\":1},\"1\":{\"24\":1}}],[\"简介\",{\"0\":{\"69\":1}}],[\"简单增加机器数量也用处不大\",{\"1\":{\"24\":1}}],[\"简称pp\",{\"1\":{\"6\":1}}],[\"简称fsdp\",{\"1\":{\"6\":1}}],[\"简称tp\",{\"1\":{\"6\":1}}],[\"简称mp\",{\"1\":{\"6\":1}}],[\"简称dp\",{\"1\":{\"6\":1}}],[\"巨量参数可以大幅提升nlp处理能力\",{\"1\":{\"24\":1}}],[\"同时\",{\"1\":{\"72\":1}}],[\"同时输入\",{\"1\":{\"70\":1}}],[\"同时确保准确性\",{\"1\":{\"46\":1}}],[\"同时最大限度地节省\",{\"1\":{\"45\":1}}],[\"同时又有12ψ个byte\",{\"1\":{\"26\":1}}],[\"同时保持高效率\",{\"1\":{\"23\":1}}],[\"同时保持了低通信量和高计算粒度\",{\"1\":{\"23\":1}}],[\"同时对分布式开发\",{\"1\":{\"0\":1}}],[\"零冗余优化器\",{\"1\":{\"23\":1}}],[\"现有系统在模型训练中内存消耗的全部范围\",{\"1\":{\"24\":1}}],[\"现有的pp\",{\"1\":{\"24\":1}}],[\"现有dp\",{\"1\":{\"23\":1}}],[\"现在假定我们要做一个训练任务\",{\"1\":{\"6\":1}}],[\"深度学习模型在训练万亿级别参数时存在根本性限制\",{\"1\":{\"23\":1}}],[\"zero3\",{\"0\":{\"39\":1}}],[\"zero2\",{\"0\":{\"38\":1}}],[\"zero1\",{\"0\":{\"37\":1},\"1\":{\"39\":1}}],[\"zero考虑可以使用将模型内存切分成多分\",{\"1\":{\"33\":1}}],[\"zero使用不同的方式优化这两种内存使用\",{\"1\":{\"25\":1}}],[\"zero\",{\"0\":{\"22\":1,\"30\":1,\"31\":1,\"32\":1,\"36\":1,\"40\":1,\"44\":1,\"48\":1},\"1\":{\"22\":1,\"23\":1,\"44\":1,\"45\":1,\"47\":1,\"49\":3,\"50\":2}}],[\"集合通讯库\",{\"0\":{\"20\":1}}],[\"则直接标记为ready\",{\"1\":{\"19\":1}}],[\"对通信\",{\"1\":{\"62\":1}}],[\"对数据按层切分\",{\"1\":{\"55\":1}}],[\"对数据并行中存储的fp16参数进行切分\",{\"1\":{\"39\":1}}],[\"对数据并行中存储的fp16梯度进行切分\",{\"1\":{\"38\":1}}],[\"对应的嵌入向量处理成\",{\"1\":{\"60\":1}}],[\"对应的每个\",{\"1\":{\"50\":1}}],[\"对应位置数据不再做相加\",{\"1\":{\"12\":1}}],[\"对切分后部分输入分开运算\",{\"1\":{\"41\":1}}],[\"对优化器本身存储的fp32数据进行切分\",{\"1\":{\"37\":1}}],[\"对于单个\",{\"1\":{\"69\":3}}],[\"对于多个gpu集群\",{\"1\":{\"66\":1}}],[\"对于内存使用和kernel计算效率\",{\"1\":{\"62\":1}}],[\"对于临时缓存采用开一段固定大小内存的方式进行反复存储\",{\"1\":{\"34\":1}}],[\"对于大型模型\",{\"1\":{\"24\":1}}],[\"对于没有参与计算的参数\",{\"1\":{\"19\":1}}],[\"哪些参数没有参与计算\",{\"1\":{\"19\":1}}],[\"记录哪些参数参与计算\",{\"1\":{\"19\":1}}],[\"前向传播逻辑\",{\"1\":{\"49\":1}}],[\"前向传播\",{\"1\":{\"49\":1}}],[\"前向传播结束后从输出开始遍历计算图\",{\"1\":{\"19\":1}}],[\"前面所提及的方法\",{\"1\":{\"6\":1}}],[\"后向传播的顺序与梯度更新的顺序大致可认为是相同的\",{\"1\":{\"19\":1}}],[\"选择收集到一定量的梯度\",{\"1\":{\"19\":1}}],[\"改进做法\",{\"0\":{\"19\":1}}],[\"改进了\",{\"1\":{\"13\":1}}],[\"传统做法\",{\"0\":{\"18\":1}}],[\"传统的dp在带来使用大数据集可能的同时\",{\"1\":{\"9\":1}}],[\"不难发现只要我们给出startrow\",{\"1\":{\"82\":1}}],[\"不需要线程之间进行响应和同步\",{\"1\":{\"81\":1}}],[\"不需要进行额外通讯\",{\"1\":{\"60\":1}}],[\"不过由于我们使用的a是同一个\",{\"1\":{\"60\":1}}],[\"不是magatron\",{\"1\":{\"55\":1}}],[\"不同属性如何并行\",{\"1\":{\"69\":1}}],[\"不同gpu之间需要进行定期同步\",{\"1\":{\"64\":1}}],[\"不同的并行策略\",{\"1\":{\"62\":1}}],[\"不同参数的梯度在后向调度的不同位置计算\",{\"1\":{\"49\":1}}],[\"不同迭代中\",{\"1\":{\"19\":1}}],[\"不得不保存的模型内容\",{\"1\":{\"24\":1}}],[\"不再赘述\",{\"1\":{\"17\":1}}],[\"不切分数据的方式\",{\"1\":{\"6\":1}}],[\"就是采用高精度的算法\",{\"1\":{\"87\":1}}],[\"就是将单一计算机节点要做的任务分布在多个计算机节点上完成的\",{\"1\":{\"3\":1}}],[\"就已经溢出了\",{\"1\":{\"87\":1}}],[\"就可以完成计算了\",{\"1\":{\"82\":1}}],[\"就可以解决这个问题\",{\"1\":{\"81\":1}}],[\"就可以实现从本机训练到分布式训练的部署\",{\"1\":{\"16\":1}}],[\"就放在第\",{\"1\":{\"55\":1}}],[\"就调用allreduce对该bucket进行通信\",{\"1\":{\"19\":1}}],[\"using\",{\"1\":{\"52\":1,\"59\":1,\"61\":1}}],[\"user\",{\"1\":{\"20\":1}}],[\"unique\",{\"0\":{\"47\":1}}],[\"update\",{\"1\":{\"16\":1,\"47\":2,\"49\":1}}],[\"uber\",{\"1\":{\"9\":1}}],[\"bin\",{\"1\":{\"80\":1}}],[\"billion\",{\"1\":{\"44\":1,\"59\":1}}],[\"beyond\",{\"1\":{\"68\":1}}],[\"b考虑\",{\"1\":{\"66\":1}}],[\"by\",{\"1\":{\"60\":1}}],[\"bk\",{\"1\":{\"55\":2}}],[\"bwd后\",{\"1\":{\"47\":1}}],[\"bwd\",{\"1\":{\"47\":1,\"49\":2,\"50\":1}}],[\"b为有效batch\",{\"1\":{\"47\":1}}],[\"b\",{\"1\":{\"31\":1,\"33\":1,\"66\":2}}],[\"bubble\",{\"1\":{\"64\":1}}],[\"bubble大小也有影响\",{\"1\":{\"62\":1}}],[\"bubble的大小\",{\"1\":{\"62\":1}}],[\"buﬀers\",{\"0\":{\"28\":1,\"34\":1,\"42\":1}}],[\"bucketing\",{\"1\":{\"19\":1}}],[\"bf16\",{\"1\":{\"26\":1}}],[\"batch的数量\",{\"1\":{\"64\":1}}],[\"batch的操作\",{\"1\":{\"64\":1}}],[\"batch过小\",{\"1\":{\"63\":1}}],[\"batches\",{\"0\":{\"56\":1}}],[\"batch\",{\"1\":{\"46\":4,\"49\":3,\"56\":2,\"64\":1,\"66\":2}}],[\"batch较小时\",{\"1\":{\"18\":1}}],[\"backward\",{\"1\":{\"16\":2,\"49\":4,\"55\":1,\"60\":1}}],[\"broadcastglobalvariableshook\",{\"1\":{\"14\":1}}],[\"broadcast\",{\"1\":{\"13\":1,\"49\":1}}],[\"9\",{\"1\":{\"16\":1}}],[\"8倍加速比的效果\",{\"1\":{\"81\":1}}],[\"8个线程\",{\"1\":{\"81\":1}}],[\"8位指数位\",{\"1\":{\"26\":2}}],[\"8\",{\"1\":{\"16\":1}}],[\"71828182846\",{\"1\":{\"89\":1}}],[\"7位尾数位\",{\"1\":{\"26\":1}}],[\"7\",{\"1\":{\"16\":1,\"81\":1}}],[\"6\",{\"1\":{\"16\":1,\"81\":1}}],[\"5位指数位\",{\"1\":{\"26\":1}}],[\"5\",{\"1\":{\"16\":1,\"81\":1}}],[\"3d并行\",{\"0\":{\"61\":1}}],[\"32和p32\",{\"1\":{\"47\":1}}],[\"32\",{\"1\":{\"47\":1}}],[\"3\",{\"1\":{\"16\":1,\"55\":1,\"81\":1,\"89\":2}}],[\"3次更新之后\",{\"1\":{\"11\":1}}],[\"e\",{\"1\":{\"89\":2}}],[\"en​\",{\"1\":{\"88\":3}}],[\"end\",{\"1\":{\"60\":3}}],[\"empty\",{\"1\":{\"60\":1}}],[\"embeddings\",{\"1\":{\"60\":4}}],[\"embedding\",{\"1\":{\"60\":7}}],[\"efficient\",{\"1\":{\"52\":1,\"61\":1}}],[\"efficiency\",{\"0\":{\"46\":1}}],[\"else\",{\"1\":{\"49\":2,\"60\":1}}],[\"execution\",{\"1\":{\"68\":1,\"69\":2}}],[\"extended\",{\"0\":{\"24\":1}}],[\"export\",{\"1\":{\"80\":1}}],[\"exp\",{\"1\":{\"16\":2}}],[\"experiences\",{\"1\":{\"15\":1}}],[\"easy\",{\"1\":{\"9\":1}}],[\"workerargs\",{\"1\":{\"82\":1}}],[\"world\",{\"1\":{\"49\":1}}],[\"width\",{\"1\":{\"82\":2}}],[\"with\",{\"1\":{\"14\":1,\"16\":1}}],[\"wget\",{\"1\":{\"80\":1}}],[\"weight\",{\"1\":{\"60\":2}}],[\"where\",{\"0\":{\"25\":1}}],[\"while\",{\"1\":{\"14\":1}}],[\"www\",{\"1\":{\"20\":1}}],[\"cin\",{\"1\":{\"87\":1}}],[\"cpp中的源码\",{\"1\":{\"82\":1}}],[\"cpu计算量可能成为瓶颈\",{\"1\":{\"46\":1}}],[\"cpu计算量并不是瓶颈\",{\"1\":{\"46\":1}}],[\"cpu\",{\"1\":{\"45\":2,\"47\":4,\"49\":11,\"50\":4}}],[\"cs149\",{\"0\":{\"75\":1,\"78\":1},\"1\":{\"80\":2},\"2\":{\"76\":1,\"83\":1}}],[\"carlo\",{\"1\":{\"69\":1}}],[\"category\",{\"1\":{\"60\":3}}],[\"chain\",{\"1\":{\"69\":1}}],[\"checkpointing\",{\"0\":{\"41\":1}}],[\"checkpoint\",{\"1\":{\"14\":1}}],[\"clusters\",{\"1\":{\"61\":1}}],[\"clone\",{\"1\":{\"60\":1,\"80\":1}}],[\"class\",{\"1\":{\"60\":2}}],[\"ctx\",{\"1\":{\"60\":2}}],[\"cell\",{\"1\":{\"55\":2}}],[\"c\",{\"1\":{\"31\":1}}],[\"cout\",{\"1\":{\"87\":1}}],[\"course\",{\"0\":{\"75\":1}}],[\"co\",{\"1\":{\"70\":1}}],[\"columns\",{\"1\":{\"60\":2}}],[\"copy\",{\"1\":{\"49\":2}}],[\"const\",{\"1\":{\"82\":1}}],[\"constant\",{\"0\":{\"42\":1}}],[\"consumption\",{\"0\":{\"27\":1}}],[\"config=config\",{\"1\":{\"14\":1}}],[\"configproto\",{\"1\":{\"14\":1}}],[\"config\",{\"1\":{\"14\":2}}],[\"compute\",{\"1\":{\"49\":1,\"70\":1}}],[\"com\",{\"1\":{\"9\":1,\"15\":1,\"20\":1,\"22\":1,\"59\":1,\"61\":1,\"80\":2}}],[\"保证带宽不浪费\",{\"1\":{\"42\":1}}],[\"保证各个计算gpu模型同步\",{\"1\":{\"8\":1}}],[\"保存到检查点以及在完成或发生错误时关闭\",{\"1\":{\"14\":1}}],[\"从下图中我们可以看出\",{\"1\":{\"60\":1}}],[\"从而降低内存占用\",{\"1\":{\"31\":1}}],[\"从而保证通讯无boundary\",{\"1\":{\"6\":1}}],[\"从检查点恢复\",{\"1\":{\"14\":1}}],[\"负责会话初始化\",{\"1\":{\"14\":1}}],[\"mcmc算法内部维护一个\",{\"1\":{\"72\":1}}],[\"m=b\",{\"1\":{\"66\":1}}],[\"mm\",{\"1\":{\"60\":1}}],[\"multi\",{\"1\":{\"59\":1}}],[\"method=init\",{\"1\":{\"60\":1}}],[\"megatron\",{\"0\":{\"59\":1},\"1\":{\"59\":2,\"61\":2}}],[\"memory\",{\"0\":{\"25\":1,\"27\":1,\"29\":1,\"33\":1,\"35\":1,\"43\":1},\"1\":{\"22\":1}}],[\"main\",{\"1\":{\"89\":1}}],[\"mandelbrotserial\",{\"1\":{\"82\":2}}],[\"mandelbort\",{\"0\":{\"79\":1},\"1\":{\"81\":1}}],[\"managing\",{\"0\":{\"34\":1,\"35\":1}}],[\"markov\",{\"1\":{\"69\":1}}],[\"maxiterations\",{\"1\":{\"82\":2}}],[\"max\",{\"1\":{\"60\":1,\"87\":1}}],[\"masked\",{\"1\":{\"60\":4}}],[\"mask\",{\"1\":{\"60\":6}}],[\"materialization\",{\"0\":{\"57\":1}}],[\"mb\",{\"1\":{\"46\":1,\"47\":3}}],[\"m\",{\"1\":{\"46\":1,\"47\":1}}],[\"mp占据模型内存\",{\"1\":{\"33\":1}}],[\"mp都在通信和计算效率之间权衡\",{\"1\":{\"24\":1}}],[\"mp\",{\"1\":{\"23\":1,\"53\":1}}],[\"mpi\",{\"1\":{\"20\":2}}],[\"mini\",{\"1\":{\"56\":1}}],[\"minimize\",{\"1\":{\"14\":1}}],[\"microbatch的选择也非常重要\",{\"1\":{\"66\":1}}],[\"micro\",{\"0\":{\"56\":1},\"1\":{\"64\":1,\"66\":1}}],[\"microsoft\",{\"1\":{\"22\":1}}],[\"mseloss\",{\"1\":{\"16\":1}}],[\"momentum\",{\"1\":{\"47\":1}}],[\"monte\",{\"1\":{\"69\":1}}],[\"mon\",{\"1\":{\"14\":3}}],[\"monitoredtrainingsession\",{\"1\":{\"14\":2}}],[\"models\",{\"1\":{\"22\":1,\"59\":1}}],[\"model\",{\"0\":{\"26\":1,\"55\":1,\"60\":1},\"1\":{\"6\":1,\"16\":1,\"25\":1,\"44\":1,\"59\":1,\"60\":8,\"61\":1,\"68\":1}}],[\"04\",{\"1\":{\"80\":1}}],[\"04473https\",{\"1\":{\"61\":1}}],[\"05358\",{\"1\":{\"68\":1}}],[\"05799https\",{\"1\":{\"9\":1}}],[\"08053https\",{\"1\":{\"59\":1}}],[\"06965\",{\"1\":{\"52\":1}}],[\"06840\",{\"1\":{\"44\":1}}],[\"06840https\",{\"1\":{\"44\":1}}],[\"02054\",{\"1\":{\"22\":1}}],[\"01\",{\"1\":{\"14\":1,\"16\":1}}],[\"0\",{\"1\":{\"14\":3,\"49\":1,\"60\":4,\"80\":4}}],[\"构建模型\",{\"1\":{\"14\":1}}],[\"lm\",{\"0\":{\"59\":1},\"1\":{\"59\":2,\"61\":2}}],[\"lm提出的新mp方案\",{\"1\":{\"55\":1}}],[\"l\",{\"1\":{\"49\":14}}],[\"lab\",{\"0\":{\"78\":1},\"2\":{\"83\":1,\"84\":1}}],[\"large\",{\"1\":{\"61\":1}}],[\"language\",{\"1\":{\"59\":1,\"61\":1}}],[\"layer\",{\"1\":{\"55\":1}}],[\"layers\",{\"1\":{\"49\":12}}],[\"latest\",{\"1\":{\"20\":1}}],[\"lr=0\",{\"1\":{\"16\":1}}],[\"linux\",{\"1\":{\"80\":3}}],[\"linear\",{\"1\":{\"16\":1}}],[\"list\",{\"1\":{\"14\":1}}],[\"log10\",{\"1\":{\"89\":2}}],[\"log10​\",{\"1\":{\"88\":1}}],[\"log\",{\"1\":{\"88\":1}}],[\"logs\",{\"1\":{\"14\":1}}],[\"long\",{\"1\":{\"87\":2}}],[\"location\",{\"1\":{\"70\":1}}],[\"local\",{\"1\":{\"14\":1}}],[\"loss\",{\"1\":{\"14\":2,\"49\":1}}],[\"learning\",{\"1\":{\"9\":1}}],[\"of\",{\"1\":{\"52\":1}}],[\"offload在cpu上直接更新fp32参数和剩余的优化器状态\",{\"1\":{\"49\":1}}],[\"offload在小\",{\"1\":{\"46\":1}}],[\"offload可以立即将这些梯度逐个或切分传输到\",{\"1\":{\"49\":1}}],[\"offload将数据进行分区\",{\"1\":{\"49\":1}}],[\"offload将深度学习训练建模为数据流图\",{\"1\":{\"47\":1}}],[\"offload\",{\"0\":{\"44\":1,\"47\":1,\"48\":1},\"1\":{\"44\":1,\"45\":1,\"46\":1,\"50\":3}}],[\"owns\",{\"1\":{\"49\":1}}],[\"owner\",{\"1\":{\"49\":6}}],[\"overview\",{\"0\":{\"30\":1,\"31\":1,\"32\":1}}],[\"output\",{\"1\":{\"60\":5,\"82\":2}}],[\"out\",{\"1\":{\"16\":2}}],[\"one\",{\"1\":{\"60\":1}}],[\"on\",{\"1\":{\"15\":1,\"49\":4,\"61\":1}}],[\"op并行\",{\"1\":{\"69\":1}}],[\"operator\",{\"1\":{\"69\":4,\"70\":6,\"71\":1,\"72\":3}}],[\"open\",{\"1\":{\"20\":1}}],[\"op\",{\"1\":{\"14\":2}}],[\"optimal\",{\"0\":{\"47\":1}}],[\"optimizations\",{\"1\":{\"22\":1}}],[\"optimizer\",{\"0\":{\"26\":1},\"1\":{\"16\":1,\"69\":1}}],[\"optim\",{\"1\":{\"16\":3,\"49\":2}}],[\"options\",{\"1\":{\"14\":1}}],[\"opt\",{\"1\":{\"14\":4,\"16\":2}}],[\"org\",{\"1\":{\"9\":1,\"15\":1,\"20\":1,\"22\":1,\"44\":2,\"52\":1,\"59\":1,\"61\":1,\"68\":1}}],[\"=\",{\"1\":{\"14\":7,\"16\":6,\"49\":7,\"60\":10,\"82\":3,\"87\":5,\"89\":3}}],[\"固定\",{\"1\":{\"14\":1}}],[\"初始化权重\",{\"1\":{\"60\":1}}],[\"初始化每个进程的层\",{\"1\":{\"49\":1}}],[\"初始化\",{\"1\":{\"14\":1}}],[\"i++\",{\"1\":{\"87\":1}}],[\"idx\",{\"1\":{\"60\":3}}],[\"id\",{\"1\":{\"60\":1}}],[\"if\",{\"1\":{\"49\":4,\"60\":2,\"82\":1,\"89\":1}}],[\"i\",{\"1\":{\"49\":18,\"87\":3}}],[\"ispc\",{\"1\":{\"80\":5}}],[\"is\",{\"1\":{\"49\":4}}],[\"io\",{\"1\":{\"20\":1}}],[\"import\",{\"1\":{\"14\":2,\"16\":4}}],[\"include\",{\"1\":{\"89\":2}}],[\"index\",{\"1\":{\"60\":8}}],[\"int\",{\"1\":{\"82\":6,\"87\":2,\"89\":5}}],[\"into\",{\"0\":{\"36\":1,\"40\":1,\"56\":1}}],[\"introduction\",{\"0\":{\"24\":1}}],[\"insights\",{\"0\":{\"30\":1,\"31\":1,\"32\":1}}],[\"input\",{\"1\":{\"60\":12}}],[\"inp\",{\"1\":{\"16\":2}}],[\"initialize\",{\"1\":{\"16\":1,\"49\":2}}],[\"init\",{\"1\":{\"14\":1,\"16\":1,\"60\":3}}],[\"in\",{\"1\":{\"9\":1,\"49\":7}}],[\"步即可使用\",{\"1\":{\"13\":1}}],[\"404\",{\"1\":{\"93\":1}}],[\"4个维度描述搜索空间\",{\"1\":{\"69\":1}}],[\"4个cell\",{\"1\":{\"55\":1}}],[\"4\",{\"1\":{\"13\":1,\"16\":1,\"55\":1,\"81\":1}}],[\"操作符的共置\",{\"1\":{\"70\":1}}],[\"操作视为对输入进行索引操作\",{\"1\":{\"60\":1}}],[\"操作\",{\"1\":{\"13\":1,\"50\":1,\"60\":3}}],[\"添加hook\",{\"1\":{\"14\":1}}],[\"添加\",{\"1\":{\"13\":1,\"14\":1}}],[\"添加了对单机多卡的支持\",{\"1\":{\"13\":1}}],[\"并且梦到了一个帅气的男孩纸\",{\"1\":{\"86\":1}}],[\"并且每个\",{\"1\":{\"50\":1}}],[\"并在后续针对数据结果决定是否要进行优化\",{\"1\":{\"82\":1}}],[\"并随机替换被选择的\",{\"1\":{\"72\":1}}],[\"并使用模型并行操作来优化\",{\"1\":{\"60\":1}}],[\"并沿着其列\",{\"1\":{\"60\":1}}],[\"并将更新后的\",{\"1\":{\"49\":1}}],[\"并将其分为两部分\",{\"1\":{\"24\":1}}],[\"并减少\",{\"1\":{\"45\":1}}],[\"并优化了性能\",{\"1\":{\"13\":1}}],[\"并行计算\",{\"2\":{\"77\":1,\"84\":1}}],[\"并行运算\",{\"2\":{\"74\":1}}],[\"并行运算感兴趣\",{\"1\":{\"0\":1}}],[\"并行使用的gpu的数量\",{\"1\":{\"64\":1}}],[\"并行中使用的参数如何调整\",{\"1\":{\"6\":1}}],[\"库实现了\",{\"1\":{\"13\":1}}],[\"n=\",{\"1\":{\"88\":2}}],[\"n=ptd\",{\"1\":{\"66\":1}}],[\"n阶乘的计算量十分大\",{\"1\":{\"88\":1}}],[\"n阶乘的位数\",{\"1\":{\"86\":1}}],[\"n2\",{\"1\":{\"87\":1}}],[\"n\",{\"1\":{\"66\":1,\"70\":1,\"86\":4,\"87\":3,\"88\":4,\"89\":5}}],[\"naive\",{\"0\":{\"55\":1}}],[\"neural\",{\"1\":{\"52\":1,\"68\":1}}],[\"networks\",{\"1\":{\"52\":1,\"68\":1}}],[\"net\",{\"1\":{\"16\":5}}],[\"numthreads\",{\"1\":{\"82\":2}}],[\"numrows\",{\"1\":{\"82\":2}}],[\"num\",{\"1\":{\"49\":4,\"60\":4,\"89\":3}}],[\"novel\",{\"1\":{\"68\":1}}],[\"norm\",{\"1\":{\"60\":2}}],[\"normal\",{\"1\":{\"60\":1}}],[\"node\",{\"1\":{\"47\":1}}],[\"not\",{\"1\":{\"14\":1,\"93\":1}}],[\"n参数\",{\"1\":{\"41\":1}}],[\"n份数据\",{\"1\":{\"37\":1,\"38\":1,\"39\":1}}],[\"nvidia本身支持这种优化并不会有通讯增加\",{\"1\":{\"39\":1}}],[\"nvidia\",{\"1\":{\"20\":1,\"59\":1,\"61\":1}}],[\"nn\",{\"1\":{\"16\":5}}],[\"nccl\",{\"1\":{\"13\":1,\"20\":3}}],[\"nlp等ai方向\",{\"1\":{\"0\":1}}],[\"命名为\",{\"1\":{\"13\":1}}],[\"包括流水线并行和张量并行\",{\"1\":{\"66\":1}}],[\"包括优化器状态\",{\"1\":{\"24\":1}}],[\"包\",{\"1\":{\"13\":1}}],[\"相邻gpu对应位置进行通讯\",{\"1\":{\"12\":1}}],[\"目标是把红色块的数据广播到其余gpu对应的位置上\",{\"1\":{\"11\":1}}],[\"进行空间分解\",{\"1\":{\"81\":1}}],[\"进行数据计算\",{\"1\":{\"6\":1}}],[\"进而生成\",{\"1\":{\"72\":1}}],[\"进程直接在\",{\"1\":{\"50\":1}}],[\"进程\",{\"1\":{\"19\":1}}],[\"进入all\",{\"1\":{\"11\":1}}],[\"使每个gpu仅留1\",{\"1\":{\"37\":1,\"38\":1,\"39\":1}}],[\"使我们能够根据设备数量按比例扩展模型大小\",{\"1\":{\"23\":1}}],[\"使得参数额外开销尽可能减少\",{\"1\":{\"39\":1}}],[\"使得某些参数的梯度不需要用到\",{\"1\":{\"19\":1}}],[\"使得每个gpu只和其相邻的两块gpu通讯\",{\"1\":{\"11\":1}}],[\"使用16个线程运行改进后代码\",{\"1\":{\"81\":1}}],[\"使用固定大小buffer指定数据的单批发送量\",{\"1\":{\"42\":1}}],[\"使用reduce\",{\"1\":{\"41\":1}}],[\"使用时通讯获取完整参数\",{\"1\":{\"39\":1}}],[\"使用的参数可能不相同\",{\"1\":{\"19\":1}}],[\"使用参数的反序作为梯度放入bucket的顺序\",{\"1\":{\"19\":1}}],[\"使用方法\",{\"0\":{\"14\":1}}],[\"使用\",{\"1\":{\"13\":1}}],[\"使用尽可能多的参数\",{\"1\":{\"4\":1}}],[\"定义网络拓扑关系\",{\"1\":{\"11\":1}}],[\"rows++\",{\"1\":{\"82\":1}}],[\"rows\",{\"1\":{\"82\":6}}],[\"row\",{\"1\":{\"60\":1}}],[\"r\",{\"0\":{\"32\":1,\"40\":1}}],[\"repo到本地来开始lab了\",{\"1\":{\"80\":1}}],[\"releases\",{\"1\":{\"80\":1}}],[\"recompute也是一种可以考虑的方法\",{\"1\":{\"66\":1}}],[\"region\",{\"1\":{\"60\":1}}],[\"re\",{\"0\":{\"57\":1}}],[\"return\",{\"1\":{\"49\":2,\"60\":3,\"89\":1}}],[\"reducing\",{\"0\":{\"33\":1}}],[\"reduce\",{\"0\":{\"11\":1},\"1\":{\"11\":1,\"49\":1,\"50\":1,\"60\":3}}],[\"residual\",{\"0\":{\"27\":1},\"1\":{\"24\":1,\"25\":1}}],[\"range\",{\"1\":{\"49\":5,\"60\":1}}],[\"randn\",{\"1\":{\"16\":2}}],[\"rank\",{\"1\":{\"14\":3,\"49\":5,\"60\":2}}],[\"run\",{\"1\":{\"14\":1,\"16\":2}}],[\"ring\",{\"0\":{\"10\":1},\"1\":{\"10\":1,\"13\":2}}],[\"gz\",{\"1\":{\"80\":2}}],[\"get\",{\"1\":{\"60\":1}}],[\"gelu\",{\"1\":{\"60\":1}}],[\"global\",{\"1\":{\"60\":1,\"66\":1}}],[\"gloo\",{\"1\":{\"20\":1}}],[\"gloo和mpi\",{\"1\":{\"20\":1}}],[\"git\",{\"1\":{\"80\":2}}],[\"github\",{\"1\":{\"9\":1,\"15\":1,\"22\":1,\"59\":1,\"61\":1,\"80\":2}}],[\"giant\",{\"1\":{\"52\":1}}],[\"gpipe使用模型并行\",{\"1\":{\"53\":1}}],[\"gpipe\",{\"0\":{\"52\":1,\"53\":1},\"1\":{\"52\":1}}],[\"gpu总数\",{\"1\":{\"66\":1}}],[\"gpu服务器内部\",{\"1\":{\"62\":1}}],[\"gpu内存占用是一件非常昂贵的事情\",{\"1\":{\"45\":1}}],[\"gpu\",{\"1\":{\"14\":3,\"45\":2,\"47\":3,\"49\":5,\"50\":6,\"53\":1,\"55\":4,\"57\":1,\"60\":1,\"61\":1}}],[\"graph\",{\"1\":{\"70\":1,\"71\":1,\"72\":1}}],[\"gradient\",{\"1\":{\"60\":3}}],[\"gradients\",{\"0\":{\"26\":1}}],[\"grad\",{\"1\":{\"49\":7,\"60\":1}}],[\"group\",{\"1\":{\"16\":1}}],[\"go\",{\"0\":{\"25\":1}}],[\"gateway\",{\"1\":{\"20\":1}}],[\"gather阶段\",{\"1\":{\"11\":1}}],[\"gather\",{\"0\":{\"12\":1},\"1\":{\"10\":1,\"50\":1}}],[\"guide\",{\"1\":{\"20\":1}}],[\"s\",{\"1\":{\"89\":3}}],[\"sample并行\",{\"1\":{\"69\":1}}],[\"sample\",{\"1\":{\"69\":5,\"70\":1}}],[\"sa两个环节做了如下优化\",{\"1\":{\"60\":1}}],[\"simulator\",{\"1\":{\"68\":1,\"69\":1}}],[\"size\",{\"0\":{\"42\":1},\"1\":{\"46\":4,\"47\":1,\"49\":1,\"53\":1,\"60\":4,\"63\":1,\"66\":2,\"82\":2}}],[\"sosd\",{\"2\":{\"73\":1}}],[\"soap\",{\"1\":{\"68\":1,\"69\":2,\"70\":1}}],[\"solo\",{\"1\":{\"20\":1}}],[\"spatial\",{\"1\":{\"81\":1}}],[\"sparse\",{\"1\":{\"60\":1}}],[\"split\",{\"0\":{\"56\":1}}],[\"src\",{\"1\":{\"49\":1}}],[\"schedule\",{\"0\":{\"48\":1}}],[\"scanf\",{\"1\":{\"89\":1}}],[\"scale\",{\"1\":{\"44\":1,\"60\":1,\"61\":1}}],[\"scatter更新各个参数状态\",{\"1\":{\"41\":1}}],[\"scatter阶段结束\",{\"1\":{\"11\":1}}],[\"scatter\",{\"0\":{\"11\":1},\"1\":{\"50\":1}}],[\"scatter和all\",{\"1\":{\"10\":1}}],[\"super\",{\"1\":{\"47\":1,\"60\":1}}],[\"sgd\",{\"1\":{\"16\":1}}],[\"semantics\",{\"1\":{\"64\":1}}],[\"self\",{\"1\":{\"60\":24}}],[\"select\",{\"1\":{\"60\":1}}],[\"setup\",{\"1\":{\"16\":1}}],[\"sess\",{\"1\":{\"14\":3}}],[\"std\",{\"1\":{\"87\":2}}],[\"stanford\",{\"1\":{\"80\":1}}],[\"startrow\",{\"1\":{\"82\":5}}],[\"start\",{\"1\":{\"60\":4}}],[\"states\",{\"0\":{\"26\":2},\"1\":{\"24\":1,\"25\":2,\"49\":2}}],[\"step\",{\"1\":{\"16\":1,\"49\":2}}],[\"stop\",{\"1\":{\"14\":1}}],[\"strategy\",{\"0\":{\"47\":1},\"1\":{\"71\":1,\"72\":4}}],[\"str\",{\"1\":{\"14\":1}}],[\"should\",{\"1\":{\"14\":1}}],[\"sharded\",{\"1\":{\"6\":1}}],[\"可拆分的维度并不一样\",{\"1\":{\"70\":1}}],[\"可以通过计算对比来估计一下斯特林公式算出结果\",{\"1\":{\"88\":1}}],[\"可以简单分析一下mandelbrotserial\",{\"1\":{\"82\":1}}],[\"可以准确预测并行策略的性能\",{\"1\":{\"68\":1}}],[\"可以得到以下结论\",{\"1\":{\"66\":1}}],[\"可以将\",{\"1\":{\"60\":1}}],[\"可以在transformer中实现简单并发\",{\"1\":{\"60\":1}}],[\"可以切为\",{\"1\":{\"55\":1}}],[\"可以转移到cpu上\",{\"1\":{\"47\":1}}],[\"可以明显看到gpu数量增多时\",{\"1\":{\"9\":1}}],[\"可证明地最大化节约gpu内存\",{\"1\":{\"46\":1}}],[\"可能会导致梯度更新不稳定\",{\"1\":{\"56\":1}}],[\"可能内存池的维护并不能做到完全利用\",{\"1\":{\"29\":1}}],[\"可能并不会产生权重累计\",{\"1\":{\"26\":1}}],[\"可能在模型训练过程中梯度不大等原因\",{\"1\":{\"26\":1}}],[\"可能大幅度提升计算效率\",{\"1\":{\"3\":1}}],[\"又同时增加了额外的通讯开销\",{\"1\":{\"9\":1}}],[\"又切分模型的参数\",{\"1\":{\"6\":1}}],[\"1<=n<=25000\",{\"1\":{\"86\":1}}],[\"1位符号位\",{\"1\":{\"26\":3}}],[\"1909\",{\"1\":{\"59\":1}}],[\"1910\",{\"1\":{\"22\":1}}],[\"19\",{\"1\":{\"16\":1}}],[\"1807\",{\"1\":{\"68\":1}}],[\"1802\",{\"1\":{\"9\":1}}],[\"1811\",{\"1\":{\"52\":1}}],[\"18\",{\"1\":{\"16\":1}}],[\"17\",{\"1\":{\"16\":1}}],[\"16\",{\"1\":{\"16\":1}}],[\"15\",{\"1\":{\"16\":1}}],[\"15704https\",{\"1\":{\"15\":1}}],[\"141592654\",{\"1\":{\"89\":1}}],[\"14\",{\"1\":{\"16\":1}}],[\"13\",{\"1\":{\"16\":1}}],[\"12\",{\"1\":{\"16\":1,\"55\":1}}],[\"11\",{\"1\":{\"16\":1}}],[\"10位尾数位\",{\"1\":{\"26\":1}}],[\"10\",{\"1\":{\"16\":5,\"86\":1}}],[\"1\",{\"0\":{\"56\":1},\"1\":{\"16\":1,\"19\":1,\"24\":1,\"49\":1,\"60\":2,\"86\":1,\"87\":2,\"88\":2,\"89\":2}}],[\"1块梯度收集gpu\",{\"1\":{\"8\":1}}],[\"h>\",{\"1\":{\"89\":2}}],[\"height\",{\"1\":{\"82\":6}}],[\"html\",{\"1\":{\"20\":1}}],[\"https\",{\"1\":{\"9\":1,\"15\":1,\"20\":3,\"22\":1,\"44\":1,\"52\":1,\"59\":1,\"61\":1,\"68\":1,\"80\":2}}],[\"home\",{\"1\":{\"80\":1}}],[\"hot\",{\"1\":{\"60\":1}}],[\"hooks=hooks\",{\"1\":{\"14\":1}}],[\"hooks\",{\"1\":{\"14\":1}}],[\"horovod工作\",{\"0\":{\"13\":1}}],[\"horovod\",{\"0\":{\"9\":1},\"1\":{\"9\":2,\"13\":2,\"14\":3}}],[\"hvd\",{\"1\":{\"14\":5}}],[\"ans\",{\"1\":{\"87\":3,\"89\":3}}],[\"and\",{\"0\":{\"26\":1,\"30\":1,\"31\":1,\"32\":1},\"1\":{\"9\":1,\"16\":1,\"68\":1}}],[\"args\",{\"1\":{\"82\":16}}],[\"arxiv\",{\"1\":{\"9\":1,\"15\":1,\"22\":1,\"44\":2,\"52\":1,\"59\":1,\"61\":1,\"68\":1}}],[\"attribute\",{\"1\":{\"69\":2}}],[\"autograd\",{\"1\":{\"60\":1}}],[\"activation\",{\"0\":{\"33\":1,\"41\":1},\"1\":{\"66\":1}}],[\"accelerating\",{\"1\":{\"15\":1}}],[\"a\",{\"1\":{\"31\":1,\"33\":1}}],[\"adam\",{\"1\":{\"26\":1}}],[\"adam本身对每一个参数都需要保留momentum和variance两个参数进行数据更新\",{\"1\":{\"26\":1}}],[\"adagradoptimizer\",{\"1\":{\"14\":1}}],[\"asst1\",{\"1\":{\"80\":1}}],[\"asst1并不需要额外配置运行环境\",{\"1\":{\"80\":1}}],[\"assignment1\",{\"0\":{\"78\":1}}],[\"as\",{\"1\":{\"14\":3,\"16\":3}}],[\"api\",{\"1\":{\"13\":1,\"20\":1}}],[\"allocate\",{\"1\":{\"49\":4}}],[\"all\",{\"0\":{\"12\":1,\"25\":1},\"1\":{\"50\":1,\"60\":1}}],[\"allreduce将这个过程分为reduce\",{\"1\":{\"10\":1}}],[\"allreduce就是要让每块gpu上的数据都变成箭头右边汇总的样子\",{\"1\":{\"10\":1}}],[\"allreduce\",{\"0\":{\"10\":1},\"1\":{\"13\":2}}],[\"allreduce的方式\",{\"1\":{\"9\":1}}],[\"abstract\",{\"0\":{\"23\":1,\"53\":1}}],[\"abs\",{\"1\":{\"9\":1,\"15\":1,\"22\":1,\"52\":1,\"59\":1}}],[\"aisys\",{\"0\":{\"1\":1},\"2\":{\"74\":1}}],[\"found\",{\"1\":{\"93\":1}}],[\"for\",{\"1\":{\"49\":6,\"68\":1,\"87\":1}}],[\"forward\",{\"1\":{\"16\":1,\"49\":3,\"55\":1,\"60\":2}}],[\"float\",{\"1\":{\"82\":4}}],[\"float2half\",{\"1\":{\"47\":1}}],[\"flexflow负责将\",{\"1\":{\"70\":1}}],[\"flexflow\",{\"0\":{\"68\":1},\"1\":{\"68\":2}}],[\"flush消耗的时间则越小\",{\"1\":{\"64\":1}}],[\"flush操作\",{\"1\":{\"64\":1}}],[\"freq\",{\"1\":{\"60\":1}}],[\"from\",{\"1\":{\"60\":2}}],[\"fragmented\",{\"0\":{\"35\":1}}],[\"fragmentation\",{\"0\":{\"29\":1}}],[\"function\",{\"1\":{\"60\":1}}],[\"fully\",{\"1\":{\"6\":1}}],[\"f\",{\"1\":{\"60\":2}}],[\"fk和\",{\"1\":{\"55\":2}}],[\"false\",{\"1\":{\"49\":1}}],[\"fast\",{\"1\":{\"9\":1}}],[\"fwd\",{\"1\":{\"47\":1,\"49\":1}}],[\"fp16梯度和所有优化器状态存储在cpu上\",{\"1\":{\"49\":1}}],[\"fp16\",{\"1\":{\"26\":2,\"49\":3}}],[\"fp32\",{\"1\":{\"26\":2,\"47\":1,\"49\":6}}],[\"fsdp并行\",{\"0\":{\"21\":1}}],[\"聚合再下发梯度操作被称为allreduce\",{\"1\":{\"8\":1}}],[\"把\",{\"1\":{\"60\":1}}],[\"把当前卡上不要的\",{\"1\":{\"60\":1}}],[\"把本地梯度push到梯度收集gpu\",{\"1\":{\"8\":1}}],[\"把一份data\",{\"1\":{\"8\":1}}],[\"每pipeline中的microbatch的数量\",{\"1\":{\"66\":1}}],[\"每块\",{\"1\":{\"55\":1}}],[\"每块gpu上都有一块数据拥有了对应位置完整的聚合\",{\"1\":{\"11\":1}}],[\"每块gpu上的数据也对应被切成4份\",{\"1\":{\"10\":1}}],[\"每块gpu均拷贝一份完整的模型\",{\"1\":{\"8\":1}}],[\"每份\",{\"1\":{\"55\":1}}],[\"每个内存存有限位数据\",{\"1\":{\"87\":1}}],[\"每个点的迭代次数\",{\"1\":{\"82\":1}}],[\"每个stage放在独立的设备\",{\"1\":{\"53\":1}}],[\"每个\",{\"1\":{\"50\":1}}],[\"每个梯度传输可以与反向计算重叠\",{\"1\":{\"49\":1}}],[\"每个gpu都没有保存或通讯获取完整的参数\",{\"1\":{\"41\":1}}],[\"每个gpu保存1\",{\"1\":{\"41\":1}}],[\"每个进程一个\",{\"1\":{\"14\":1}}],[\"每次都会有ψ\",{\"1\":{\"39\":1}}],[\"每次发送对应位置的数据进行累加\",{\"1\":{\"11\":1}}],[\"每一个集群上的节点假如包含g个gpu卡\",{\"1\":{\"66\":1}}],[\"每一列代表一个时间段\",{\"1\":{\"55\":1}}],[\"每一种颜色代表一块\",{\"1\":{\"55\":1}}],[\"每一次累加更新都形成一个拓扑环\",{\"1\":{\"11\":1}}],[\"每一块gpu完成forward和backward后\",{\"1\":{\"8\":1}}],[\"2πn\",{\"1\":{\"88\":1}}],[\"2πn​\",{\"1\":{\"88\":1}}],[\"25000\",{\"1\":{\"87\":1}}],[\"27的时候\",{\"1\":{\"87\":1}}],[\"2^n\",{\"1\":{\"70\":1}}],[\"2m\",{\"1\":{\"47\":2}}],[\"2依托allreduce算法实现\",{\"1\":{\"39\":1}}],[\"23位尾数位\",{\"1\":{\"26\":1}}],[\"23\",{\"1\":{\"16\":1}}],[\"22\",{\"1\":{\"16\":1,\"80\":1}}],[\"21​log10​\",{\"1\":{\"88\":1}}],[\"2104\",{\"1\":{\"61\":1}}],[\"2101\",{\"1\":{\"44\":2}}],[\"21\",{\"1\":{\"16\":1,\"80\":4}}],[\"20\",{\"1\":{\"16\":3}}],[\"2006\",{\"1\":{\"15\":1}}],[\"2\",{\"0\":{\"57\":1},\"1\":{\"8\":1,\"16\":1,\"19\":1,\"24\":1,\"50\":1,\"89\":3}}],[\"分别计算图像的上下两个部分\",{\"1\":{\"81\":1}}],[\"分别表示pp\",{\"1\":{\"66\":1}}],[\"分别表示第\",{\"1\":{\"55\":2}}],[\"分发到不同的设备上\",{\"1\":{\"70\":1}}],[\"分割a\",{\"1\":{\"60\":1}}],[\"分开重算\",{\"1\":{\"33\":1}}],[\"分配n块计算gpu\",{\"1\":{\"8\":1}}],[\"分布式优化器\",{\"1\":{\"14\":1}}],[\"分布式系统\",{\"2\":{\"74\":1}}],[\"分布式系统如何发挥作用\",{\"0\":{\"5\":1}}],[\"分布式系统顾名思义\",{\"1\":{\"3\":1}}],[\"分布式开发\",{\"0\":{\"1\":1}}],[\"典型数据并行的流程\",{\"0\":{\"8\":1}}],[\"downloads\",{\"1\":{\"80\":1}}],[\"download\",{\"1\":{\"80\":1}}],[\"docs\",{\"1\":{\"20\":3}}],[\"doc\",{\"1\":{\"20\":4}}],[\"d\",{\"1\":{\"66\":2,\"89\":2}}],[\"dtype\",{\"1\":{\"60\":1}}],[\"dtype=args\",{\"1\":{\"60\":1}}],[\"dx\",{\"1\":{\"49\":3}}],[\"ddp支持用户使用统一的api\",{\"1\":{\"20\":1}}],[\"ddp支持三种通讯库\",{\"1\":{\"20\":1}}],[\"ddp\",{\"0\":{\"15\":1}}],[\"dim\",{\"1\":{\"60\":2}}],[\"dive\",{\"0\":{\"36\":1,\"40\":1}}],[\"did\",{\"0\":{\"25\":1}}],[\"dir=\",{\"1\":{\"14\":1}}],[\"distributeddataparallel\",{\"1\":{\"16\":1}}],[\"distributedoptimizer\",{\"1\":{\"14\":1}}],[\"distributed\",{\"1\":{\"9\":1,\"15\":1,\"16\":1}}],[\"decomposition\",{\"1\":{\"81\":1}}],[\"design\",{\"0\":{\"54\":1}}],[\"dest\",{\"1\":{\"49\":1}}],[\"del\",{\"1\":{\"49\":1}}],[\"define\",{\"1\":{\"89\":2}}],[\"def\",{\"1\":{\"49\":5,\"60\":4}}],[\"defragmentation\",{\"0\":{\"43\":1}}],[\"democratizing\",{\"1\":{\"44\":1}}],[\"devices\",{\"1\":{\"69\":2}}],[\"device\",{\"1\":{\"14\":1,\"70\":1,\"71\":1,\"72\":1}}],[\"deepspeedhttps\",{\"1\":{\"22\":1}}],[\"deeplearning\",{\"1\":{\"20\":1}}],[\"deep\",{\"0\":{\"36\":1,\"40\":1},\"1\":{\"9\":1,\"68\":1}}],[\"dp并行维度\",{\"1\":{\"66\":1}}],[\"dp的区别是\",{\"1\":{\"41\":1}}],[\"dp\",{\"0\":{\"7\":1,\"31\":1,\"36\":1},\"1\":{\"50\":1}}],[\"dataset\",{\"1\":{\"49\":1}}],[\"data\",{\"1\":{\"6\":2,\"15\":1,\"68\":1}}],[\"是指碎片化内存\",{\"1\":{\"29\":1}}],[\"是指通讯过程中\",{\"1\":{\"28\":1}}],[\"是独立计算的\",{\"1\":{\"19\":1}}],[\"是一件非常复杂的事情\",{\"1\":{\"6\":1}}],[\"是在利用切分层内数据\",{\"1\":{\"6\":1}}],[\"在乘法时做类似竖式乘法的高精度运算\",{\"1\":{\"87\":1}}],[\"在n\",{\"1\":{\"87\":1}}],[\"在数据存储\",{\"1\":{\"87\":1}}],[\"在task1中解释了空间分解的概念\",{\"1\":{\"81\":1}}],[\"在workerthreadstart\",{\"1\":{\"81\":1}}],[\"在需要时\",{\"1\":{\"66\":1}}],[\"在大模型训练中内存往往比算力更加宝贵\",{\"1\":{\"66\":1}}],[\"在大多数情况下\",{\"1\":{\"46\":1}}],[\"在流水线并行技术中\",{\"1\":{\"64\":1}}],[\"在每一个batch计算完毕时执行pipeline\",{\"1\":{\"64\":1}}],[\"在一个大规模的gpu集群上达到超过50\",{\"1\":{\"62\":1}}],[\"在所有模型并行\",{\"1\":{\"60\":1}}],[\"在优化\",{\"1\":{\"60\":1}}],[\"在pytorch中可以通过下面的代码简单实现\",{\"1\":{\"60\":1}}],[\"在反向传播时要保证在保存不同切分w的gpu中均及时更新a\",{\"1\":{\"60\":1}}],[\"在反向传播计算完成后\",{\"1\":{\"19\":1}}],[\"在该方法下\",{\"1\":{\"60\":1}}],[\"在mlp中最常用的操作是mm\",{\"1\":{\"60\":1}}],[\"在图像和nlp的模型上都得到更好的模型效果\",{\"1\":{\"53\":1}}],[\"在将梯度传输到cpu内存之前\",{\"1\":{\"49\":1}}],[\"在\",{\"1\":{\"49\":5,\"50\":2}}],[\"在实现最小通信量的同时\",{\"1\":{\"46\":1}}],[\"在cpu上的计算量比gpu少多个数量级\",{\"1\":{\"46\":1}}],[\"在过去训练中人们往往忽略了cpu的计算潜力\",{\"1\":{\"45\":1}}],[\"在计算时\",{\"1\":{\"26\":1}}],[\"在模型计算的过程中\",{\"1\":{\"25\":1}}],[\"在小batch时\",{\"1\":{\"19\":1}}],[\"在初始化期间将变量从\",{\"1\":{\"14\":1}}],[\"在128卡时甚至已经超过训练开销\",{\"1\":{\"9\":1}}],[\"在探讨了dp\",{\"1\":{\"6\":1}}],[\"在训练过程中\",{\"1\":{\"49\":1}}],[\"在训练过程中总会有数据\",{\"1\":{\"6\":1}}],[\"在训练ai时\",{\"1\":{\"4\":1}}],[\"printf\",{\"1\":{\"89\":1}}],[\"pro1的内容主要是为了让学生了解std\",{\"1\":{\"81\":1}}],[\"prog1\",{\"0\":{\"79\":1}}],[\"proposals\",{\"1\":{\"72\":1}}],[\"properly\",{\"1\":{\"16\":1}}],[\"processgroup来调用不同的集合通讯库\",{\"1\":{\"20\":1}}],[\"process\",{\"1\":{\"16\":1}}],[\"posts\",{\"0\":{\"95\":1}}],[\"pos\",{\"1\":{\"89\":2}}],[\"pi\",{\"1\":{\"89\":2}}],[\"pipeline尺寸\",{\"1\":{\"64\":1}}],[\"pipeline\",{\"0\":{\"56\":1,\"57\":1},\"1\":{\"52\":1,\"62\":2}}],[\"pipe\",{\"1\":{\"6\":1}}],[\"p\",{\"1\":{\"66\":1}}],[\"p的策略\",{\"1\":{\"62\":1}}],[\"per\",{\"1\":{\"60\":2}}],[\"pdf\",{\"1\":{\"44\":2,\"61\":1,\"68\":1}}],[\"pytorch使用hook机制\",{\"1\":{\"19\":1}}],[\"pytorch使用gradient\",{\"1\":{\"19\":1}}],[\"pytorch在设计api时做到了仅调用第11行代码中的distributeddataparallel部分\",{\"1\":{\"16\":1}}],[\"pytorch\",{\"0\":{\"15\":1},\"1\":{\"15\":3,\"20\":1,\"60\":1}}],[\"python前端api\",{\"0\":{\"16\":1}}],[\"python\",{\"1\":{\"13\":1}}],[\"pp\",{\"1\":{\"6\":1,\"53\":1}}],[\"path=$path\",{\"1\":{\"80\":1}}],[\"patallel\",{\"1\":{\"6\":3}}],[\"padding\",{\"1\":{\"60\":1}}],[\"pass可以来获取不同的性能\",{\"1\":{\"64\":1}}],[\"pass和backward\",{\"1\":{\"64\":1}}],[\"pass\",{\"1\":{\"16\":2,\"49\":1}}],[\"part\",{\"1\":{\"50\":5}}],[\"partition\",{\"1\":{\"50\":1,\"60\":2}}],[\"partitioned\",{\"0\":{\"41\":1}}],[\"params\",{\"1\":{\"60\":1}}],[\"param\",{\"1\":{\"47\":1,\"49\":7}}],[\"parameter\",{\"1\":{\"22\":1,\"59\":1,\"60\":1,\"69\":2}}],[\"parameters\",{\"0\":{\"26\":1},\"1\":{\"16\":2}}],[\"parallelization\",{\"1\":{\"71\":1,\"72\":4}}],[\"parallelism\",{\"0\":{\"55\":1,\"56\":1,\"57\":1},\"1\":{\"52\":1,\"59\":1,\"68\":1}}],[\"parallel且语义和原始mlp对等\",{\"1\":{\"60\":1}}],[\"parallel\",{\"0\":{\"60\":1},\"1\":{\"6\":2,\"15\":1,\"16\":1,\"49\":1,\"60\":10}}],[\"par\",{\"1\":{\"16\":2}}],[\"梯度与\",{\"1\":{\"47\":1}}],[\"梯度和参数\",{\"1\":{\"24\":1}}],[\"梯度同步算法\",{\"0\":{\"17\":1}}],[\"梯度收集gpu聚合梯度\",{\"1\":{\"8\":1}}],[\"梯度\",{\"1\":{\"6\":1}}],[\"既切分优化器状态\",{\"1\":{\"6\":1}}],[\"既然我们有了对数据切分的方法\",{\"1\":{\"6\":1}}],[\"既然可能有很大的数据集需要切分\",{\"1\":{\"6\":1}}],[\"谷歌专门为tp开发了tpu进行并发适配\",{\"1\":{\"6\":1}}],[\"task\",{\"1\":{\"81\":1}}],[\"tar\",{\"1\":{\"80\":3}}],[\"threadid\",{\"1\":{\"82\":1}}],[\"thread的并行机制和\",{\"1\":{\"81\":1}}],[\"threads\",{\"0\":{\"79\":1}}],[\"the\",{\"0\":{\"25\":1}}],[\"t和p\",{\"1\":{\"66\":1}}],[\"t\",{\"1\":{\"66\":1,\"82\":2}}],[\"type\",{\"1\":{\"60\":1}}],[\"temporary\",{\"0\":{\"28\":1,\"34\":1}}],[\"tensorflow框架下的通讯开销越大\",{\"1\":{\"9\":1}}],[\"tensorflow\",{\"1\":{\"9\":1,\"13\":2,\"14\":2}}],[\"tensor\",{\"1\":{\"6\":1,\"60\":6}}],[\"transformer\",{\"1\":{\"64\":1}}],[\"transformers\",{\"0\":{\"60\":1}}],[\"training\",{\"1\":{\"15\":1,\"22\":1,\"44\":1,\"52\":1,\"59\":1,\"61\":1}}],[\"train\",{\"1\":{\"14\":5}}],[\"true\",{\"1\":{\"49\":1}}],[\"trillion\",{\"1\":{\"22\":1}}],[\"topology\",{\"1\":{\"70\":1,\"71\":1,\"72\":1}}],[\"toward\",{\"1\":{\"22\":1}}],[\"torch\",{\"1\":{\"16\":7,\"60\":2}}],[\"tmp\",{\"1\":{\"14\":1}}],[\"tf\",{\"1\":{\"14\":4}}],[\"tp\",{\"0\":{\"58\":1},\"1\":{\"66\":1}}],[\"tpu\",{\"1\":{\"53\":1}}],[\"tpu运算中无以为继\",{\"1\":{\"24\":1}}],[\"tpu没办法高效完成我们的运算\",{\"1\":{\"4\":1}}],[\"tp基本并行方式后\",{\"1\":{\"6\":1}}],[\"tp也是应用较广的基本并发方式\",{\"1\":{\"6\":1}}],[\"算法\",{\"2\":{\"92\":1}}],[\"算法与数据结构实验题\",{\"1\":{\"86\":1}}],[\"算法的实现转化为一个独立的\",{\"1\":{\"13\":1}}],[\"算法还是0基础新人\",{\"1\":{\"0\":1}}],[\"算子并行\",{\"1\":{\"6\":1}}],[\"产生部分输出\",{\"1\":{\"6\":1}}],[\"让每一张卡只保留必须的参数和算子\",{\"1\":{\"6\":1}}],[\"让每一个gpu仅保留几个隐藏层的模型\",{\"1\":{\"6\":1}}],[\"计算用时\",{\"1\":{\"87\":1}}],[\"计算梯度时\",{\"1\":{\"57\":1}}],[\"计算梯度并平均\",{\"1\":{\"50\":1}}],[\"计算\",{\"1\":{\"55\":1}}],[\"计算损失并反向传播\",{\"1\":{\"49\":1}}],[\"计算损失\",{\"1\":{\"49\":1}}],[\"计算放置在一起\",{\"1\":{\"47\":1}}],[\"计算时间\",{\"1\":{\"45\":1}}],[\"计算参数时\",{\"1\":{\"41\":1}}],[\"计算粒度更精细\",{\"1\":{\"31\":1}}],[\"计算过程中产生的一些临时数据\",{\"1\":{\"28\":1}}],[\"计算与通信比率的定量或定性度量\",{\"1\":{\"23\":1}}],[\"计算与聚合之间存在间隔\",{\"1\":{\"18\":1}}],[\"计算成本过大的问题\",{\"1\":{\"9\":1}}],[\"计算gpu从聚合gpu中pull完整梯度\",{\"1\":{\"8\":1}}],[\"计算出本地的梯度\",{\"1\":{\"8\":1}}],[\"计算矩阵进行切分\",{\"1\":{\"6\":1}}],[\"计算机大二本科小白\",{\"1\":{\"0\":1}}],[\"为什么不流水线并行batch\",{\"1\":{\"56\":1}}],[\"为什么ai训练需要分布式系统\",{\"0\":{\"4\":1}}],[\"为什么ai需要分布式系统\",{\"0\":{\"2\":1}}],[\"为一个\",{\"1\":{\"47\":1}}],[\"为避免cpu计算成为瓶颈\",{\"1\":{\"47\":1}}],[\"为了加速并行策略的搜索\",{\"1\":{\"68\":1}}],[\"为了确保optimizer\",{\"1\":{\"64\":1}}],[\"为了确定最佳的下载策略\",{\"1\":{\"47\":1}}],[\"为了解决这个问题\",{\"1\":{\"46\":1}}],[\"为了解决传统dp计算节点和聚合节点比例不好确定导致的通讯成本\",{\"1\":{\"9\":1}}],[\"为了解决层切分的弊端\",{\"1\":{\"6\":1}}],[\"被模型状态占用\",{\"1\":{\"24\":1}}],[\"被称作模型并行\",{\"1\":{\"6\":1}}],[\"被我们称作数据并行\",{\"1\":{\"6\":1}}],[\"那么通过对图片本身的上下多份分割\",{\"1\":{\"81\":1}}],[\"那并行配置\",{\"1\":{\"70\":1}}],[\"那就有4ψ个byte\",{\"1\":{\"26\":1}}],[\"那自然也可能有很大的模型进行切分\",{\"1\":{\"6\":1}}],[\"那我们也可以考虑进行结合\",{\"1\":{\"6\":1}}],[\"那我们就可以考虑把数据切分成好几份\",{\"1\":{\"6\":1}}],[\"那我们可以分到多台设备上\",{\"1\":{\"4\":1}}],[\"那我们可以分到多张卡上面\",{\"1\":{\"4\":1}}],[\"给不同的gpu做计算的方式\",{\"1\":{\"6\":1}}],[\"我希望能把这个数据很快的训练完\",{\"1\":{\"6\":1}}],[\"我们知道对于一个n进制数x\",{\"1\":{\"88\":1}}],[\"我们将进一步推导用斯特林公式估算阶乘位数n的公式\",{\"1\":{\"88\":1}}],[\"我们将一开始就对任务给出多线程的解决方式\",{\"1\":{\"82\":1}}],[\"我们将这种方式称作张量并行\",{\"1\":{\"6\":1}}],[\"我们称这个过程中的等待时间为pipeline\",{\"1\":{\"64\":1}}],[\"我们需要保证不同机器处理bucket的顺序一致\",{\"1\":{\"19\":1}}],[\"我们期望有可以自动为我们选定并行方法的策略\",{\"1\":{\"6\":1}}],[\"我们可以看到\",{\"1\":{\"88\":1}}],[\"我们可以考虑在某一个gpu中存储和更新参数\",{\"1\":{\"31\":1}}],[\"我们可以考虑将三种并行方式进行综合\",{\"1\":{\"6\":1}}],[\"我们可以考虑将计算过程中的算子\",{\"1\":{\"6\":1}}],[\"我们可以把一台机器存不下的任务放到多个结点里面\",{\"1\":{\"3\":1}}],[\"我们可以把一台机器的task进行切分\",{\"1\":{\"3\":1}}],[\"我们有我们自己的很大的数据集\",{\"1\":{\"6\":1}}],[\"我们要怎么做呢\",{\"1\":{\"6\":1}}],[\"我们针对ai训练达成的一种共识\",{\"1\":{\"4\":1}}],[\"我们总要拿出一部分数据用来预训练模型\",{\"1\":{\"4\":1}}],[\"等等需要保存的东西\",{\"1\":{\"6\":1}}],[\"激活函数\",{\"1\":{\"6\":2,\"60\":1,\"70\":1}}],[\"参数的选取\",{\"1\":{\"62\":1}}],[\"参数都按块切分\",{\"1\":{\"55\":1}}],[\"参数更新逻辑\",{\"1\":{\"49\":1}}],[\"参数从\",{\"1\":{\"49\":1}}],[\"参数\",{\"1\":{\"6\":2,\"26\":1,\"47\":1,\"50\":1}}],[\"模型有\",{\"1\":{\"55\":1}}],[\"模型状态\",{\"1\":{\"47\":1}}],[\"模型并行\",{\"1\":{\"23\":1,\"69\":1}}],[\"模型绕过mp方法按层切分时可能带来的通讯瓶颈\",{\"1\":{\"6\":1}}],[\"模型\",{\"1\":{\"6\":1}}],[\"输出\",{\"1\":{\"6\":1,\"26\":1,\"55\":1,\"86\":1}}],[\"输入第一行为一个正整数\",{\"1\":{\"86\":1}}],[\"输入x分割\",{\"1\":{\"60\":1}}],[\"输入\",{\"1\":{\"6\":1,\"26\":1,\"86\":1}}],[\"或者考虑让cpu也存储一部分模型数据\",{\"1\":{\"4\":1}}],[\"但结果较不精确\",{\"1\":{\"88\":1}}],[\"但即使这样\",{\"1\":{\"70\":1}}],[\"但大多数\",{\"1\":{\"70\":1}}],[\"但要增加计算时长\",{\"1\":{\"57\":1}}],[\"但占用空间会多很多\",{\"1\":{\"56\":1}}],[\"但对于小\",{\"1\":{\"46\":1}}],[\"但重点是计算规模和速度\",{\"1\":{\"24\":1}}],[\"但参数量的上升在传统的单机gpu\",{\"1\":{\"24\":1}}],[\"但是一般来说高精度阶乘的时间复杂度是o\",{\"1\":{\"87\":1}}],[\"但是我们都知道\",{\"1\":{\"87\":1}}],[\"但是单卡\",{\"1\":{\"53\":1}}],[\"但是事实上可以考虑在不同隐藏层中实现异步更新参数\",{\"1\":{\"39\":1}}],[\"但是zero3需要对参数进行切分和更新\",{\"1\":{\"39\":1}}],[\"但是需要时常更新\",{\"1\":{\"33\":1}}],[\"但是在更新参数进行新的计算时\",{\"1\":{\"26\":1}}],[\"但是考虑在更新权重的时候\",{\"1\":{\"26\":1}}],[\"但是由于nvidia对于fp16精度计算的高优化度\",{\"1\":{\"26\":1}}],[\"但是也可以利用类似cpu指令流水线执行的方式\",{\"1\":{\"6\":1}}],[\"但是仅让一个卡存模型的几层在计算某些必须要用到之前的数据的模型时可能不尽如人意\",{\"1\":{\"6\":1}}],[\"但每一个gpu均做保留完整的模型做计算\",{\"1\":{\"6\":1}}],[\"但可惜一台机器的性能总是有限的\",{\"1\":{\"4\":1}}],[\"但同时也可能引入更多的问题\",{\"1\":{\"3\":1}}],[\"无论哪一种模型\",{\"1\":{\"6\":1}}],[\"无论使用哪一种模型\",{\"1\":{\"4\":1}}],[\"无论在cv方向还是nlp等其他方向\",{\"1\":{\"4\":1}}],[\"这对估算阶乘的规模来说是完全可以接受的误差\",{\"1\":{\"88\":1}}],[\"这就是第一种错误的可能\",{\"1\":{\"87\":1}}],[\"这就是ai使用分布式系统想要解决的问题\",{\"1\":{\"4\":1}}],[\"这将是一件极为恐怖的事情\",{\"1\":{\"87\":1}}],[\"这道题看上去还挺有意思的很符合大学生的心理状态\",{\"1\":{\"87\":1}}],[\"这一天晚上\",{\"1\":{\"86\":1}}],[\"这一部分主要介绍作者使用zero的一些想法\",{\"1\":{\"30\":1}}],[\"这被称为空间分解\",{\"1\":{\"81\":1}}],[\"这是我的事后诸葛亮\",{\"1\":{\"81\":1}}],[\"这也限制了可以使用的卡的规模\",{\"1\":{\"63\":1}}],[\"这个公式以詹姆斯\",{\"1\":{\"88\":1}}],[\"这个男孩给了弯通一个数字\",{\"1\":{\"86\":1}}],[\"这个操作等价于先对输入进行\",{\"1\":{\"60\":1}}],[\"这个时候就不得不引入分布式系统来改善这种局面了\",{\"1\":{\"4\":1}}],[\"这两种措施共同保证了zero\",{\"1\":{\"46\":1}}],[\"这又是一个仅在计算时才能用到的额外copy\",{\"1\":{\"26\":1}}],[\"这会导致梯度同步结果出现错误\",{\"1\":{\"19\":1}}],[\"这样就可以将每一部分计算矩阵进行并发处理\",{\"1\":{\"6\":1}}],[\"这样可以训练更大的模型\",{\"1\":{\"6\":1}}],[\"这种方法的好处是保障了各自在独立计算时的语义对等\",{\"1\":{\"60\":1}}],[\"这种方式能不能过这个题我没有试过因为我懒\",{\"1\":{\"87\":1}}],[\"这种方式有两个问题需要注意\",{\"1\":{\"19\":1}}],[\"这种方式被称作流水线并行\",{\"1\":{\"6\":1}}],[\"这种策略被称作自动并行\",{\"1\":{\"6\":1}}],[\"这种并行考量被称为3d并行\",{\"1\":{\"6\":1}}],[\"这种并行方式被称作完全分片数据并行\",{\"1\":{\"6\":1}}],[\"这种按层切分的方式固然可以增加可容纳的模型的大小\",{\"1\":{\"6\":1}}],[\"这种按层切分模型\",{\"1\":{\"6\":1}}],[\"这种每个一份数据切分成多份\",{\"1\":{\"6\":1}}],[\"这种系统的好处是显而易见的\",{\"1\":{\"3\":1}}],[\"这基本上是在不考虑机器性能上限的情况下\",{\"1\":{\"4\":1}}],[\"这些都问题都有进一步研究的价值\",{\"1\":{\"3\":1}}],[\"拓展数据规模\",{\"1\":{\"3\":1}}],[\"各个节点之间通过网络进行通讯的计算机系统\",{\"1\":{\"3\":1}}],[\"什么是分布式系统\",{\"0\":{\"3\":1}}],[\"路漫漫其修远兮\",{\"1\":{\"0\":1}}],[\"主攻cv\",{\"1\":{\"0\":1}}]],\"serializationVersion\":2}}")).map(([e,t])=>[e,zt(t,{fields:["h","t","c"],storeFields:["h","t","c"]})]));self.onmessage=({data:{type:e="all",query:t,locale:s,options:n,id:o}})=>{const u=bt[s];e==="suggest"?self.postMessage([e,o,tt(t,u,n)]):e==="search"?self.postMessage([e,o,Z(t,u,n)]):self.postMessage({suggestions:[e,o,tt(t,u,n)],results:[e,o,Z(t,u,n)]})};
//# sourceMappingURL=index.js.map
